{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T07:08:49.785749Z",
     "start_time": "2020-05-22T07:08:20.633278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Part-Of-Speech Tagging \n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T07:08:53.664944Z",
     "start_time": "2020-05-22T07:08:49.787746Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T07:08:53.732892Z",
     "start_time": "2020-05-22T07:08:53.666942Z"
    }
   },
   "outputs": [],
   "source": [
    "en_file = 'shinpakusuu_en.txt'\n",
    "zh_file = 'shinpakusuu_zh.txt'\n",
    "\n",
    "def read_f(x_file):\n",
    "    with open(x_file,'r', encoding='utf-8') as file:\n",
    "        x_list = file.read().splitlines()\n",
    "        \n",
    "    return list(filter(None, x_list))\n",
    "    \n",
    "en_list = read_f(en_file)\n",
    "        \n",
    "zh_list = read_f(zh_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T07:35:04.061032Z",
     "start_time": "2020-05-22T07:35:03.016370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\gabri\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.792 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# English\n",
    "# 1. Tokenize Sentence -> Words\n",
    "# 2. Remove punctuation (or not) # https://stackoverflow.com/questions/57851379/pos-tagging-before-after-punctuation-removal\n",
    "\n",
    "from nltk.tokenize import word_tokenize  # splits by contractions which I don't like\n",
    "from string import punctuation\n",
    "\n",
    "punctuation = punctuation +'–’“”'\n",
    "\n",
    "en_list_token = [word_tokenize(s) for s in en_list]\n",
    "en_list_proc = []\n",
    "for s in en_list_token:\n",
    "    en_list_proc.append([w for w in s if w not in punctuation])\n",
    "\n",
    "# Chinese  ## POSSEG does segment and pos tagging at once\n",
    "# 1. Segmentation\n",
    "# 2. Remove punctuation (or not)\n",
    "\n",
    "punctuation = punctuation + '，「」。！？《》【】、'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T07:44:29.996325Z",
     "start_time": "2020-05-22T07:44:29.960220Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T07:45:14.998201Z",
     "start_time": "2020-05-22T07:45:14.951326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My', 'PRP$'), ('heart', 'NN'), ('when', 'WRB'), ('it', 'PRP'), ('stops', 'VBD')]\n",
      "[('I', 'PRP'), ('m', 'VBP'), ('sure', 'JJ'), ('that', 'IN'), ('this', 'DT'), ('world', 'NN'), ('I', 'PRP'), ('think', 'VBP'), ('I', 'PRP'), ('ll', 'VBP'), ('have', 'VBP'), ('fully', 'RB'), ('enjoyed', 'VBN'), ('it', 'PRP')]\n",
      "[('As', 'IN'), ('for', 'IN'), ('what', 'WP'), ('I', 'PRP'), ('ll', 'VBP'), ('leave', 'VBP'), ('behind', 'IN'), ('pretty', 'RB'), ('much', 'JJ'), ('nothing', 'NN')]\n",
      "[('At', 'IN'), ('your', 'PRP$'), ('side', 'NN'), ('I', 'PRP'), ('think', 'VBP'), ('I', 'PRP'), ('just', 'RB'), ('want', 'VBP'), ('to', 'TO'), ('keep', 'VB'), ('smiling', 'NN')]\n",
      "[('Through', 'IN'), ('the', 'DT'), ('pounding', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('chest', 'NN'), ('I', 'PRP'), ('still', 'RB'), ('want', 'VBP'), ('to', 'TO'), ('protect', 'VB'), ('you', 'PRP')]\n",
      "[('As', 'IN'), ('a', 'DT'), ('reason', 'NN'), ('to', 'TO'), ('live', 'VB'), ('that', 'DT'), ('s', 'JJ'), ('fine', 'NN'), ('by', 'IN'), ('me', 'PRP')]\n",
      "[('One', 'CD'), ('more', 'JJR'), ('one', 'CD'), ('more', 'JJR'), ('I', 'PRP'), ('count', 'VBP'), ('the', 'DT'), ('same', 'JJ'), ('tears', 'NNS')]\n",
      "[('And', 'CC'), ('once', 'RB'), ('again', 'RB'), ('we', 'PRP'), ('know', 'VBP'), ('each', 'DT'), ('other', 'JJ')]\n",
      "[('My', 'PRP$'), ('throbbing', 'VBG'), ('pulse', 'JJ'), ('conveys', 'NNS'), ('them', 'PRP')]\n",
      "[('The', 'DT'), ('recurring', 'VBG'), ('sounds', 'NNS'), ('and', 'CC'), ('my', 'PRP$'), ('running', 'NN'), ('thoughts', 'NNS')]\n",
      "[('Let', 'VB'), ('us', 'PRP'), ('promise', 'VB'), ('to', 'TO'), ('be', 'VB'), ('apart', 'RB'), ('no', 'DT'), ('longer', 'NN')]\n",
      "[('So', 'RB'), ('that', 'IN'), ('you', 'PRP'), ('should', 'MD'), ('never', 'RB'), ('be', 'VB'), ('lonely', 'RB')]\n",
      "[('My', 'PRP$'), ('heart', 'NN'), ('in', 'IN'), ('one', 'CD'), ('minute', 'NN')]\n",
      "[('Seventy', 'NNP'), ('times', 'NNS'), ('it', 'PRP'), ('shouts', 'VBZ'), ('I', 'PRP'), ('live', 'VBP')]\n",
      "[('But', 'CC'), ('when', 'WRB'), ('I', 'PRP'), ('m', 'VBP'), ('with', 'IN'), ('you', 'PRP'), ('it', 'PRP'), ('runs', 'VBZ'), ('fast', 'RB')]\n",
      "[('And', 'CC'), ('one', 'CD'), ('hundred', 'VBD'), ('ten', 'PRP'), ('times', 'VBZ'), ('it', 'PRP'), ('shouts', 'VBZ'), ('I', 'PRP'), ('love', 'VBP')]\n",
      "[('Through', 'IN'), ('the', 'DT'), ('pounding', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('chest', 'NN'), ('I', 'PRP'), ('still', 'RB'), ('want', 'VBP'), ('to', 'TO'), ('protect', 'VB'), ('you', 'PRP')]\n",
      "[('As', 'IN'), ('a', 'DT'), ('reason', 'NN'), ('to', 'TO'), ('live', 'VB'), ('that', 'DT'), ('s', 'JJ'), ('fine', 'NN'), ('by', 'IN'), ('me', 'PRP')]\n",
      "[('Once', 'RB'), ('more', 'JJR'), ('once', 'RB'), ('more', 'JJR'), ('the', 'DT'), ('same', 'JJ'), ('heart', 'NN'), ('repeats', 'NNS')]\n",
      "[('And', 'CC'), ('once', 'RB'), ('again', 'RB'), ('we', 'PRP'), ('know', 'VBP'), ('each', 'DT'), ('other', 'JJ')]\n",
      "[('The', 'DT'), ('meetings', 'NNS'), ('between', 'IN'), ('you', 'PRP'), ('and', 'CC'), ('I', 'PRP')]\n",
      "[('If', 'IN'), ('there', 'EX'), ('had', 'VBD'), ('to', 'TO'), ('be', 'VB'), ('some', 'DT'), ('reason', 'NN'), ('for', 'IN'), ('them', 'PRP')]\n",
      "[('While', 'IN'), ('I', 'PRP'), ('don', 'VBP'), ('t', 'RB'), ('know', 'VBP'), ('if', 'IN'), ('it', 'PRP'), ('would', 'MD'), ('be', 'VB'), ('fate', 'NN')]\n",
      "[('Their', 'PRP$'), ('sheer', 'NN'), ('happiness', 'NN'), ('is', 'VBZ'), ('unchanging', 'VBG')]\n",
      "[('Until', 'IN'), ('that', 'DT'), ('someday', 'NN'), ('when', 'WRB'), ('I', 'PRP'), ('m', 'VBP'), ('ended', 'VBD')]\n",
      "[('How', 'WRB'), ('many', 'JJ'), ('more', 'JJR'), ('loves', 'NNS'), ('can', 'MD'), ('I', 'PRP'), ('utter', 'VB')]\n",
      "[('To', 'TO'), ('your', 'PRP$'), ('being', 'VBG'), ('here', 'RB'), ('with', 'IN'), ('me', 'PRP'), ('I', 'PRP'), ('offer', 'VBP'), ('gratitude', 'JJ')]\n",
      "[('And', 'CC'), ('for', 'IN'), ('simply', 'RB'), ('being', 'VBG'), ('alive', 'JJ'), ('I', 'PRP'), ('thank', 'VBP'), ('you', 'PRP')]\n",
      "[('My', 'PRP$'), ('throbbing', 'VBG'), ('pulse', 'JJ'), ('conveys', 'NNS'), ('them', 'PRP')]\n",
      "[('The', 'DT'), ('recurring', 'VBG'), ('sounds', 'NNS'), ('and', 'CC'), ('my', 'PRP$'), ('running', 'NN'), ('thoughts', 'NNS')]\n",
      "[('Let', 'VB'), ('us', 'PRP'), ('promise', 'VB'), ('to', 'TO'), ('keep', 'VB'), ('loving', 'VBG'), ('each', 'DT'), ('other', 'JJ')]\n",
      "[('Until', 'IN'), ('our', 'PRP$'), ('heartbeats', 'NNS'), ('should', 'MD'), ('stop', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/47519987/how-to-use-pos-tag-in-nltk\n",
    "# Or use treetagger for EN and ZH using same POS tagger \n",
    "\n",
    "for i in en_list_proc:\n",
    "    print(nltk.pos_tag(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T08:03:40.380074Z",
     "start_time": "2020-05-22T08:03:40.343679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('在', 'p'), ('我', 'r'), ('的', 'uj'), ('心脏', 'n'), ('停下', 'v'), ('的', 'uj'), ('时候', 'n'), ('呢', 'y')]\n",
      "[('我', 'r'), ('一定', 'd'), ('是', 'v'), ('觉得', 'v'), ('已经', 'd'), ('充分', 'ad'), ('享受', 'v'), ('过', 'ug'), ('这个', 'r'), ('世界', 'n'), ('才', 'd'), ('结束', 'v'), ('的', 'uj'), ('吧', 'y')]\n",
      "[('彷佛', 'v'), ('没', 'd'), ('做', 'v'), ('完', 'v'), ('的', 'uj'), ('事', 'n'), ('几乎', 'd'), ('都', 'd'), ('没有', 'v'), ('般', 'u')]\n",
      "[('希望', 'v'), ('能', 'v'), ('在', 'p'), ('你', 'r'), ('身旁', 's'), ('一直', 'd'), ('笑', 'v'), ('着', 'uz')]\n",
      "[('仍然', 'd'), ('想', 'v'), ('在', 'p'), ('这', 'r'), ('颗', 'q'), ('心', 'n'), ('跳动', 'vn'), ('的', 'uj'), ('时间', 'n'), ('内', 'n'), ('守护', 'v'), ('你', 'r')]\n",
      "[('只要', 'c'), ('以', 'p'), ('那件事', 'l'), ('为', 'p'), ('生存', 'v'), ('意义', 'n'), ('就', 'd'), ('好', 'a'), ('了', 'ul')]\n",
      "[('再', 'd'), ('一个', 'm'), ('再', 'd'), ('一个', 'm'), ('的', 'uj'), ('数着', 'm'), ('相同', 'd'), ('的', 'uj'), ('眼泪', 'n')]\n",
      "[('我们', 'r'), ('又', 'd'), ('再度', 'd'), ('了解', 'v'), ('了', 'ul'), ('彼此', 'r')]\n",
      "[('巨大', 'a'), ('的', 'uj'), ('跳动', 'vn'), ('声', 'n'), ('传达', 'v'), ('来', 'v'), ('的', 'uj')]\n",
      "[('重叠', 'v'), ('的', 'uj'), ('声响', 'n'), ('与', 'p'), ('流泄', 'v'), ('的', 'uj'), ('思念', 'n')]\n",
      "[('约定', 'v'), ('再也', 'd'), ('不要', 'df'), ('分开', 'v'), ('吧', 'y')]\n",
      "[('希望', 'v'), ('无论', 'c'), ('何时', 'c'), ('都', 'd'), ('不要', 'df'), ('让', 'v'), ('你', 'r'), ('寂寞', 'a')]\n",
      "[('我', 'r'), ('的', 'uj'), ('心脏', 'n'), ('在', 'p'), ('一分钟', 'm'), ('内', 'f'), ('呢', 'y')]\n",
      "[('会', 'v'), ('喊出', 'v'), ('70', 'm'), ('次', 'm'), ('的', 'uj'), ('我', 'r'), ('正', 'd'), ('活着', 'v')]\n",
      "[('但是', 'c'), ('和', 'c'), ('你', 'r'), ('在', 'p'), ('一起', 'm'), ('时', 'n'), ('就', 'd'), ('会', 'v'), ('稍微', 'd'), ('加快脚步', 'i')]\n",
      "[('喊出', 'v'), ('110', 'm'), ('次', 'm'), ('的', 'uj'), ('我爱你', 'l')]\n",
      "[('仍然', 'd'), ('想', 'v'), ('在', 'p'), ('这', 'r'), ('颗', 'q'), ('心', 'n'), ('跳动', 'vn'), ('的', 'uj'), ('时间', 'n'), ('内', 'n'), ('守护', 'v'), ('你', 'r')]\n",
      "[('只要', 'c'), ('以', 'p'), ('那件事', 'l'), ('为', 'p'), ('生存', 'v'), ('意义', 'n'), ('就', 'd'), ('好', 'a'), ('了', 'ul')]\n",
      "[('再', 'd'), ('一次', 'm'), ('再', 'd'), ('一次', 'm'), ('的', 'uj'), ('重迭', 'd'), ('相同', 'd'), ('的', 'uj'), ('心意', 'n')]\n",
      "[('我们', 'r'), ('又', 'd'), ('再度', 'd'), ('了解', 'v'), ('了', 'ul'), ('彼此', 'r')]\n",
      "[('如果', 'c'), ('我', 'r'), ('和', 'c'), ('你', 'r'), ('的', 'uj'), ('相遇', 'v')]\n",
      "[('是', 'v'), ('有', 'v'), ('什么', 'r'), ('理由', 'n'), ('的话', 'u')]\n",
      "[('就算', 'v'), ('不', 'd'), ('知道', 'v'), ('是不是', 'l'), ('命运', 'n')]\n",
      "[('那', 'r'), ('份', 'q'), ('喜悦', 'a'), ('也', 'd'), ('是', 'v'), ('不会', 'v'), ('改变', 'v'), ('的', 'uj'), ('喔', 'o')]\n",
      "[('直到', 'v'), ('某天', 'r'), ('你', 'r'), ('放弃', 'v'), ('我', 'r'), ('为止', 'v')]\n",
      "[('你', 'r'), ('还', 'd'), ('会', 'v'), ('说出', 'v'), ('多少', 'm'), ('次', 'q'), ('喜欢', 'v'), ('呢', 'y')]\n",
      "[('去', 'v'), ('感谢', 'v'), ('能身', 'n'), ('在', 'p'), ('这里', 'r'), ('的', 'uj'), ('这件', 'mq'), ('事', 'n'), ('吧', 'y')]\n",
      "[('就', 'd'), ('为了', 'p'), ('活着', 'v'), ('这件', 'mq'), ('事', 'n'), ('而', 'c'), ('感谢', 'v'), ('吧', 'y')]\n",
      "[('巨大', 'a'), ('的', 'uj'), ('跳动', 'vn'), ('声', 'n'), ('传达', 'v'), ('来', 'v'), ('的', 'uj')]\n",
      "[('重叠', 'v'), ('的', 'uj'), ('声响', 'n'), ('与', 'p'), ('流泄', 'v'), ('的', 'uj'), ('思念', 'n')]\n",
      "[('约定', 'v'), ('一直', 'd'), ('相爱', 'v'), ('下去', 't'), ('吧', 'y')]\n",
      "[('直到', 'v'), ('心跳', 'v'), ('停止', 'v'), ('为止', 'v')]\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg\n",
    "\n",
    "for i in zh_list:\n",
    "    print([(w,y) for w,y in jieba.posseg.cut(i) if w not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:10:32.016331Z",
     "start_time": "2020-05-22T09:10:32.007354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Penn Chinese POS Tagger https://repository.upenn.edu/cgi/viewcontent.cgi?article=1039&context=ircs_reports\n",
    "# https://www.biaodianfu.com/pos-tagging-set.html\n",
    "# https://github.com/fxsjy/jieba (under 词性标注)\n",
    "# https://stackoverflow.com/questions/15388831/what-are-all-possible-pos-tags-of-nltk\n",
    "\n",
    "simple_pos_legend = {\n",
    "    \n",
    "    # Nouns\n",
    "    'NN':'n',\n",
    "    'NNS':'n',\n",
    "    'NNP':'n',\n",
    "    'NNPS':'n',\n",
    "    \n",
    "    'n':'n',\n",
    "    'f':'n',\n",
    "    's':'n',\n",
    "    'nr':'n',\n",
    "    'ns':'n',\n",
    "    'nt':'n',\n",
    "    'nw':'n',\n",
    "    'nz':'n',\n",
    "    \n",
    "    \n",
    "    # Verbs\n",
    "    'VB':'v',\n",
    "    'VBD':'v', \n",
    "    'VBG':'v', \n",
    "    'VBN':'v', \n",
    "    'VBP':'v', \n",
    "    'VBZ':'v',\n",
    "    \n",
    "    'v':'v',\n",
    "    'vd':'v',\n",
    "    'vn':'v',\n",
    "    \n",
    "    \n",
    "    # Adjectives/Adverbs\n",
    "    'JJ':'a',\n",
    "    'JJR':'a',\n",
    "    'JJS':'a',\n",
    "    \n",
    "    'a':'a',\n",
    "    'ad':'a',\n",
    "    'an':'a',\n",
    "    \n",
    "    'RB':'a',\n",
    "    'RBR':'a',\n",
    "    'RBS':'a',\n",
    "    \n",
    "    'd':'a',\n",
    "    \n",
    "    'CC':'c', #conjuction\n",
    "    'CD':'m', #number\n",
    "    'IN':'p', #prepo\n",
    "    \n",
    "    \n",
    "    # Pronoun\n",
    "    'r':'r',\n",
    "    'PRP':'r',\n",
    "    'PRP$':'r',\n",
    "    \n",
    "    # Added after observation\n",
    "    'DT':'r'\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "## Unknown: u 助词 maybe MD (auxil verb) t for time, xc for others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:10:33.314457Z",
     "start_time": "2020-05-22T09:10:33.306489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('m', 'VBP'), ('sure', 'JJ'), ('that', 'IN'), ('this', 'DT'), ('world', 'NN'), ('I', 'PRP'), ('think', 'VBP'), ('I', 'PRP'), ('ll', 'VBP'), ('have', 'VBP'), ('fully', 'RB'), ('enjoyed', 'VBN'), ('it', 'PRP')]\n",
      "[('我', 'r'), ('一定', 'd'), ('是', 'v'), ('觉得', 'v'), ('已经', 'd'), ('充分', 'ad'), ('享受', 'v'), ('过', 'ug'), ('这个', 'r'), ('世界', 'n'), ('才', 'd'), ('结束', 'v'), ('的', 'uj'), ('吧', 'y')]\n"
     ]
    }
   ],
   "source": [
    "line_no = 1\n",
    "print(nltk.pos_tag(en_list_proc[line_no]))\n",
    "print([(w,y) for w,y in jieba.posseg.cut(zh_list[line_no]) if w not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:29:20.451065Z",
     "start_time": "2020-05-22T09:29:20.444048Z"
    }
   },
   "outputs": [],
   "source": [
    "def switch_pos_tags(pos_list, filtered=[], legend=simple_pos_legend):\n",
    "    new_pos_list = []\n",
    "    tag_count_dict = {}\n",
    "    for word, tag in pos_list:\n",
    "        new_tag = legend.get(tag,tag)\n",
    "        new_pos_tuple = (word,new_tag) # default is tag itself if not found in dict\n",
    "        new_pos_list.append(new_pos_tuple)\n",
    "        \n",
    "        if new_tag not in tag_count_dict:\n",
    "            tag_count_dict[new_tag]=1\n",
    "        else: \n",
    "            tag_count_dict[new_tag]+=1\n",
    "    \n",
    "    if filtered:\n",
    "        filtered_dict = {k: v for k, v in tag_count_dict.items() if k in filtered}\n",
    "        output_dict = sorted(filtered_dict.items())\n",
    "    else:\n",
    "        output_dict = sorted(tag_count_dict.items())\n",
    "    \n",
    "    return new_pos_list, output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:31:45.746525Z",
     "start_time": "2020-05-22T09:31:45.737549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Let', 'v'),\n",
       "  ('us', 'r'),\n",
       "  ('promise', 'v'),\n",
       "  ('to', 'TO'),\n",
       "  ('be', 'v'),\n",
       "  ('apart', 'a'),\n",
       "  ('no', 'r'),\n",
       "  ('longer', 'n')],\n",
       " [('a', 1), ('n', 1), ('v', 3)])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_no = 10\n",
    "see_tags = ['a','v','n']\n",
    "\n",
    "switch_pos_tags(nltk.pos_tag(en_list_proc[line_no]), see_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:31:45.930644Z",
     "start_time": "2020-05-22T09:31:45.923663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('约定', 'v'), ('再也', 'a'), ('不要', 'df'), ('分开', 'v'), ('吧', 'y')],\n",
       " [('a', 1), ('v', 2)])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "switch_pos_tags([(w,y) for w,y in jieba.posseg.cut(zh_list[line_no]) if w not in punctuation], see_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
