{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning Parallel Monolingual Corpora\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explored methods of aligning sentences by\n",
    "* Length ([Gale & Church 1993](https://www.aclweb.org/anthology/J93-1004.pdf))\n",
    "* Parts of Speech (Using Stanza, concept from [Chen & Chen 1993](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.4921&rep=rep1&type=pdf))\n",
    "* Embeddings from BiLSTM (Using LASER, [Artetxe & Schwenk 2018](https://arxiv.org/pdf/1812.10464.pdf))\n",
    "* Embeddings from BERT Transformers (Using BERT, [Devlin et al. 2018](https://arxiv.org/abs/1810.04805v2))\n",
    "\n",
    "on English and Chinese.\n",
    "\n",
    "Future exploration\n",
    "* Chunking ([Sun et al. 2000](https://www.aclweb.org/anthology/W00-1314/))\n",
    "* Topic mapping ([Sabbah & Akker 2018](http://lrec-conf.org/workshops/lrec2018/W8/summaries/9_W8.html))\n",
    "* Other languages besides Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:22:52.991201Z",
     "start_time": "2020-07-01T00:19:22.171756Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 1.52MB/s]\n",
      "2020-07-01 08:21:48 INFO: Downloading default packages for language: en (English)...\n",
      "2020-07-01 08:21:53 INFO: File exists: C:\\Users\\gabri\\stanza_resources\\en\\default.zip.\n",
      "2020-07-01 08:22:08 INFO: Finished downloading models and saved to C:\\Users\\gabri\\stanza_resources.\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 547kB/s]\n",
      "2020-07-01 08:22:09 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2020-07-01 08:22:09 INFO: Downloading default packages for language: zh-hans (Simplified_Chinese)...\n",
      "2020-07-01 08:22:18 INFO: File exists: C:\\Users\\gabri\\stanza_resources\\zh-hans\\default.zip.\n",
      "2020-07-01 08:22:52 INFO: Finished downloading models and saved to C:\\Users\\gabri\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import logging\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from random import randrange\n",
    "from string import punctuation\n",
    "\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import stanza\n",
    "import torch\n",
    "import transformers as ppb\n",
    "from laserembeddings import Laser\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pylab import polyfit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from gachalign import length_cost\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stanza.download('en')\n",
    "stanza.download('zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universally-used functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:22:53.226476Z",
     "start_time": "2020-07-01T00:22:52.994232Z"
    }
   },
   "outputs": [],
   "source": [
    "en_stopwords=stopwords.words(\"english\")+[\"'s\"]  #chinese de is stopword\n",
    "stemmer=PorterStemmer()\n",
    "punctuation = punctuation +'–’“”'\n",
    "\n",
    "def en_proc(sentence):\n",
    "    ''' 1. Tokenize Sentence -> Words\n",
    "        2. Remove punctuation and stopwords\n",
    "        3. Stemming Words'''\n",
    "    word_list = word_tokenize(sentence)\n",
    "    bow_list = [stemmer.stem(w.lower()) for w in word_list if w.lower() not in en_stopwords and w not in punctuation]\n",
    "    \n",
    "    return bow_list\n",
    "\n",
    "with open('zh_stopwords.txt','r', encoding='utf-8') as file:\n",
    "    zh_stopwords = file.read()\n",
    "zh_stopwords = re.sub('[ A-Za-z]+\\n', ',', zh_stopwords)\n",
    "zh_stopwords = zh_stopwords.translate(str.maketrans('', '', '\\n')).split(',') \n",
    "zh_stopwords = list(filter(None, zh_stopwords))\n",
    "punctuation = punctuation + '，「」。！？《》【】、'\n",
    "\n",
    "\n",
    "def zh_proc(sentence):\n",
    "    ''' 1. Segmentation\n",
    "        2. Remove punctuation and stopwords'''\n",
    "    bow_list = [w for w in jieba.cut(sentence) if w not in zh_stopwords and w not in punctuation]\n",
    "    return bow_list\n",
    "\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    '''cosine_similarity(transformed_docs[2], transformed_docs[2])'''\n",
    "    # np.squeeze() allows both v1 dot v1 and v1 dot v2\n",
    "    # np.toarray() converts to array\n",
    "    v1 = np.squeeze(v1)\n",
    "    v2 = np.squeeze(v2)\n",
    "    return np.dot(v1,v2) / ( np.sqrt(np.dot(v1,v1)) * np.sqrt(np.dot(v2,v2)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:22:53.231435Z",
     "start_time": "2020-07-01T00:22:53.228429Z"
    }
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(v1, v2):\n",
    "    '''euclidean_distance([0,0,0,0], [1,0,1,0])'''\n",
    "    return np.sum(np.subtract(v1, v2) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:43:58.218838Z",
     "start_time": "2020-07-01T00:43:58.206869Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_df(df, path, have_string=0, index=False, sep='\\t'):\n",
    "    if have_string==1:\n",
    "        quoting=csv.QUOTE_NONE\n",
    "        escapechar=\"\\\\\"\n",
    "    else:\n",
    "        quoting=None\n",
    "        escapechar=None\n",
    "        \n",
    "    path = Path(path)\n",
    "    df.to_csv(path, index=index, sep=sep, quoting=quoting, escapechar=escapechar)\n",
    "    return\n",
    "    \n",
    "def read_df(path, names=None, have_string=0, header=0, sep='\\t'):\n",
    "    if have_string==1:\n",
    "        quoting=csv.QUOTE_NONE\n",
    "        escapechar=\"\\\\\"\n",
    "    else:\n",
    "        quoting=0\n",
    "        escapechar=None\n",
    "    \n",
    "    path = Path(path)\n",
    "    if path.is_file():\n",
    "        print('File exists, reading...')\n",
    "        new_df = pd.read_csv(path, names=names, header=header, sep=sep, quoting=quoting, escapechar=escapechar)\n",
    "        return new_df\n",
    "     \n",
    "    else:\n",
    "        print('File does not exist.')\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def apply_to_df(df, path, method, reoutput=0, index=False, header=0, sep='\\t', **kwargs):\n",
    "    \n",
    "    callbacks = {\n",
    "        'gc' : make_gachalign_feats,\n",
    "        'pos' : make_pos_feats,\n",
    "        'laser' : make_laser_feats,\n",
    "        'bert' : make_bert_feats,\n",
    "        'concat' : pd.concat,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    if reoutput == 1:\n",
    "        df = callbacks[method](df, **kwargs)\n",
    "        save_df(df, path,  index=index, sep=sep)\n",
    "        print('File overwritten.')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    _df = read_df(path, header=header, sep=sep)\n",
    "    \n",
    "    if _df is None:\n",
    "        df = callbacks[method](df, **kwargs)\n",
    "        save_df(df, path,  index=index, sep=sep)\n",
    "        return df\n",
    "    else:\n",
    "        return _df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:22:53.347080Z",
     "start_time": "2020-07-01T00:22:53.253056Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_to_df(df, funct):\n",
    "    test_df = df[:10]\n",
    "    df = eval(funct)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:35:01.232823Z",
     "start_time": "2020-07-01T00:35:01.224843Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bucc_data(reoutput=False):\n",
    "    \n",
    "    data_file = Path(\"bucc_data/zh-en.training.pairs\")\n",
    "    \n",
    "    if data_file.is_file() and not reoutput:\n",
    "        print('Data file exists, reading...')\n",
    "        new_df = read_df(data_file, have_string=1)\n",
    "    \n",
    "    else:\n",
    "        print('Data file does not exist, creating...') if not reoutput else print('Data file to be overwritten.')\n",
    "    \n",
    "        zh_file = Path(\"bucc_data/zh-en.training.zh\")\n",
    "        en_file = Path(\"bucc_data/zh-en.training.en\")\n",
    "        pair_file = Path(\"bucc_data/zh-en.training.gold\")\n",
    "    \n",
    "        zh_df = read_df(zh_file, names=['ID_zh','Sentence_zh'], header=None, have_string=1)\n",
    "        en_df = read_df(en_file, names=['ID_en','Sentence_en'], header=None, have_string=1)\n",
    "        pair_df = read_df(pair_file, names=['ID_zh','ID_en'], header=None)\n",
    "        \n",
    "        new_df = pair_df.merge(zh_df, 'inner', 'ID_zh')\n",
    "        new_df = new_df.merge(en_df, 'inner', 'ID_en')\n",
    "        save_df(new_df, data_file)\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:35:05.196347Z",
     "start_time": "2020-07-01T00:35:05.187410Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bucc_non_pair_data(reoutput=False):\n",
    "    \n",
    "    data_file = Path(\"bucc_data/zh-en.training.nonpairs\")\n",
    "    \n",
    "    if data_file.is_file() and not reoutput:\n",
    "        print('Data file exists, reading...')\n",
    "        new_df = read_df(data_file, have_string=1)\n",
    "    \n",
    "    else:\n",
    "        print('Data file does not exist, creating...') if not reoutput else print('Data file to be overwritten.')\n",
    "        \n",
    "        new_df = pd.DataFrame(columns=['ID_zh', 'ID_en'])\n",
    "    \n",
    "        bucc_file = \"bucc_data/zh-en.training.pairs\"\n",
    "        \n",
    "        bucc_df = read_df(bucc_file, have_string=1)\n",
    "        \n",
    "        n = 0\n",
    "        \n",
    "        while n < 1899:\n",
    "            x = randrange(1899)\n",
    "            y = randrange(1899)\n",
    "            if x != y:\n",
    "                zh_id = bucc_df.iloc[y]['ID_zh']\n",
    "                en_id = bucc_df.iloc[x]['ID_en']\n",
    "                new_df.loc[n] = [zh_id, en_id]\n",
    "                n+=1\n",
    "                \n",
    "        zh_file = \"bucc_data/zh-en.training.zh\"\n",
    "        en_file = \"bucc_data/zh-en.training.en\"\n",
    "        \n",
    "        zh_df = read_df(zh_file, names=['ID_zh','Sentence_zh'], header=None, have_string=1)\n",
    "        en_df = read_df(en_file, names=['ID_en','Sentence_en'], header=None, have_string=1)\n",
    "        \n",
    "        new_df = new_df.merge(zh_df, 'inner', 'ID_zh')\n",
    "        new_df = new_df.merge(en_df, 'inner', 'ID_en')\n",
    "        save_df(new_df, data_file)\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:07.133061Z",
     "start_time": "2020-07-01T00:53:07.001094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file exists, reading...\n",
      "File exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_zh</th>\n",
       "      <th>ID_en</th>\n",
       "      <th>Sentence_zh</th>\n",
       "      <th>Sentence_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zh-000000033</td>\n",
       "      <td>en-000005983</td>\n",
       "      <td>1989年以前，全球经济包含大约8亿到10亿人口。</td>\n",
       "      <td>Until 1989, the global market encompassed betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zh-000000231</td>\n",
       "      <td>en-000047360</td>\n",
       "      <td>今日全球面临的威胁是超民族的，因此也必须采取超民族的方式来应对。</td>\n",
       "      <td>The threats facing the world today are suprana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zh-000000272</td>\n",
       "      <td>en-000027140</td>\n",
       "      <td>欧盟移民政策的硬伤还有一个不太显著的方面。</td>\n",
       "      <td>There is another, less obvious, reason why the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zh-000000438</td>\n",
       "      <td>en-000065621</td>\n",
       "      <td>只有让民粹主义服务于自由主义改革，政府才能取得长久的利益。</td>\n",
       "      <td>Only if populism is put at the service of libe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zh-000000639</td>\n",
       "      <td>en-000005169</td>\n",
       "      <td>但社会民主派必须理解为何示威的发展会独立于现有的有组织中左翼政治。</td>\n",
       "      <td>But social democrats must understand why the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>zh-000094590</td>\n",
       "      <td>en-000013258</td>\n",
       "      <td>事件发生后当局在尚未进行调查的情况下就匆匆掩埋了出事列车残骸。</td>\n",
       "      <td>The wrecked body of the ruined train was burie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>zh-000094593</td>\n",
       "      <td>en-000061419</td>\n",
       "      <td>北方拥有丰富的自然资源，就连电力也是从北方输送到南方。</td>\n",
       "      <td>Natural resources were abundant in the North, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>zh-000094607</td>\n",
       "      <td>en-000039373</td>\n",
       "      <td>如果利率为3%，那么年税收额必须增加15亿美元。</td>\n",
       "      <td>If it is 3%, the required increase in annual t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>zh-000094611</td>\n",
       "      <td>en-000003807</td>\n",
       "      <td>五年前，叙利亚北部边陲城镇享受着土耳其高速经济增长的红利。</td>\n",
       "      <td>Five years ago, Syria’s northern border towns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>zh-000094633</td>\n",
       "      <td>en-000083972</td>\n",
       "      <td>在过去的一个世纪中，我们的世界发生了翻天覆地的变化——技术是其中的重要原因。</td>\n",
       "      <td>Our world has changed vastly over the past cen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1899 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_zh         ID_en                             Sentence_zh  \\\n",
       "0     zh-000000033  en-000005983               1989年以前，全球经济包含大约8亿到10亿人口。   \n",
       "1     zh-000000231  en-000047360        今日全球面临的威胁是超民族的，因此也必须采取超民族的方式来应对。   \n",
       "2     zh-000000272  en-000027140                   欧盟移民政策的硬伤还有一个不太显著的方面。   \n",
       "3     zh-000000438  en-000065621           只有让民粹主义服务于自由主义改革，政府才能取得长久的利益。   \n",
       "4     zh-000000639  en-000005169       但社会民主派必须理解为何示威的发展会独立于现有的有组织中左翼政治。   \n",
       "...            ...           ...                                     ...   \n",
       "1894  zh-000094590  en-000013258         事件发生后当局在尚未进行调查的情况下就匆匆掩埋了出事列车残骸。   \n",
       "1895  zh-000094593  en-000061419             北方拥有丰富的自然资源，就连电力也是从北方输送到南方。   \n",
       "1896  zh-000094607  en-000039373                如果利率为3%，那么年税收额必须增加15亿美元。   \n",
       "1897  zh-000094611  en-000003807           五年前，叙利亚北部边陲城镇享受着土耳其高速经济增长的红利。   \n",
       "1898  zh-000094633  en-000083972  在过去的一个世纪中，我们的世界发生了翻天覆地的变化——技术是其中的重要原因。   \n",
       "\n",
       "                                            Sentence_en  \n",
       "0     Until 1989, the global market encompassed betw...  \n",
       "1     The threats facing the world today are suprana...  \n",
       "2     There is another, less obvious, reason why the...  \n",
       "3     Only if populism is put at the service of libe...  \n",
       "4     But social democrats must understand why the p...  \n",
       "...                                                 ...  \n",
       "1894  The wrecked body of the ruined train was burie...  \n",
       "1895  Natural resources were abundant in the North, ...  \n",
       "1896  If it is 3%, the required increase in annual t...  \n",
       "1897  Five years ago, Syria’s northern border towns ...  \n",
       "1898  Our world has changed vastly over the past cen...  \n",
       "\n",
       "[1899 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucc_df = get_bucc_data()\n",
    "bucc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:13.861854Z",
     "start_time": "2020-07-01T00:53:13.835925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file exists, reading...\n",
      "File exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_zh</th>\n",
       "      <th>ID_en</th>\n",
       "      <th>Sentence_zh</th>\n",
       "      <th>Sentence_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zh-000030343</td>\n",
       "      <td>en-000044219</td>\n",
       "      <td>这个国家的这种做法是对抗击气候变化事业的巨大损害。</td>\n",
       "      <td>When Russia faced its worst crisis, aid was gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zh-000077588</td>\n",
       "      <td>en-000044219</td>\n",
       "      <td>和任何民主国家一样，对土耳其政府政策公共批评是正常的健康现象。</td>\n",
       "      <td>When Russia faced its worst crisis, aid was gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zh-000030343</td>\n",
       "      <td>en-000036472</td>\n",
       "      <td>这个国家的这种做法是对抗击气候变化事业的巨大损害。</td>\n",
       "      <td>Investments in infrastructure, education, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zh-000094584</td>\n",
       "      <td>en-000036472</td>\n",
       "      <td>东南方则是已有400，000难民涌入土耳其的战火纷飞的叙利亚。</td>\n",
       "      <td>Investments in infrastructure, education, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zh-000075027</td>\n",
       "      <td>en-000036472</td>\n",
       "      <td>据“世界粮食计划”统计，当地70%的人口缺少食品安全。</td>\n",
       "      <td>Investments in infrastructure, education, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>zh-000078635</td>\n",
       "      <td>en-000079186</td>\n",
       "      <td>在阿根廷和智利南部美丽的巴塔哥尼亚地区，旅游业大有可为。</td>\n",
       "      <td>More debt relief – encompassing more countries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>zh-000053016</td>\n",
       "      <td>en-000033080</td>\n",
       "      <td>布什政府不但没有延续上届政府推行的禁止湿地开发的政策，反而将其彻底推翻。</td>\n",
       "      <td>People in rich countries are undoubtedly famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>zh-000009129</td>\n",
       "      <td>en-000012334</td>\n",
       "      <td>从20世纪早期开始，墨西哥人就感觉到了美国实力的威胁。</td>\n",
       "      <td>Any country with a sensible development strate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>zh-000052489</td>\n",
       "      <td>en-000002928</td>\n",
       "      <td>四十年前我初入政界时是如此，四十年后的今天也是如此。</td>\n",
       "      <td>As recently as 2008, Turkey’s highest court co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>zh-000025214</td>\n",
       "      <td>en-000024329</td>\n",
       "      <td>但即使是美国宪法，对国会和总统在外交政策方面的权力也语焉不详。</td>\n",
       "      <td>Either way, Iran’s activities confront the wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1899 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_zh         ID_en                           Sentence_zh  \\\n",
       "0     zh-000030343  en-000044219             这个国家的这种做法是对抗击气候变化事业的巨大损害。   \n",
       "1     zh-000077588  en-000044219       和任何民主国家一样，对土耳其政府政策公共批评是正常的健康现象。   \n",
       "2     zh-000030343  en-000036472             这个国家的这种做法是对抗击气候变化事业的巨大损害。   \n",
       "3     zh-000094584  en-000036472       东南方则是已有400，000难民涌入土耳其的战火纷飞的叙利亚。   \n",
       "4     zh-000075027  en-000036472           据“世界粮食计划”统计，当地70%的人口缺少食品安全。   \n",
       "...            ...           ...                                   ...   \n",
       "1894  zh-000078635  en-000079186          在阿根廷和智利南部美丽的巴塔哥尼亚地区，旅游业大有可为。   \n",
       "1895  zh-000053016  en-000033080  布什政府不但没有延续上届政府推行的禁止湿地开发的政策，反而将其彻底推翻。   \n",
       "1896  zh-000009129  en-000012334           从20世纪早期开始，墨西哥人就感觉到了美国实力的威胁。   \n",
       "1897  zh-000052489  en-000002928            四十年前我初入政界时是如此，四十年后的今天也是如此。   \n",
       "1898  zh-000025214  en-000024329       但即使是美国宪法，对国会和总统在外交政策方面的权力也语焉不详。   \n",
       "\n",
       "                                            Sentence_en  \n",
       "0     When Russia faced its worst crisis, aid was gi...  \n",
       "1     When Russia faced its worst crisis, aid was gi...  \n",
       "2     Investments in infrastructure, education, and ...  \n",
       "3     Investments in infrastructure, education, and ...  \n",
       "4     Investments in infrastructure, education, and ...  \n",
       "...                                                 ...  \n",
       "1894  More debt relief – encompassing more countries...  \n",
       "1895  People in rich countries are undoubtedly famil...  \n",
       "1896  Any country with a sensible development strate...  \n",
       "1897  As recently as 2008, Turkey’s highest court co...  \n",
       "1898  Either way, Iran’s activities confront the wor...  \n",
       "\n",
       "[1899 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucc_non_pair_df = get_bucc_non_pair_data()\n",
    "bucc_non_pair_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gale & Church\n",
    "\n",
    "Using [GaChalign](https://github.com/alvations/gachalign) to easily modify mean and variance variables and investigate effects on length distance/cost. \n",
    "\n",
    "Concept from [Wu 1994](https://www.aclweb.org/anthology/P94-1012/) to count each Chinese character as having length 2, and each English or punctuation character as having length 1.\n",
    "\n",
    "3 types of counting explored: by character, by word tokenization, by special counting method from above paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:57:59.426546Z",
     "start_time": "2020-07-01T00:57:59.409317Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_length(sentence, groupby=\"char\", lang =\"en\"):\n",
    "    if groupby == \"char\":\n",
    "        n = len(sentence)\n",
    "        \n",
    "    elif groupby == \"word\":\n",
    "        if lang == \"en\":\n",
    "            n = len(word_tokenize(sentence))\n",
    "        elif lang == \"zh\":\n",
    "            n = len(jieba.lcut(sentence))\n",
    "            \n",
    "    elif groupby == \"special\":\n",
    "        # count each Chinese character as having length 2, and each English or punctuation character as having length 1\n",
    "        if lang == \"zh\":\n",
    "            n=0\n",
    "            for c in sentence:\n",
    "                if c in punctuation:\n",
    "                    n+=1\n",
    "                else:\n",
    "                    n+=2\n",
    "        else:\n",
    "            n = len(sentence)\n",
    "            \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:57:59.441502Z",
     "start_time": "2020-07-01T00:57:59.429538Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_gachalign_feats(df, c=1, s2=6.8):\n",
    "    # Calculate length cost given 2 sentence. Lower cost = higher prob.\n",
    "    # c is mean\n",
    "    # s2 is variance\n",
    "    \n",
    "    gc_df = pd.DataFrame()\n",
    "    \n",
    "    gc_df['char_zh'] = df['Sentence_zh'].map(lambda x: get_length(x, \"char\", \"zh\"))\n",
    "    gc_df['char_en'] = df['Sentence_en'].map(lambda x: get_length(x, \"char\", \"en\"))\n",
    "    gc_df['char_cost'] = gc_df.apply(lambda x: length_cost([x['char_zh']], [x['char_en']], c, s2) if length_cost([x['char_zh']], [x['char_en']], c, s2) >= 0 else 0, axis=1)\n",
    "    \n",
    "    gc_df['word_zh'] = df['Sentence_zh'].map(lambda x: get_length(x, \"word\", \"zh\"))\n",
    "    gc_df['word_en'] = df['Sentence_en'].map(lambda x: get_length(x, \"word\", \"en\"))\n",
    "    gc_df['word_cost'] = gc_df.apply(lambda x: length_cost([x['word_zh']], [x['word_en']], c, s2) if length_cost([x['word_zh']], [x['word_en']], c, s2) >= 0 else 0, axis=1)\n",
    "    \n",
    "    gc_df['special_zh'] = df['Sentence_zh'].map(lambda x: get_length(x, \"special\", \"zh\"))\n",
    "    gc_df['special_en'] = df['Sentence_en'].map(lambda x: get_length(x, \"special\", \"en\"))\n",
    "    gc_df['special_cost'] = gc_df.apply(lambda x: length_cost([x['special_zh']], [x['special_en']], c, s2) if length_cost([x['special_zh']], [x['special_en']], c, s2) >=0 else 0, axis=1)\n",
    "    \n",
    "    return gc_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts Of Speech\n",
    "\n",
    "Stanza is slower than NLTK POS tagger and jieba, but gives better results. Benefit of multilingual POS tagger, shares same tagging legend. \n",
    "\n",
    "Count NOUN, VERB, ADJ, NUM. Did not count quotation marks unlike in [Chen & Chen 1993](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.4921&rep=rep1&type=pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:58:18.645617Z",
     "start_time": "2020-07-01T00:57:59.443497Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-01 08:57:59 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | ewt       |\n",
      "| pos       | ewt       |\n",
      "| lemma     | ewt       |\n",
      "| depparse  | ewt       |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-07-01 08:57:59 INFO: Use device: cpu\n",
      "2020-07-01 08:57:59 INFO: Loading: tokenize\n",
      "2020-07-01 08:58:00 INFO: Loading: pos\n",
      "2020-07-01 08:58:07 INFO: Loading: lemma\n",
      "2020-07-01 08:58:07 INFO: Loading: depparse\n",
      "2020-07-01 08:58:10 INFO: Loading: ner\n",
      "2020-07-01 08:58:18 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "en_postagger = stanza.Pipeline('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:59:08.371865Z",
     "start_time": "2020-07-01T00:58:18.648493Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-01 08:58:18 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2020-07-01 08:58:18 INFO: Loading these models for language: zh-hans (Simplified_Chinese):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | gsdsimp   |\n",
      "| pos       | gsdsimp   |\n",
      "| lemma     | gsdsimp   |\n",
      "| depparse  | gsdsimp   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-07-01 08:58:18 INFO: Use device: cpu\n",
      "2020-07-01 08:58:18 INFO: Loading: tokenize\n",
      "2020-07-01 08:58:18 INFO: Loading: pos\n",
      "2020-07-01 08:58:37 INFO: Loading: lemma\n",
      "2020-07-01 08:58:38 INFO: Loading: depparse\n",
      "2020-07-01 08:58:59 INFO: Loading: ner\n",
      "2020-07-01 08:59:08 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "zh_postagger = stanza.Pipeline('zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:00:29.973385Z",
     "start_time": "2020-07-01T00:59:08.373860Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-01 08:59:08 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2020-07-01 08:59:08 INFO: Loading these models for language: zh-hans (Simplified_Chinese):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | gsdsimp   |\n",
      "| pos       | gsdsimp   |\n",
      "| lemma     | gsdsimp   |\n",
      "| depparse  | gsdsimp   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-07-01 08:59:08 INFO: Use device: cpu\n",
      "2020-07-01 08:59:08 INFO: Loading: tokenize\n",
      "2020-07-01 08:59:08 INFO: Loading: pos\n",
      "2020-07-01 08:59:44 INFO: Loading: lemma\n",
      "2020-07-01 08:59:50 INFO: Loading: depparse\n",
      "2020-07-01 09:00:18 INFO: Loading: ner\n",
      "2020-07-01 09:00:29 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "zh_postagger_pretoken = stanza.Pipeline(lang='zh', tokenize_pretokenized=True)\n",
    "\n",
    "# words split by space, sentences by newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:00:33.749470Z",
     "start_time": "2020-07-01T01:00:30.085053Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pos_counts(sentence, attr = \"upos\", lang =\"en\"):\n",
    "    \n",
    "    tag_count_dict = {}\n",
    "    \n",
    "    if lang == \"en\":\n",
    "        pos_list = [getattr(word, attr) for s in en_postagger(sentence).sentences for word in s.words]\n",
    "        \n",
    "    elif lang == \"zh\":\n",
    "        pos_list = [getattr(word, attr) for s in zh_postagger(sentence).sentences for word in s.words]\n",
    "        \n",
    "    elif lang == \"zh_jieba\":\n",
    "        pos_list = [getattr(word, attr) for s in zh_postagger_pretoken(' '.join(jieba.lcut(sentence))).sentences for word in s.words]\n",
    "        \n",
    "    for tag in pos_list:\n",
    "        if tag not in tag_count_dict:\n",
    "            tag_count_dict[tag]=1\n",
    "        else: \n",
    "            tag_count_dict[tag]+=1\n",
    "    \n",
    "    return tag_count_dict\n",
    "\n",
    "def make_pos_vect(pos_string, filters=['NOUN', 'VERB', 'ADJ', 'NUM']):\n",
    "    \n",
    "    # pos_dict = eval(pos_string) # if converted to str before saving in df\n",
    "    pos_dict = pos_string\n",
    "    \n",
    "    filtered_dict = {}\n",
    "    \n",
    "    for f in filters:\n",
    "        if f not in pos_dict:\n",
    "            filtered_dict[f] = 0\n",
    "        else:\n",
    "            filtered_dict[f] = pos_dict[f]\n",
    "            \n",
    "    ordered_list = [v for k, v in sorted(filtered_dict.items())]\n",
    "            \n",
    "    vector = np.asarray(ordered_list)\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:00:34.926285Z",
     "start_time": "2020-07-01T01:00:34.211242Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pos_feats(df, filters=['NOUN', 'VERB', 'ADJ', 'NUM']):\n",
    "    \n",
    "    pos_df = pd.DataFrame()\n",
    "    \n",
    "    pos_df['dict_zh'] = df['Sentence_zh'].map(lambda x: get_pos_counts(x, lang=\"zh\"))\n",
    "    pos_df['dict_en'] = df['Sentence_en'].map(lambda x: get_pos_counts(x, lang=\"en\"))\n",
    "    \n",
    "    pos_df['vect_zh'] = pos_df['dict_zh'].map(lambda x: make_pos_vect(x, filters))\n",
    "    pos_df['vect_en'] = pos_df['dict_en'].map(lambda x: make_pos_vect(x, filters))\n",
    "    \n",
    "    # pos_df['cos_sim'] = pos_df.apply(lambda x: cosine_similarity(x['vect_zh'], x['vect_en']), axis=1) # Edit: Use Euclidean Distance to deal with zero vectors\n",
    "    pos_df['euclid_dist'] = pos_df.apply(lambda x: euclidean_distance(x['vect_zh'], x['vect_en']), axis=1)\n",
    "    \n",
    "    return pos_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASER Embeddings\n",
    "\n",
    "Language-Agnostic SEntence Representations ([LASER](https://github.com/facebookresearch/LASER)) has multiple languages encoded by the same BiLSTM encoder. Supports code-switching. Specify language for tokenization only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:00:59.370551Z",
     "start_time": "2020-07-01T01:00:37.662306Z"
    }
   },
   "outputs": [],
   "source": [
    "laser = Laser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:00:59.590029Z",
     "start_time": "2020-07-01T01:00:59.493823Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_laser_vect(sentence, proc=True, lang=\"en\"):\n",
    "    if proc==True:\n",
    "        if lang == \"en\":\n",
    "            s = ' '.join(en_proc(sentence))\n",
    "        elif lang == \"zh\":\n",
    "            s = ' '.join(zh_proc(sentence))\n",
    "        else:\n",
    "            print('No proccessing method for this language.')\n",
    "    else:\n",
    "        s = sentence\n",
    "    return laser.embed_sentences(s, lang=[lang])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:01:00.559543Z",
     "start_time": "2020-07-01T01:00:59.743410Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_laser_feats(df):\n",
    "    \n",
    "    laser_df = pd.DataFrame()\n",
    "    \n",
    "    laser_df['vect_proc_zh'] = df['Sentence_zh'].map(lambda x: get_laser_vect(x, lang=\"zh\"))\n",
    "    laser_df['vect_proc_en'] = df['Sentence_en'].map(lambda x: get_laser_vect(x, lang=\"en\"))\n",
    "    laser_df['cos_sim_proc'] = laser_df.apply(lambda x: cosine_similarity(x['vect_proc_zh'], x['vect_proc_en']), axis=1)\n",
    "    \n",
    "    laser_df['vect_noproc_zh'] = df['Sentence_zh'].map(lambda x: get_laser_vect(x, False, lang=\"zh\"))\n",
    "    laser_df['vect_noproc_en'] = df['Sentence_en'].map(lambda x: get_laser_vect(x, False, lang=\"en\"))\n",
    "    laser_df['cos_sim_noproc'] = laser_df.apply(lambda x: cosine_similarity(x['vect_noproc_zh'], x['vect_noproc_en']), axis=1)\n",
    "    \n",
    "    return laser_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embeddings\n",
    "\n",
    "Using [Distilled Multilingual Bert](https://github.com/huggingface/transformers/tree/master/examples/distillation) from Huggingface Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:02:37.922118Z",
     "start_time": "2020-07-01T01:01:00.613203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-multilingual-cased')\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:02:47.705369Z",
     "start_time": "2020-07-01T01:02:39.512668Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bert_vect(sentence, vtype=\"cls\", proc=None):\n",
    "    if proc:\n",
    "        if proc == \"en\":\n",
    "            s = en_proc(sentence)\n",
    "        elif proc == \"zh\":\n",
    "            s = zh_proc(sentence)\n",
    "        else:\n",
    "            print('No proccessing method for this language.')\n",
    "            \n",
    "        tokens_ids = tokenizer.convert_tokens_to_ids(s)\n",
    "        tokens_ids = tokenizer.build_inputs_with_special_tokens(tokens_ids)\n",
    "        tokens_pt = torch.tensor([tokens_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens_pt)\n",
    "        \n",
    "    else:\n",
    "        s = sentence\n",
    "        \n",
    "        tokens = tokenizer.encode(s, add_special_tokens=True)\n",
    "        tokens_pt = torch.tensor([tokens])\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens_pt)\n",
    "            \n",
    "            \n",
    "    if vtype == \"cls\":\n",
    "        return outputs[0][0][0]\n",
    "    elif vtype == \"mean\":\n",
    "        return outputs[0].mean(1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:02:52.963654Z",
     "start_time": "2020-07-01T01:02:48.022234Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_bert_feats(df):\n",
    "    \n",
    "    bert_df = pd.DataFrame()\n",
    "    \n",
    "    bert_df['vect_cls_proc_zh'] = df['Sentence_zh'].map(lambda x: get_bert_vect(x, \"cls\", \"zh\"))\n",
    "    bert_df['vect_cls_proc_en'] = df['Sentence_en'].map(lambda x: get_bert_vect(x, \"cls\", \"en\"))\n",
    "    bert_df['sim_cls_proc'] = bert_df.apply(lambda x: cosine_similarity(x['vect_cls_proc_zh'], x['vect_cls_proc_en']), axis=1)\n",
    "    \n",
    "    bert_df['vect_cls_noproc_zh'] = df['Sentence_zh'].map(lambda x: get_bert_vect(x, \"cls\"))\n",
    "    bert_df['vect_cls_noproc_en'] = df['Sentence_en'].map(lambda x: get_bert_vect(x, \"cls\"))\n",
    "    bert_df['sim_cls_noproc'] = bert_df.apply(lambda x: cosine_similarity(x['vect_cls_noproc_zh'], x['vect_cls_noproc_en']), axis=1)\n",
    "    \n",
    "    bert_df['vect_mean_proc_zh'] = df['Sentence_zh'].map(lambda x: get_bert_vect(x, \"mean\", \"zh\"))\n",
    "    bert_df['vect_mean_proc_en'] = df['Sentence_en'].map(lambda x: get_bert_vect(x, \"mean\", \"en\"))\n",
    "    bert_df['sim_mean_proc'] = bert_df.apply(lambda x: cosine_similarity(x['vect_mean_proc_zh'], x['vect_mean_proc_en']), axis=1)\n",
    "    \n",
    "    bert_df['vect_mean_noproc_zh'] = df['Sentence_zh'].map(lambda x: get_bert_vect(x, \"mean\"))\n",
    "    bert_df['vect_mean_noproc_en'] = df['Sentence_en'].map(lambda x: get_bert_vect(x, \"mean\"))\n",
    "    bert_df['sim_mean_noproc'] = bert_df.apply(lambda x: cosine_similarity(x['vect_mean_noproc_zh'], x['vect_mean_noproc_en']), axis=1)\n",
    "    \n",
    "    return bert_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T02:13:23.399420Z",
     "start_time": "2020-07-01T02:13:23.353692Z"
    }
   },
   "outputs": [],
   "source": [
    "def ensemble(df, path_prefix, num, pair, reoutput=0, deep_reoutput=0):\n",
    "    \n",
    "    pair=int(pair)\n",
    "    _pair = \"pair\" if pair==1 else \"nonpair\"\n",
    "    \n",
    "    _gc_df = apply_to_df(df, path_prefix+\".gachalign\", \"gc\", reoutput=deep_reoutput)\n",
    "    _pos_df = apply_to_df(df, path_prefix+\".pos\", \"pos\", reoutput=deep_reoutput)\n",
    "    _laser_df = apply_to_df(df, path_prefix+\".laser\", \"laser\", reoutput=deep_reoutput)\n",
    "    _bert_df = apply_to_df(df, path_prefix+\".bert\", \"bert\", reoutput=deep_reoutput)\n",
    "    \n",
    "    _feats_list = [\n",
    "        pd.Series(pair, name='pair', index=range(num)), \n",
    "        _gc_df[['char_cost','word_cost','special_cost']], \n",
    "        _pos_df['euclid_dist'].rename('pos'), \n",
    "        _laser_df[['cos_sim_proc', 'cos_sim_noproc']].rename(columns=lambda x: 'laser_'+x[8:]), \n",
    "        _bert_df[['sim_cls_proc','sim_cls_noproc', 'sim_mean_proc','sim_mean_noproc']].rename(columns=lambda x: 'bert_'+x[4:])\n",
    "    ]\n",
    "    \n",
    "    new_df = apply_to_df(_feats_list, path_prefix+'.'+_pair, \"concat\", reoutput=reoutput, axis=1)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T03:41:03.589006Z",
     "start_time": "2020-07-01T03:41:03.394615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_zh</th>\n",
       "      <th>char_en</th>\n",
       "      <th>char_cost</th>\n",
       "      <th>word_zh</th>\n",
       "      <th>word_en</th>\n",
       "      <th>word_cost</th>\n",
       "      <th>special_zh</th>\n",
       "      <th>special_en</th>\n",
       "      <th>special_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>85</td>\n",
       "      <td>625.600212</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>8.361790</td>\n",
       "      <td>48</td>\n",
       "      <td>85</td>\n",
       "      <td>250.264773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>103</td>\n",
       "      <td>703.551801</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>23.009397</td>\n",
       "      <td>62</td>\n",
       "      <td>103</td>\n",
       "      <td>248.353301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>82</td>\n",
       "      <td>685.467548</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>59.338722</td>\n",
       "      <td>41</td>\n",
       "      <td>82</td>\n",
       "      <td>310.167001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>102</td>\n",
       "      <td>756.902252</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>25.230475</td>\n",
       "      <td>56</td>\n",
       "      <td>102</td>\n",
       "      <td>305.377916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>129</td>\n",
       "      <td>1005.265643</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>7.171378</td>\n",
       "      <td>65</td>\n",
       "      <td>129</td>\n",
       "      <td>436.581072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>31</td>\n",
       "      <td>93</td>\n",
       "      <td>597.886734</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>24.422795</td>\n",
       "      <td>61</td>\n",
       "      <td>93</td>\n",
       "      <td>182.031339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>777.412323</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>25.230475</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>336.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>24</td>\n",
       "      <td>87</td>\n",
       "      <td>679.130552</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>65.186118</td>\n",
       "      <td>45</td>\n",
       "      <td>87</td>\n",
       "      <td>304.874844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>29</td>\n",
       "      <td>106</td>\n",
       "      <td>808.117073</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>42.197643</td>\n",
       "      <td>56</td>\n",
       "      <td>106</td>\n",
       "      <td>340.720506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>38</td>\n",
       "      <td>88</td>\n",
       "      <td>415.381161</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>59.192447</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>59.634310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1899 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      char_zh  char_en    char_cost  word_zh  word_en  word_cost  special_zh  \\\n",
       "0          25       85   625.600212       14       15   8.361790          48   \n",
       "1          32      103   703.551801       21       18  23.009397          62   \n",
       "2          21       82   685.467548       12       18  59.338722          41   \n",
       "3          29      102   756.902252       15       18  25.230475          56   \n",
       "4          33      129  1005.265643       20       19   7.171378          65   \n",
       "...       ...      ...          ...      ...      ...        ...         ...   \n",
       "1894       31       93   597.886734       19       16  24.422795          61   \n",
       "1895       27      100   777.412323       15       18  25.230475          52   \n",
       "1896       24       87   679.130552       14       21  65.186118          45   \n",
       "1897       29      106   808.117073       16       21  42.197643          56   \n",
       "1898       38       88   415.381161       24       17  59.192447          74   \n",
       "\n",
       "      special_en  special_cost  \n",
       "0             85    250.264773  \n",
       "1            103    248.353301  \n",
       "2             82    310.167001  \n",
       "3            102    305.377916  \n",
       "4            129    436.581072  \n",
       "...          ...           ...  \n",
       "1894          93    182.031339  \n",
       "1895         100    336.003998  \n",
       "1896          87    304.874844  \n",
       "1897         106    340.720506  \n",
       "1898          88     59.634310  \n",
       "\n",
       "[1899 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc_df = apply_to_df(bucc_df, \"bucc_data/zh-en.output.gachalign\", \"gc\")\n",
    "gc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T03:41:07.528929Z",
     "start_time": "2020-07-01T03:41:07.273317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_zh</th>\n",
       "      <th>dict_en</th>\n",
       "      <th>vect_zh</th>\n",
       "      <th>vect_en</th>\n",
       "      <th>euclid_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'NUM': 3, 'NOUN': 4, 'ADP': 1, 'PUNCT': 2, 'V...</td>\n",
       "      <td>{'ADP': 2, 'NUM': 5, 'PUNCT': 2, 'DET': 1, 'AD...</td>\n",
       "      <td>[0 4 3 1]</td>\n",
       "      <td>[1 2 5 1]</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'NOUN': 6, 'VERB': 3, 'PART': 5, 'AUX': 2, 'P...</td>\n",
       "      <td>{'DET': 2, 'NOUN': 3, 'VERB': 2, 'AUX': 3, 'AD...</td>\n",
       "      <td>[0 6 0 3]</td>\n",
       "      <td>[2 3 0 2]</td>\n",
       "      <td>3.741657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'PROPN': 1, 'NOUN': 5, 'PART': 2, 'ADV': 3, '...</td>\n",
       "      <td>{'PRON': 1, 'VERB': 1, 'DET': 2, 'PUNCT': 3, '...</td>\n",
       "      <td>[1 5 1 1]</td>\n",
       "      <td>[2 3 0 1]</td>\n",
       "      <td>2.449490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'ADP': 1, 'VERB': 4, 'NOUN': 7, 'PUNCT': 2, '...</td>\n",
       "      <td>{'ADV': 1, 'SCONJ': 1, 'NOUN': 5, 'AUX': 2, 'V...</td>\n",
       "      <td>[1 7 0 4]</td>\n",
       "      <td>[2 5 0 2]</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'ADV': 1, 'NOUN': 6, 'PART': 3, 'AUX': 2, 'VE...</td>\n",
       "      <td>{'CCONJ': 1, 'ADJ': 2, 'NOUN': 4, 'AUX': 1, 'V...</td>\n",
       "      <td>[0 6 0 6]</td>\n",
       "      <td>[2 4 0 4]</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>{'NOUN': 6, 'VERB': 5, 'ADP': 3, 'ADV': 4, 'PA...</td>\n",
       "      <td>{'DET': 3, 'VERB': 3, 'NOUN': 3, 'ADP': 2, 'AU...</td>\n",
       "      <td>[0 6 0 5]</td>\n",
       "      <td>[0 3 0 3]</td>\n",
       "      <td>3.605551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>{'NOUN': 6, 'VERB': 4, 'ADJ': 1, 'PART': 1, 'P...</td>\n",
       "      <td>{'ADJ': 2, 'NOUN': 2, 'AUX': 2, 'ADP': 3, 'DET...</td>\n",
       "      <td>[1 6 0 4]</td>\n",
       "      <td>[2 2 0 1]</td>\n",
       "      <td>5.099020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>{'ADP': 1, 'NOUN': 4, 'AUX': 2, 'NUM': 2, 'PUN...</td>\n",
       "      <td>{'SCONJ': 1, 'PRON': 1, 'AUX': 1, 'NUM': 3, 'S...</td>\n",
       "      <td>[0 4 2 1]</td>\n",
       "      <td>[1 4 3 2]</td>\n",
       "      <td>1.732051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>{'NUM': 1, 'NOUN': 6, 'ADP': 1, 'PUNCT': 2, 'P...</td>\n",
       "      <td>{'NUM': 1, 'NOUN': 6, 'ADV': 1, 'PUNCT': 3, 'P...</td>\n",
       "      <td>[1 6 1 2]</td>\n",
       "      <td>[2 6 1 1]</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>{'ADP': 2, 'NOUN': 11, 'PART': 5, 'NUM': 1, 'P...</td>\n",
       "      <td>{'PRON': 1, 'NOUN': 3, 'AUX': 1, 'VERB': 1, 'A...</td>\n",
       "      <td>[ 1 11  1  1]</td>\n",
       "      <td>[1 3 0 1]</td>\n",
       "      <td>8.062258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1899 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                dict_zh  \\\n",
       "0     {'NUM': 3, 'NOUN': 4, 'ADP': 1, 'PUNCT': 2, 'V...   \n",
       "1     {'NOUN': 6, 'VERB': 3, 'PART': 5, 'AUX': 2, 'P...   \n",
       "2     {'PROPN': 1, 'NOUN': 5, 'PART': 2, 'ADV': 3, '...   \n",
       "3     {'ADP': 1, 'VERB': 4, 'NOUN': 7, 'PUNCT': 2, '...   \n",
       "4     {'ADV': 1, 'NOUN': 6, 'PART': 3, 'AUX': 2, 'VE...   \n",
       "...                                                 ...   \n",
       "1894  {'NOUN': 6, 'VERB': 5, 'ADP': 3, 'ADV': 4, 'PA...   \n",
       "1895  {'NOUN': 6, 'VERB': 4, 'ADJ': 1, 'PART': 1, 'P...   \n",
       "1896  {'ADP': 1, 'NOUN': 4, 'AUX': 2, 'NUM': 2, 'PUN...   \n",
       "1897  {'NUM': 1, 'NOUN': 6, 'ADP': 1, 'PUNCT': 2, 'P...   \n",
       "1898  {'ADP': 2, 'NOUN': 11, 'PART': 5, 'NUM': 1, 'P...   \n",
       "\n",
       "                                                dict_en        vect_zh  \\\n",
       "0     {'ADP': 2, 'NUM': 5, 'PUNCT': 2, 'DET': 1, 'AD...      [0 4 3 1]   \n",
       "1     {'DET': 2, 'NOUN': 3, 'VERB': 2, 'AUX': 3, 'AD...      [0 6 0 3]   \n",
       "2     {'PRON': 1, 'VERB': 1, 'DET': 2, 'PUNCT': 3, '...      [1 5 1 1]   \n",
       "3     {'ADV': 1, 'SCONJ': 1, 'NOUN': 5, 'AUX': 2, 'V...      [1 7 0 4]   \n",
       "4     {'CCONJ': 1, 'ADJ': 2, 'NOUN': 4, 'AUX': 1, 'V...      [0 6 0 6]   \n",
       "...                                                 ...            ...   \n",
       "1894  {'DET': 3, 'VERB': 3, 'NOUN': 3, 'ADP': 2, 'AU...      [0 6 0 5]   \n",
       "1895  {'ADJ': 2, 'NOUN': 2, 'AUX': 2, 'ADP': 3, 'DET...      [1 6 0 4]   \n",
       "1896  {'SCONJ': 1, 'PRON': 1, 'AUX': 1, 'NUM': 3, 'S...      [0 4 2 1]   \n",
       "1897  {'NUM': 1, 'NOUN': 6, 'ADV': 1, 'PUNCT': 3, 'P...      [1 6 1 2]   \n",
       "1898  {'PRON': 1, 'NOUN': 3, 'AUX': 1, 'VERB': 1, 'A...  [ 1 11  1  1]   \n",
       "\n",
       "        vect_en  euclid_dist  \n",
       "0     [1 2 5 1]     3.000000  \n",
       "1     [2 3 0 2]     3.741657  \n",
       "2     [2 3 0 1]     2.449490  \n",
       "3     [2 5 0 2]     3.000000  \n",
       "4     [2 4 0 4]     3.464102  \n",
       "...         ...          ...  \n",
       "1894  [0 3 0 3]     3.605551  \n",
       "1895  [2 2 0 1]     5.099020  \n",
       "1896  [1 4 3 2]     1.732051  \n",
       "1897  [2 6 1 1]     1.414214  \n",
       "1898  [1 3 0 1]     8.062258  \n",
       "\n",
       "[1899 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df = apply_to_df(bucc_df, \"bucc_data/zh-en.output.pos\", \"pos\")\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T03:41:20.974166Z",
     "start_time": "2020-07-01T03:41:20.881577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vect_proc_zh</th>\n",
       "      <th>vect_proc_en</th>\n",
       "      <th>cos_sim_proc</th>\n",
       "      <th>vect_noproc_zh</th>\n",
       "      <th>vect_noproc_en</th>\n",
       "      <th>cos_sim_noproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[ 0.00645304  0.01016895  0.0112541  ...  0.0...</td>\n",
       "      <td>[[0.00347378 0.00540323 0.00875655 ... 0.02086...</td>\n",
       "      <td>0.837227</td>\n",
       "      <td>[[ 0.00392936  0.01487431  0.01211387 ...  0.0...</td>\n",
       "      <td>[[0.00515043 0.02721935 0.00645456 ... 0.01680...</td>\n",
       "      <td>0.899076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.01141793 0.00508447 0.0129709  ... 0.04458...</td>\n",
       "      <td>[[ 1.4517792e-02 -2.0507550e-05  2.4949501e-03...</td>\n",
       "      <td>0.701900</td>\n",
       "      <td>[[0.01262616 0.00193994 0.00612493 ... 0.04488...</td>\n",
       "      <td>[[ 1.5549253e-02 -6.9306821e-05 -1.1087634e-04...</td>\n",
       "      <td>0.854534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[ 0.00363402 -0.00035689 -0.00126717 ...  0.0...</td>\n",
       "      <td>[[ 1.4998055e-02 -9.0022750e-06  7.4755466e-03...</td>\n",
       "      <td>0.605472</td>\n",
       "      <td>[[ 0.00837048 -0.00038536 -0.00178816 ...  0.0...</td>\n",
       "      <td>[[ 4.2293437e-02 -4.6420514e-04 -1.7852148e-04...</td>\n",
       "      <td>0.744089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.00071763  0.00012011  0.00200634 ...  0.0...</td>\n",
       "      <td>[[ 0.01445586 -0.00014476  0.00294003 ...  0.0...</td>\n",
       "      <td>0.755492</td>\n",
       "      <td>[[3.2259028e-05 8.7529244e-03 1.3469356e-03 .....</td>\n",
       "      <td>[[-7.7551391e-05  2.4979616e-02  3.8849344e-03...</td>\n",
       "      <td>0.871500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[ 0.00596821 -0.00014701  0.00115364 ...  0.0...</td>\n",
       "      <td>[[ 0.0082258  -0.00044157 -0.00094935 ...  0.0...</td>\n",
       "      <td>0.818175</td>\n",
       "      <td>[[0.01313915 0.00910229 0.0044931  ... 0.06837...</td>\n",
       "      <td>[[ 0.00675407  0.01356385 -0.00238059 ...  0.0...</td>\n",
       "      <td>0.879257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>[[ 1.9390594e-03 -5.6734676e-05 -1.4707656e-03...</td>\n",
       "      <td>[[ 0.01836784  0.00051258 -0.001157   ...  0.0...</td>\n",
       "      <td>0.582360</td>\n",
       "      <td>[[0.01405967 0.0111012  0.00022158 ... 0.02790...</td>\n",
       "      <td>[[ 4.0991213e-03 -1.6492419e-05 -3.1652416e-03...</td>\n",
       "      <td>0.756503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>[[ 0.00034669  0.00011753 -0.00030322 ...  0.0...</td>\n",
       "      <td>[[ 0.01621959  0.0003056  -0.00237891 ...  0.0...</td>\n",
       "      <td>0.707579</td>\n",
       "      <td>[[ 0.00266796  0.00774885  0.00021995 ...  0.0...</td>\n",
       "      <td>[[ 5.1623415e-03  4.5243862e-05 -1.0195789e-03...</td>\n",
       "      <td>0.886560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>[[ 0.00203523 -0.00086154  0.0016085  ...  0.0...</td>\n",
       "      <td>[[ 0.01299874 -0.00041894  0.00354722 ...  0.0...</td>\n",
       "      <td>0.840512</td>\n",
       "      <td>[[0.00070778 0.03335044 0.0027578  ... 0.00442...</td>\n",
       "      <td>[[0.00178883 0.07145008 0.00521136 ... 0.00900...</td>\n",
       "      <td>0.865018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>[[0.01515337 0.00470427 0.00074662 ... 0.06852...</td>\n",
       "      <td>[[ 1.0927872e-02  1.4790997e-02 -4.9027418e-05...</td>\n",
       "      <td>0.888686</td>\n",
       "      <td>[[0.01581433 0.00860143 0.00266306 ... 0.06571...</td>\n",
       "      <td>[[0.00521134 0.01128286 0.00996406 ... 0.06455...</td>\n",
       "      <td>0.911643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>[[ 0.01191691  0.0045437  -0.00246253 ...  0.0...</td>\n",
       "      <td>[[1.6358349e-02 2.9611205e-05 1.7158054e-03 .....</td>\n",
       "      <td>0.622765</td>\n",
       "      <td>[[ 0.01201276  0.01489317 -0.00020652 ...  0.0...</td>\n",
       "      <td>[[ 1.5478059e-02  3.9264446e-06 -3.4608047e-03...</td>\n",
       "      <td>0.795300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1899 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           vect_proc_zh  \\\n",
       "0     [[ 0.00645304  0.01016895  0.0112541  ...  0.0...   \n",
       "1     [[0.01141793 0.00508447 0.0129709  ... 0.04458...   \n",
       "2     [[ 0.00363402 -0.00035689 -0.00126717 ...  0.0...   \n",
       "3     [[-0.00071763  0.00012011  0.00200634 ...  0.0...   \n",
       "4     [[ 0.00596821 -0.00014701  0.00115364 ...  0.0...   \n",
       "...                                                 ...   \n",
       "1894  [[ 1.9390594e-03 -5.6734676e-05 -1.4707656e-03...   \n",
       "1895  [[ 0.00034669  0.00011753 -0.00030322 ...  0.0...   \n",
       "1896  [[ 0.00203523 -0.00086154  0.0016085  ...  0.0...   \n",
       "1897  [[0.01515337 0.00470427 0.00074662 ... 0.06852...   \n",
       "1898  [[ 0.01191691  0.0045437  -0.00246253 ...  0.0...   \n",
       "\n",
       "                                           vect_proc_en  cos_sim_proc  \\\n",
       "0     [[0.00347378 0.00540323 0.00875655 ... 0.02086...      0.837227   \n",
       "1     [[ 1.4517792e-02 -2.0507550e-05  2.4949501e-03...      0.701900   \n",
       "2     [[ 1.4998055e-02 -9.0022750e-06  7.4755466e-03...      0.605472   \n",
       "3     [[ 0.01445586 -0.00014476  0.00294003 ...  0.0...      0.755492   \n",
       "4     [[ 0.0082258  -0.00044157 -0.00094935 ...  0.0...      0.818175   \n",
       "...                                                 ...           ...   \n",
       "1894  [[ 0.01836784  0.00051258 -0.001157   ...  0.0...      0.582360   \n",
       "1895  [[ 0.01621959  0.0003056  -0.00237891 ...  0.0...      0.707579   \n",
       "1896  [[ 0.01299874 -0.00041894  0.00354722 ...  0.0...      0.840512   \n",
       "1897  [[ 1.0927872e-02  1.4790997e-02 -4.9027418e-05...      0.888686   \n",
       "1898  [[1.6358349e-02 2.9611205e-05 1.7158054e-03 .....      0.622765   \n",
       "\n",
       "                                         vect_noproc_zh  \\\n",
       "0     [[ 0.00392936  0.01487431  0.01211387 ...  0.0...   \n",
       "1     [[0.01262616 0.00193994 0.00612493 ... 0.04488...   \n",
       "2     [[ 0.00837048 -0.00038536 -0.00178816 ...  0.0...   \n",
       "3     [[3.2259028e-05 8.7529244e-03 1.3469356e-03 .....   \n",
       "4     [[0.01313915 0.00910229 0.0044931  ... 0.06837...   \n",
       "...                                                 ...   \n",
       "1894  [[0.01405967 0.0111012  0.00022158 ... 0.02790...   \n",
       "1895  [[ 0.00266796  0.00774885  0.00021995 ...  0.0...   \n",
       "1896  [[0.00070778 0.03335044 0.0027578  ... 0.00442...   \n",
       "1897  [[0.01581433 0.00860143 0.00266306 ... 0.06571...   \n",
       "1898  [[ 0.01201276  0.01489317 -0.00020652 ...  0.0...   \n",
       "\n",
       "                                         vect_noproc_en  cos_sim_noproc  \n",
       "0     [[0.00515043 0.02721935 0.00645456 ... 0.01680...        0.899076  \n",
       "1     [[ 1.5549253e-02 -6.9306821e-05 -1.1087634e-04...        0.854534  \n",
       "2     [[ 4.2293437e-02 -4.6420514e-04 -1.7852148e-04...        0.744089  \n",
       "3     [[-7.7551391e-05  2.4979616e-02  3.8849344e-03...        0.871500  \n",
       "4     [[ 0.00675407  0.01356385 -0.00238059 ...  0.0...        0.879257  \n",
       "...                                                 ...             ...  \n",
       "1894  [[ 4.0991213e-03 -1.6492419e-05 -3.1652416e-03...        0.756503  \n",
       "1895  [[ 5.1623415e-03  4.5243862e-05 -1.0195789e-03...        0.886560  \n",
       "1896  [[0.00178883 0.07145008 0.00521136 ... 0.00900...        0.865018  \n",
       "1897  [[0.00521134 0.01128286 0.00996406 ... 0.06455...        0.911643  \n",
       "1898  [[ 1.5478059e-02  3.9264446e-06 -3.4608047e-03...        0.795300  \n",
       "\n",
       "[1899 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_to_df(bucc_df, \"make_laser_feats(test_df)\")\n",
    "laser_df = apply_to_df(bucc_df, \"bucc_data/zh-en.output.laser\", \"laser\")\n",
    "laser_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T03:41:32.147347Z",
     "start_time": "2020-07-01T03:41:30.460558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vect_cls_proc_zh</th>\n",
       "      <th>vect_cls_proc_en</th>\n",
       "      <th>sim_cls_proc</th>\n",
       "      <th>vect_cls_noproc_zh</th>\n",
       "      <th>vect_cls_noproc_en</th>\n",
       "      <th>sim_cls_noproc</th>\n",
       "      <th>vect_mean_proc_zh</th>\n",
       "      <th>vect_mean_proc_en</th>\n",
       "      <th>sim_mean_proc</th>\n",
       "      <th>vect_mean_noproc_zh</th>\n",
       "      <th>vect_mean_noproc_en</th>\n",
       "      <th>sim_mean_noproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor([-1.7088e-01,  1.0762e-01, -1.3487e-01,...</td>\n",
       "      <td>tensor([-4.8489e-01,  8.8018e-02, -4.3963e-02,...</td>\n",
       "      <td>0.944367</td>\n",
       "      <td>tensor([-2.5697e-01, -1.8738e-01,  4.5120e-02,...</td>\n",
       "      <td>tensor([-3.3425e-01, -2.6686e-01,  2.3955e-02,...</td>\n",
       "      <td>0.932438</td>\n",
       "      <td>tensor([[-2.8351e-01,  7.9982e-02, -1.5785e-01...</td>\n",
       "      <td>tensor([[-6.0150e-01,  1.1672e-02,  6.6766e-02...</td>\n",
       "      <td>0.768387</td>\n",
       "      <td>tensor([[-4.6078e-01, -5.4302e-01,  3.6953e-01...</td>\n",
       "      <td>tensor([[-6.0650e-01, -5.2651e-01,  1.4976e-01...</td>\n",
       "      <td>0.718354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor([ 1.0295e-04,  3.2729e-01, -1.5472e-02,...</td>\n",
       "      <td>tensor([-1.2937e-01,  1.1730e-01, -2.5667e-01,...</td>\n",
       "      <td>0.826390</td>\n",
       "      <td>tensor([-2.7488e-01, -1.0204e-01,  8.2408e-02,...</td>\n",
       "      <td>tensor([-2.7188e-01, -1.2896e-01, -3.4097e-01,...</td>\n",
       "      <td>0.885249</td>\n",
       "      <td>tensor([[-2.0262e-01,  2.7153e-01,  2.3812e-02...</td>\n",
       "      <td>tensor([[-3.2220e-01,  2.3857e-01, -3.7317e-02...</td>\n",
       "      <td>0.704907</td>\n",
       "      <td>tensor([[-5.7265e-01, -2.7035e-01,  5.9032e-01...</td>\n",
       "      <td>tensor([[-5.8185e-01, -2.9130e-01, -3.3270e-01...</td>\n",
       "      <td>0.628691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor([-2.1172e-02,  3.3266e-01, -2.0031e-01,...</td>\n",
       "      <td>tensor([-1.7163e-01,  3.5121e-01, -2.2221e-01,...</td>\n",
       "      <td>0.924598</td>\n",
       "      <td>tensor([-1.5105e-01, -7.8253e-02,  2.3573e-01,...</td>\n",
       "      <td>tensor([-3.1621e-01, -7.9063e-02,  1.3702e-01,...</td>\n",
       "      <td>0.911883</td>\n",
       "      <td>tensor([[-1.9326e-01,  2.5108e-01, -2.4815e-01...</td>\n",
       "      <td>tensor([[-3.3650e-01,  3.3788e-01, -2.3007e-01...</td>\n",
       "      <td>0.853088</td>\n",
       "      <td>tensor([[-1.6103e-01, -2.6882e-01,  7.9026e-01...</td>\n",
       "      <td>tensor([[-5.5742e-01, -8.0466e-02,  2.3267e-01...</td>\n",
       "      <td>0.621186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor([-2.1172e-02,  3.3266e-01, -2.0031e-01,...</td>\n",
       "      <td>tensor([-1.8954e-01,  1.6436e-01,  4.4577e-01,...</td>\n",
       "      <td>0.785227</td>\n",
       "      <td>tensor([-1.3524e-01,  6.8776e-02,  7.4715e-02,...</td>\n",
       "      <td>tensor([-3.6524e-01, -2.5968e-02,  2.4890e-02,...</td>\n",
       "      <td>0.925288</td>\n",
       "      <td>tensor([[-1.9326e-01,  2.5108e-01, -2.4815e-01...</td>\n",
       "      <td>tensor([[-1.9562e-01,  1.5004e-01,  3.1491e-01...</td>\n",
       "      <td>0.647528</td>\n",
       "      <td>tensor([[-1.6080e-01,  6.4559e-02,  5.8238e-01...</td>\n",
       "      <td>tensor([[-5.9252e-01, -2.6286e-02,  9.6520e-02...</td>\n",
       "      <td>0.692905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor([-1.0712e-01,  4.3301e-01, -1.2629e-01,...</td>\n",
       "      <td>tensor([-1.3753e-01,  6.5209e-02,  1.5559e-01,...</td>\n",
       "      <td>0.873681</td>\n",
       "      <td>tensor([-1.8522e-01,  5.3373e-02,  1.1788e-02,...</td>\n",
       "      <td>tensor([-4.0475e-01, -9.1276e-02, -3.5700e-01,...</td>\n",
       "      <td>0.856016</td>\n",
       "      <td>tensor([[-3.5143e-01,  3.9773e-01, -2.5038e-01...</td>\n",
       "      <td>tensor([[-3.8218e-01,  1.6849e-03,  1.7885e-01...</td>\n",
       "      <td>0.695893</td>\n",
       "      <td>tensor([[-1.8980e-01,  7.8458e-02,  5.3974e-01...</td>\n",
       "      <td>tensor([[-5.7922e-01, -9.4828e-02, -5.9200e-02...</td>\n",
       "      <td>0.679328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>tensor([-4.2401e-02,  3.3193e-01, -2.5014e-01,...</td>\n",
       "      <td>tensor([-2.9637e-02,  4.2298e-01, -2.5473e-01,...</td>\n",
       "      <td>0.965716</td>\n",
       "      <td>tensor([-8.7130e-02, -1.0812e-01,  1.3057e-02,...</td>\n",
       "      <td>tensor([-2.5755e-02, -1.5073e-01, -2.0023e-01,...</td>\n",
       "      <td>0.900661</td>\n",
       "      <td>tensor([[-2.3588e-01,  2.4285e-01, -3.2926e-01...</td>\n",
       "      <td>tensor([[-1.8602e-01,  4.1861e-01, -3.2512e-01...</td>\n",
       "      <td>0.962498</td>\n",
       "      <td>tensor([[-1.4315e-01, -2.6759e-01,  1.2490e-01...</td>\n",
       "      <td>tensor([[-1.3977e-01, -2.9867e-01, -3.5045e-01...</td>\n",
       "      <td>0.642806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>tensor([-2.5168e-02,  3.3407e-01, -2.0796e-01,...</td>\n",
       "      <td>tensor([ 1.7340e-02,  3.0686e-01,  1.2504e-01,...</td>\n",
       "      <td>0.844786</td>\n",
       "      <td>tensor([-1.5894e-01, -4.2638e-02,  1.7518e-01,...</td>\n",
       "      <td>tensor([-2.7662e-01, -1.9584e-01, -1.3521e-01,...</td>\n",
       "      <td>0.878535</td>\n",
       "      <td>tensor([[-2.0540e-01,  2.4748e-01, -2.6483e-01...</td>\n",
       "      <td>tensor([[-2.1405e-01,  2.4954e-01,  1.1501e-01...</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>tensor([[-3.5640e-01, -2.1323e-01,  6.3719e-01...</td>\n",
       "      <td>tensor([[-6.8853e-01, -3.1353e-01, -9.9416e-02...</td>\n",
       "      <td>0.651582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>tensor([ 2.2724e-02,  1.4694e-01, -1.5951e-01,...</td>\n",
       "      <td>tensor([-1.5070e-01, -7.4269e-02,  5.0753e-01,...</td>\n",
       "      <td>0.878529</td>\n",
       "      <td>tensor([-4.5775e-03, -4.7035e-02,  8.0545e-02,...</td>\n",
       "      <td>tensor([-7.3277e-02, -8.2576e-02,  1.3520e-01,...</td>\n",
       "      <td>0.946697</td>\n",
       "      <td>tensor([[-3.7834e-02,  3.1467e-02, -8.3374e-02...</td>\n",
       "      <td>tensor([[-2.5218e-01, -1.4371e-01,  6.3781e-01...</td>\n",
       "      <td>0.697647</td>\n",
       "      <td>tensor([[-1.8460e-02, -2.4383e-01,  5.4320e-01...</td>\n",
       "      <td>tensor([[-3.2126e-01, -3.1776e-01,  5.4247e-01...</td>\n",
       "      <td>0.735276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>tensor([ 4.2968e-03,  3.1439e-01, -2.4757e-01,...</td>\n",
       "      <td>tensor([-1.5165e-01,  1.3551e-01, -3.1547e-02,...</td>\n",
       "      <td>0.890416</td>\n",
       "      <td>tensor([-8.7320e-02, -1.7427e-01,  1.7993e-01,...</td>\n",
       "      <td>tensor([-1.6905e-01, -1.5648e-01, -5.5539e-03,...</td>\n",
       "      <td>0.937502</td>\n",
       "      <td>tensor([[-1.7464e-01,  2.1160e-01, -3.6906e-01...</td>\n",
       "      <td>tensor([[-2.8356e-01,  8.4986e-02,  1.5096e-01...</td>\n",
       "      <td>0.813110</td>\n",
       "      <td>tensor([[-3.2496e-01, -4.2663e-01,  6.5345e-01...</td>\n",
       "      <td>tensor([[-3.9661e-01, -2.2053e-01,  2.2335e-01...</td>\n",
       "      <td>0.683345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>tensor([-1.7603e-02,  4.3023e-01, -1.9144e-01,...</td>\n",
       "      <td>tensor([ 5.5467e-02,  2.1594e-01,  1.8906e-01,...</td>\n",
       "      <td>0.913768</td>\n",
       "      <td>tensor([-3.3027e-02,  2.6027e-02,  2.1937e-01,...</td>\n",
       "      <td>tensor([-2.6188e-01, -5.2058e-02,  7.1623e-02,...</td>\n",
       "      <td>0.780352</td>\n",
       "      <td>tensor([[-2.0927e-01,  3.9025e-01, -2.2090e-01...</td>\n",
       "      <td>tensor([[-2.6042e-02,  2.1508e-01,  2.4011e-01...</td>\n",
       "      <td>0.858049</td>\n",
       "      <td>tensor([[ 7.4291e-02, -3.8132e-03,  8.9410e-01...</td>\n",
       "      <td>tensor([[-3.3301e-01, -1.0678e-01,  3.6571e-01...</td>\n",
       "      <td>0.661537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1899 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       vect_cls_proc_zh  \\\n",
       "0     tensor([-1.7088e-01,  1.0762e-01, -1.3487e-01,...   \n",
       "1     tensor([ 1.0295e-04,  3.2729e-01, -1.5472e-02,...   \n",
       "2     tensor([-2.1172e-02,  3.3266e-01, -2.0031e-01,...   \n",
       "3     tensor([-2.1172e-02,  3.3266e-01, -2.0031e-01,...   \n",
       "4     tensor([-1.0712e-01,  4.3301e-01, -1.2629e-01,...   \n",
       "...                                                 ...   \n",
       "1894  tensor([-4.2401e-02,  3.3193e-01, -2.5014e-01,...   \n",
       "1895  tensor([-2.5168e-02,  3.3407e-01, -2.0796e-01,...   \n",
       "1896  tensor([ 2.2724e-02,  1.4694e-01, -1.5951e-01,...   \n",
       "1897  tensor([ 4.2968e-03,  3.1439e-01, -2.4757e-01,...   \n",
       "1898  tensor([-1.7603e-02,  4.3023e-01, -1.9144e-01,...   \n",
       "\n",
       "                                       vect_cls_proc_en  sim_cls_proc  \\\n",
       "0     tensor([-4.8489e-01,  8.8018e-02, -4.3963e-02,...      0.944367   \n",
       "1     tensor([-1.2937e-01,  1.1730e-01, -2.5667e-01,...      0.826390   \n",
       "2     tensor([-1.7163e-01,  3.5121e-01, -2.2221e-01,...      0.924598   \n",
       "3     tensor([-1.8954e-01,  1.6436e-01,  4.4577e-01,...      0.785227   \n",
       "4     tensor([-1.3753e-01,  6.5209e-02,  1.5559e-01,...      0.873681   \n",
       "...                                                 ...           ...   \n",
       "1894  tensor([-2.9637e-02,  4.2298e-01, -2.5473e-01,...      0.965716   \n",
       "1895  tensor([ 1.7340e-02,  3.0686e-01,  1.2504e-01,...      0.844786   \n",
       "1896  tensor([-1.5070e-01, -7.4269e-02,  5.0753e-01,...      0.878529   \n",
       "1897  tensor([-1.5165e-01,  1.3551e-01, -3.1547e-02,...      0.890416   \n",
       "1898  tensor([ 5.5467e-02,  2.1594e-01,  1.8906e-01,...      0.913768   \n",
       "\n",
       "                                     vect_cls_noproc_zh  \\\n",
       "0     tensor([-2.5697e-01, -1.8738e-01,  4.5120e-02,...   \n",
       "1     tensor([-2.7488e-01, -1.0204e-01,  8.2408e-02,...   \n",
       "2     tensor([-1.5105e-01, -7.8253e-02,  2.3573e-01,...   \n",
       "3     tensor([-1.3524e-01,  6.8776e-02,  7.4715e-02,...   \n",
       "4     tensor([-1.8522e-01,  5.3373e-02,  1.1788e-02,...   \n",
       "...                                                 ...   \n",
       "1894  tensor([-8.7130e-02, -1.0812e-01,  1.3057e-02,...   \n",
       "1895  tensor([-1.5894e-01, -4.2638e-02,  1.7518e-01,...   \n",
       "1896  tensor([-4.5775e-03, -4.7035e-02,  8.0545e-02,...   \n",
       "1897  tensor([-8.7320e-02, -1.7427e-01,  1.7993e-01,...   \n",
       "1898  tensor([-3.3027e-02,  2.6027e-02,  2.1937e-01,...   \n",
       "\n",
       "                                     vect_cls_noproc_en  sim_cls_noproc  \\\n",
       "0     tensor([-3.3425e-01, -2.6686e-01,  2.3955e-02,...        0.932438   \n",
       "1     tensor([-2.7188e-01, -1.2896e-01, -3.4097e-01,...        0.885249   \n",
       "2     tensor([-3.1621e-01, -7.9063e-02,  1.3702e-01,...        0.911883   \n",
       "3     tensor([-3.6524e-01, -2.5968e-02,  2.4890e-02,...        0.925288   \n",
       "4     tensor([-4.0475e-01, -9.1276e-02, -3.5700e-01,...        0.856016   \n",
       "...                                                 ...             ...   \n",
       "1894  tensor([-2.5755e-02, -1.5073e-01, -2.0023e-01,...        0.900661   \n",
       "1895  tensor([-2.7662e-01, -1.9584e-01, -1.3521e-01,...        0.878535   \n",
       "1896  tensor([-7.3277e-02, -8.2576e-02,  1.3520e-01,...        0.946697   \n",
       "1897  tensor([-1.6905e-01, -1.5648e-01, -5.5539e-03,...        0.937502   \n",
       "1898  tensor([-2.6188e-01, -5.2058e-02,  7.1623e-02,...        0.780352   \n",
       "\n",
       "                                      vect_mean_proc_zh  \\\n",
       "0     tensor([[-2.8351e-01,  7.9982e-02, -1.5785e-01...   \n",
       "1     tensor([[-2.0262e-01,  2.7153e-01,  2.3812e-02...   \n",
       "2     tensor([[-1.9326e-01,  2.5108e-01, -2.4815e-01...   \n",
       "3     tensor([[-1.9326e-01,  2.5108e-01, -2.4815e-01...   \n",
       "4     tensor([[-3.5143e-01,  3.9773e-01, -2.5038e-01...   \n",
       "...                                                 ...   \n",
       "1894  tensor([[-2.3588e-01,  2.4285e-01, -3.2926e-01...   \n",
       "1895  tensor([[-2.0540e-01,  2.4748e-01, -2.6483e-01...   \n",
       "1896  tensor([[-3.7834e-02,  3.1467e-02, -8.3374e-02...   \n",
       "1897  tensor([[-1.7464e-01,  2.1160e-01, -3.6906e-01...   \n",
       "1898  tensor([[-2.0927e-01,  3.9025e-01, -2.2090e-01...   \n",
       "\n",
       "                                      vect_mean_proc_en  sim_mean_proc  \\\n",
       "0     tensor([[-6.0150e-01,  1.1672e-02,  6.6766e-02...       0.768387   \n",
       "1     tensor([[-3.2220e-01,  2.3857e-01, -3.7317e-02...       0.704907   \n",
       "2     tensor([[-3.3650e-01,  3.3788e-01, -2.3007e-01...       0.853088   \n",
       "3     tensor([[-1.9562e-01,  1.5004e-01,  3.1491e-01...       0.647528   \n",
       "4     tensor([[-3.8218e-01,  1.6849e-03,  1.7885e-01...       0.695893   \n",
       "...                                                 ...            ...   \n",
       "1894  tensor([[-1.8602e-01,  4.1861e-01, -3.2512e-01...       0.962498   \n",
       "1895  tensor([[-2.1405e-01,  2.4954e-01,  1.1501e-01...       0.801471   \n",
       "1896  tensor([[-2.5218e-01, -1.4371e-01,  6.3781e-01...       0.697647   \n",
       "1897  tensor([[-2.8356e-01,  8.4986e-02,  1.5096e-01...       0.813110   \n",
       "1898  tensor([[-2.6042e-02,  2.1508e-01,  2.4011e-01...       0.858049   \n",
       "\n",
       "                                    vect_mean_noproc_zh  \\\n",
       "0     tensor([[-4.6078e-01, -5.4302e-01,  3.6953e-01...   \n",
       "1     tensor([[-5.7265e-01, -2.7035e-01,  5.9032e-01...   \n",
       "2     tensor([[-1.6103e-01, -2.6882e-01,  7.9026e-01...   \n",
       "3     tensor([[-1.6080e-01,  6.4559e-02,  5.8238e-01...   \n",
       "4     tensor([[-1.8980e-01,  7.8458e-02,  5.3974e-01...   \n",
       "...                                                 ...   \n",
       "1894  tensor([[-1.4315e-01, -2.6759e-01,  1.2490e-01...   \n",
       "1895  tensor([[-3.5640e-01, -2.1323e-01,  6.3719e-01...   \n",
       "1896  tensor([[-1.8460e-02, -2.4383e-01,  5.4320e-01...   \n",
       "1897  tensor([[-3.2496e-01, -4.2663e-01,  6.5345e-01...   \n",
       "1898  tensor([[ 7.4291e-02, -3.8132e-03,  8.9410e-01...   \n",
       "\n",
       "                                    vect_mean_noproc_en  sim_mean_noproc  \n",
       "0     tensor([[-6.0650e-01, -5.2651e-01,  1.4976e-01...         0.718354  \n",
       "1     tensor([[-5.8185e-01, -2.9130e-01, -3.3270e-01...         0.628691  \n",
       "2     tensor([[-5.5742e-01, -8.0466e-02,  2.3267e-01...         0.621186  \n",
       "3     tensor([[-5.9252e-01, -2.6286e-02,  9.6520e-02...         0.692905  \n",
       "4     tensor([[-5.7922e-01, -9.4828e-02, -5.9200e-02...         0.679328  \n",
       "...                                                 ...              ...  \n",
       "1894  tensor([[-1.3977e-01, -2.9867e-01, -3.5045e-01...         0.642806  \n",
       "1895  tensor([[-6.8853e-01, -3.1353e-01, -9.9416e-02...         0.651582  \n",
       "1896  tensor([[-3.2126e-01, -3.1776e-01,  5.4247e-01...         0.735276  \n",
       "1897  tensor([[-3.9661e-01, -2.2053e-01,  2.2335e-01...         0.683345  \n",
       "1898  tensor([[-3.3301e-01, -1.0678e-01,  3.6571e-01...         0.661537  \n",
       "\n",
       "[1899 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_to_df(bucc_df, \"make_bert_feats(test_df)\")\n",
    "bert_df = apply_to_df(bucc_df, \"bucc_data/zh-en.output.bert\", \"bert\")\n",
    "bert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T03:40:49.948811Z",
     "start_time": "2020-07-01T03:40:45.040581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists, reading...\n",
      "File exists, reading...\n",
      "File exists, reading...\n",
      "File exists, reading...\n",
      "File exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>char_cost</th>\n",
       "      <th>word_cost</th>\n",
       "      <th>special_cost</th>\n",
       "      <th>pos</th>\n",
       "      <th>laser_proc</th>\n",
       "      <th>laser_noproc</th>\n",
       "      <th>bert_cls_proc</th>\n",
       "      <th>bert_cls_noproc</th>\n",
       "      <th>bert_mean_proc</th>\n",
       "      <th>bert_mean_noproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>625.600212</td>\n",
       "      <td>8.361790</td>\n",
       "      <td>250.264773</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.837227</td>\n",
       "      <td>0.899076</td>\n",
       "      <td>0.944367</td>\n",
       "      <td>0.932438</td>\n",
       "      <td>0.768387</td>\n",
       "      <td>0.718354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>703.551801</td>\n",
       "      <td>23.009397</td>\n",
       "      <td>248.353301</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0.701900</td>\n",
       "      <td>0.854534</td>\n",
       "      <td>0.826390</td>\n",
       "      <td>0.885249</td>\n",
       "      <td>0.704907</td>\n",
       "      <td>0.628691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>685.467548</td>\n",
       "      <td>59.338722</td>\n",
       "      <td>310.167001</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0.605472</td>\n",
       "      <td>0.744089</td>\n",
       "      <td>0.924598</td>\n",
       "      <td>0.911883</td>\n",
       "      <td>0.853088</td>\n",
       "      <td>0.621186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>756.902252</td>\n",
       "      <td>25.230475</td>\n",
       "      <td>305.377916</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.755492</td>\n",
       "      <td>0.871500</td>\n",
       "      <td>0.785227</td>\n",
       "      <td>0.925288</td>\n",
       "      <td>0.647528</td>\n",
       "      <td>0.692905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1005.265643</td>\n",
       "      <td>7.171378</td>\n",
       "      <td>436.581072</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>0.818175</td>\n",
       "      <td>0.879257</td>\n",
       "      <td>0.873681</td>\n",
       "      <td>0.856016</td>\n",
       "      <td>0.695893</td>\n",
       "      <td>0.679328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>1</td>\n",
       "      <td>597.886734</td>\n",
       "      <td>24.422795</td>\n",
       "      <td>182.031339</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.582360</td>\n",
       "      <td>0.756503</td>\n",
       "      <td>0.965716</td>\n",
       "      <td>0.900661</td>\n",
       "      <td>0.962498</td>\n",
       "      <td>0.642806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>1</td>\n",
       "      <td>777.412323</td>\n",
       "      <td>25.230475</td>\n",
       "      <td>336.003998</td>\n",
       "      <td>5.099020</td>\n",
       "      <td>0.707579</td>\n",
       "      <td>0.886560</td>\n",
       "      <td>0.844786</td>\n",
       "      <td>0.878535</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>0.651582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>1</td>\n",
       "      <td>679.130552</td>\n",
       "      <td>65.186118</td>\n",
       "      <td>304.874844</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>0.840512</td>\n",
       "      <td>0.865018</td>\n",
       "      <td>0.878529</td>\n",
       "      <td>0.946697</td>\n",
       "      <td>0.697647</td>\n",
       "      <td>0.735276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>1</td>\n",
       "      <td>808.117073</td>\n",
       "      <td>42.197643</td>\n",
       "      <td>340.720506</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.888686</td>\n",
       "      <td>0.911643</td>\n",
       "      <td>0.890416</td>\n",
       "      <td>0.937502</td>\n",
       "      <td>0.813110</td>\n",
       "      <td>0.683345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>1</td>\n",
       "      <td>415.381161</td>\n",
       "      <td>59.192447</td>\n",
       "      <td>59.634310</td>\n",
       "      <td>8.062258</td>\n",
       "      <td>0.622765</td>\n",
       "      <td>0.795300</td>\n",
       "      <td>0.913768</td>\n",
       "      <td>0.780352</td>\n",
       "      <td>0.858049</td>\n",
       "      <td>0.661537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1899 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pair    char_cost  word_cost  special_cost       pos  laser_proc  \\\n",
       "0        1   625.600212   8.361790    250.264773  3.000000    0.837227   \n",
       "1        1   703.551801  23.009397    248.353301  3.741657    0.701900   \n",
       "2        1   685.467548  59.338722    310.167001  2.449490    0.605472   \n",
       "3        1   756.902252  25.230475    305.377916  3.000000    0.755492   \n",
       "4        1  1005.265643   7.171378    436.581072  3.464102    0.818175   \n",
       "...    ...          ...        ...           ...       ...         ...   \n",
       "1894     1   597.886734  24.422795    182.031339  3.605551    0.582360   \n",
       "1895     1   777.412323  25.230475    336.003998  5.099020    0.707579   \n",
       "1896     1   679.130552  65.186118    304.874844  1.732051    0.840512   \n",
       "1897     1   808.117073  42.197643    340.720506  1.414214    0.888686   \n",
       "1898     1   415.381161  59.192447     59.634310  8.062258    0.622765   \n",
       "\n",
       "      laser_noproc  bert_cls_proc  bert_cls_noproc  bert_mean_proc  \\\n",
       "0         0.899076       0.944367         0.932438        0.768387   \n",
       "1         0.854534       0.826390         0.885249        0.704907   \n",
       "2         0.744089       0.924598         0.911883        0.853088   \n",
       "3         0.871500       0.785227         0.925288        0.647528   \n",
       "4         0.879257       0.873681         0.856016        0.695893   \n",
       "...            ...            ...              ...             ...   \n",
       "1894      0.756503       0.965716         0.900661        0.962498   \n",
       "1895      0.886560       0.844786         0.878535        0.801471   \n",
       "1896      0.865018       0.878529         0.946697        0.697647   \n",
       "1897      0.911643       0.890416         0.937502        0.813110   \n",
       "1898      0.795300       0.913768         0.780352        0.858049   \n",
       "\n",
       "      bert_mean_noproc  \n",
       "0             0.718354  \n",
       "1             0.628691  \n",
       "2             0.621186  \n",
       "3             0.692905  \n",
       "4             0.679328  \n",
       "...                ...  \n",
       "1894          0.642806  \n",
       "1895          0.651582  \n",
       "1896          0.735276  \n",
       "1897          0.683345  \n",
       "1898          0.661537  \n",
       "\n",
       "[1899 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucc_output = ensemble(bucc_df, \"bucc_data/zh-en.output\", 1899, 1)\n",
    "bucc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T04:23:22.710009Z",
     "start_time": "2020-07-01T03:41:44.140015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File overwritten.\n",
      "File overwritten.\n",
      "File overwritten.\n",
      "File overwritten.\n",
      "File overwritten.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>char_cost</th>\n",
       "      <th>word_cost</th>\n",
       "      <th>special_cost</th>\n",
       "      <th>pos</th>\n",
       "      <th>laser_proc</th>\n",
       "      <th>laser_noproc</th>\n",
       "      <th>bert_cls_proc</th>\n",
       "      <th>bert_cls_noproc</th>\n",
       "      <th>bert_mean_proc</th>\n",
       "      <th>bert_mean_noproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>567.050117</td>\n",
       "      <td>17.076216</td>\n",
       "      <td>197.462321</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>0.562159</td>\n",
       "      <td>0.565235</td>\n",
       "      <td>0.922061</td>\n",
       "      <td>0.905559</td>\n",
       "      <td>0.806044</td>\n",
       "      <td>0.525250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>448.422605</td>\n",
       "      <td>7.819304</td>\n",
       "      <td>102.359587</td>\n",
       "      <td>4.582576</td>\n",
       "      <td>0.577667</td>\n",
       "      <td>0.575151</td>\n",
       "      <td>0.918370</td>\n",
       "      <td>0.902466</td>\n",
       "      <td>0.803569</td>\n",
       "      <td>0.559394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>625.600212</td>\n",
       "      <td>8.678403</td>\n",
       "      <td>238.943655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.544537</td>\n",
       "      <td>0.528156</td>\n",
       "      <td>0.771636</td>\n",
       "      <td>0.876779</td>\n",
       "      <td>0.773878</td>\n",
       "      <td>0.529556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>502.889048</td>\n",
       "      <td>17.722915</td>\n",
       "      <td>134.634470</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.543380</td>\n",
       "      <td>0.517663</td>\n",
       "      <td>0.790675</td>\n",
       "      <td>0.838892</td>\n",
       "      <td>0.777257</td>\n",
       "      <td>0.412686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>582.365457</td>\n",
       "      <td>17.722915</td>\n",
       "      <td>238.943655</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>0.544718</td>\n",
       "      <td>0.496453</td>\n",
       "      <td>0.771636</td>\n",
       "      <td>0.848218</td>\n",
       "      <td>0.773878</td>\n",
       "      <td>0.422117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>0</td>\n",
       "      <td>749.132896</td>\n",
       "      <td>57.068192</td>\n",
       "      <td>311.449982</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.527975</td>\n",
       "      <td>0.484224</td>\n",
       "      <td>0.816490</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.708461</td>\n",
       "      <td>0.467330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>0</td>\n",
       "      <td>598.950573</td>\n",
       "      <td>32.171100</td>\n",
       "      <td>161.664429</td>\n",
       "      <td>6.782330</td>\n",
       "      <td>0.598243</td>\n",
       "      <td>0.539671</td>\n",
       "      <td>0.756894</td>\n",
       "      <td>0.888381</td>\n",
       "      <td>0.614425</td>\n",
       "      <td>0.461016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>0</td>\n",
       "      <td>1068.567153</td>\n",
       "      <td>42.197643</td>\n",
       "      <td>552.077177</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0.519382</td>\n",
       "      <td>0.511526</td>\n",
       "      <td>0.838038</td>\n",
       "      <td>0.890924</td>\n",
       "      <td>0.757976</td>\n",
       "      <td>0.545457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>0</td>\n",
       "      <td>874.507913</td>\n",
       "      <td>23.685628</td>\n",
       "      <td>419.746350</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>0.462040</td>\n",
       "      <td>0.502066</td>\n",
       "      <td>0.877623</td>\n",
       "      <td>0.862899</td>\n",
       "      <td>0.742209</td>\n",
       "      <td>0.469648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>0</td>\n",
       "      <td>358.663455</td>\n",
       "      <td>35.473086</td>\n",
       "      <td>56.020172</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>0.495902</td>\n",
       "      <td>0.567981</td>\n",
       "      <td>0.912567</td>\n",
       "      <td>0.900107</td>\n",
       "      <td>0.813671</td>\n",
       "      <td>0.523351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1899 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pair    char_cost  word_cost  special_cost       pos  laser_proc  \\\n",
       "0        0   567.050117  17.076216    197.462321  4.123106    0.562159   \n",
       "1        0   448.422605   7.819304    102.359587  4.582576    0.577667   \n",
       "2        0   625.600212   8.678403    238.943655  1.000000    0.544537   \n",
       "3        0   502.889048  17.722915    134.634470  5.000000    0.543380   \n",
       "4        0   582.365457  17.722915    238.943655  1.732051    0.544718   \n",
       "...    ...          ...        ...           ...       ...         ...   \n",
       "1894     0   749.132896  57.068192    311.449982  3.605551    0.527975   \n",
       "1895     0   598.950573  32.171100    161.664429  6.782330    0.598243   \n",
       "1896     0  1068.567153  42.197643    552.077177  3.316625    0.519382   \n",
       "1897     0   874.507913  23.685628    419.746350  2.645751    0.462040   \n",
       "1898     0   358.663455  35.473086     56.020172  4.123106    0.495902   \n",
       "\n",
       "      laser_noproc  bert_cls_proc  bert_cls_noproc  bert_mean_proc  \\\n",
       "0         0.565235       0.922061         0.905559        0.806044   \n",
       "1         0.575151       0.918370         0.902466        0.803569   \n",
       "2         0.528156       0.771636         0.876779        0.773878   \n",
       "3         0.517663       0.790675         0.838892        0.777257   \n",
       "4         0.496453       0.771636         0.848218        0.773878   \n",
       "...            ...            ...              ...             ...   \n",
       "1894      0.484224       0.816490         0.906329        0.708461   \n",
       "1895      0.539671       0.756894         0.888381        0.614425   \n",
       "1896      0.511526       0.838038         0.890924        0.757976   \n",
       "1897      0.502066       0.877623         0.862899        0.742209   \n",
       "1898      0.567981       0.912567         0.900107        0.813671   \n",
       "\n",
       "      bert_mean_noproc  \n",
       "0             0.525250  \n",
       "1             0.559394  \n",
       "2             0.529556  \n",
       "3             0.412686  \n",
       "4             0.422117  \n",
       "...                ...  \n",
       "1894          0.467330  \n",
       "1895          0.461016  \n",
       "1896          0.545457  \n",
       "1897          0.469648  \n",
       "1898          0.523351  \n",
       "\n",
       "[1899 rows x 11 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucc_non_pair_output = ensemble(bucc_non_pair_df, \"bucc_data/non_pairs/zh-en.output\", 1899, 0, 1, 1)\n",
    "bucc_non_pair_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T04:23:23.725654Z",
     "start_time": "2020-07-01T04:23:23.031434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File overwritten.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>char_cost</th>\n",
       "      <th>word_cost</th>\n",
       "      <th>special_cost</th>\n",
       "      <th>pos</th>\n",
       "      <th>laser_proc</th>\n",
       "      <th>laser_noproc</th>\n",
       "      <th>bert_cls_proc</th>\n",
       "      <th>bert_cls_noproc</th>\n",
       "      <th>bert_mean_proc</th>\n",
       "      <th>bert_mean_noproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>625.600212</td>\n",
       "      <td>8.361790</td>\n",
       "      <td>250.264773</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.837227</td>\n",
       "      <td>0.899076</td>\n",
       "      <td>0.944367</td>\n",
       "      <td>0.932438</td>\n",
       "      <td>0.768387</td>\n",
       "      <td>0.718354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>703.551801</td>\n",
       "      <td>23.009397</td>\n",
       "      <td>248.353301</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0.701900</td>\n",
       "      <td>0.854534</td>\n",
       "      <td>0.826390</td>\n",
       "      <td>0.885249</td>\n",
       "      <td>0.704907</td>\n",
       "      <td>0.628691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>685.467548</td>\n",
       "      <td>59.338722</td>\n",
       "      <td>310.167001</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0.605472</td>\n",
       "      <td>0.744089</td>\n",
       "      <td>0.924598</td>\n",
       "      <td>0.911883</td>\n",
       "      <td>0.853088</td>\n",
       "      <td>0.621186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>756.902252</td>\n",
       "      <td>25.230475</td>\n",
       "      <td>305.377916</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.755492</td>\n",
       "      <td>0.871500</td>\n",
       "      <td>0.785227</td>\n",
       "      <td>0.925288</td>\n",
       "      <td>0.647528</td>\n",
       "      <td>0.692905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1005.265643</td>\n",
       "      <td>7.171378</td>\n",
       "      <td>436.581072</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>0.818175</td>\n",
       "      <td>0.879257</td>\n",
       "      <td>0.873681</td>\n",
       "      <td>0.856016</td>\n",
       "      <td>0.695893</td>\n",
       "      <td>0.679328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>0</td>\n",
       "      <td>749.132896</td>\n",
       "      <td>57.068192</td>\n",
       "      <td>311.449982</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.527975</td>\n",
       "      <td>0.484224</td>\n",
       "      <td>0.816490</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.708461</td>\n",
       "      <td>0.467330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>0</td>\n",
       "      <td>598.950573</td>\n",
       "      <td>32.171100</td>\n",
       "      <td>161.664429</td>\n",
       "      <td>6.782330</td>\n",
       "      <td>0.598243</td>\n",
       "      <td>0.539671</td>\n",
       "      <td>0.756894</td>\n",
       "      <td>0.888381</td>\n",
       "      <td>0.614425</td>\n",
       "      <td>0.461016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>0</td>\n",
       "      <td>1068.567153</td>\n",
       "      <td>42.197643</td>\n",
       "      <td>552.077177</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0.519382</td>\n",
       "      <td>0.511526</td>\n",
       "      <td>0.838038</td>\n",
       "      <td>0.890924</td>\n",
       "      <td>0.757976</td>\n",
       "      <td>0.545457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>0</td>\n",
       "      <td>874.507913</td>\n",
       "      <td>23.685628</td>\n",
       "      <td>419.746350</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>0.462040</td>\n",
       "      <td>0.502066</td>\n",
       "      <td>0.877623</td>\n",
       "      <td>0.862899</td>\n",
       "      <td>0.742209</td>\n",
       "      <td>0.469648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>0</td>\n",
       "      <td>358.663455</td>\n",
       "      <td>35.473086</td>\n",
       "      <td>56.020172</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>0.495902</td>\n",
       "      <td>0.567981</td>\n",
       "      <td>0.912567</td>\n",
       "      <td>0.900107</td>\n",
       "      <td>0.813671</td>\n",
       "      <td>0.523351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pair    char_cost  word_cost  special_cost       pos  laser_proc  \\\n",
       "0        1   625.600212   8.361790    250.264773  3.000000    0.837227   \n",
       "1        1   703.551801  23.009397    248.353301  3.741657    0.701900   \n",
       "2        1   685.467548  59.338722    310.167001  2.449490    0.605472   \n",
       "3        1   756.902252  25.230475    305.377916  3.000000    0.755492   \n",
       "4        1  1005.265643   7.171378    436.581072  3.464102    0.818175   \n",
       "...    ...          ...        ...           ...       ...         ...   \n",
       "1894     0   749.132896  57.068192    311.449982  3.605551    0.527975   \n",
       "1895     0   598.950573  32.171100    161.664429  6.782330    0.598243   \n",
       "1896     0  1068.567153  42.197643    552.077177  3.316625    0.519382   \n",
       "1897     0   874.507913  23.685628    419.746350  2.645751    0.462040   \n",
       "1898     0   358.663455  35.473086     56.020172  4.123106    0.495902   \n",
       "\n",
       "      laser_noproc  bert_cls_proc  bert_cls_noproc  bert_mean_proc  \\\n",
       "0         0.899076       0.944367         0.932438        0.768387   \n",
       "1         0.854534       0.826390         0.885249        0.704907   \n",
       "2         0.744089       0.924598         0.911883        0.853088   \n",
       "3         0.871500       0.785227         0.925288        0.647528   \n",
       "4         0.879257       0.873681         0.856016        0.695893   \n",
       "...            ...            ...              ...             ...   \n",
       "1894      0.484224       0.816490         0.906329        0.708461   \n",
       "1895      0.539671       0.756894         0.888381        0.614425   \n",
       "1896      0.511526       0.838038         0.890924        0.757976   \n",
       "1897      0.502066       0.877623         0.862899        0.742209   \n",
       "1898      0.567981       0.912567         0.900107        0.813671   \n",
       "\n",
       "      bert_mean_noproc  \n",
       "0             0.718354  \n",
       "1             0.628691  \n",
       "2             0.621186  \n",
       "3             0.692905  \n",
       "4             0.679328  \n",
       "...                ...  \n",
       "1894          0.467330  \n",
       "1895          0.461016  \n",
       "1896          0.545457  \n",
       "1897          0.469648  \n",
       "1898          0.523351  \n",
       "\n",
       "[3798 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucc_combined = apply_to_df([bucc_output, bucc_non_pair_output], \"bucc_data/zh-en.training.combined\", \"concat\", 1)\n",
    "bucc_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T05:05:31.416220Z",
     "start_time": "2020-07-01T05:05:31.142511Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample_data(reoutput=False):\n",
    "    \n",
    "    data_file = Path(\"bucc_data/zh-en.sample.pairs\")\n",
    "    \n",
    "    if data_file.is_file() and not reoutput:\n",
    "        print('Data file exists, reading...')\n",
    "        new_df = read_df(data_file, have_string=1)\n",
    "    \n",
    "    else:\n",
    "        print('Data file does not exist, creating...') if not reoutput else print('Data file to be overwritten.')\n",
    "    \n",
    "        zh_file = Path(\"bucc_data/zh-en.sample.zh\")\n",
    "        en_file = Path(\"bucc_data/zh-en.sample.en\")\n",
    "        pair_file = Path(\"bucc_data/zh-en.sample.gold\")\n",
    "    \n",
    "        zh_df = read_df(zh_file, names=['ID_zh','Sentence_zh'], header=None, have_string=1)\n",
    "        en_df = read_df(en_file, names=['ID_en','Sentence_en'], header=None, have_string=1)\n",
    "        pair_df = read_df(pair_file, names=['ID_zh','ID_en'], header=None)\n",
    "        \n",
    "        new_df = pair_df.merge(zh_df, 'inner', 'ID_zh')\n",
    "        new_df = new_df.merge(en_df, 'inner', 'ID_en')\n",
    "        save_df(new_df, data_file)\n",
    "        \n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T05:05:44.186725Z",
     "start_time": "2020-07-01T05:05:44.139267Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample_non_pair_data(reoutput=False):\n",
    "    \n",
    "    data_file = Path(\"bucc_data/zh-en.sample.nonpairs\")\n",
    "    \n",
    "    if data_file.is_file() and not reoutput:\n",
    "        print('Data file exists, reading...')\n",
    "        new_df = read_df(data_file, have_string=1)\n",
    "    \n",
    "    else:\n",
    "        print('Data file does not exist, creating...') if not reoutput else print('Data file to be overwritten.')\n",
    "        \n",
    "        new_df = pd.DataFrame(columns=['ID_zh', 'ID_en'])\n",
    "    \n",
    "        bucc_file = \"bucc_data/zh-en.sample.pairs\"\n",
    "        \n",
    "        bucc_df = read_df(bucc_file, have_string=1)\n",
    "        \n",
    "        n = 0\n",
    "        \n",
    "        while n < 257:\n",
    "            x = randrange(257)\n",
    "            y = randrange(257)\n",
    "            if x != y:\n",
    "                zh_id = bucc_df.iloc[y]['ID_zh']\n",
    "                en_id = bucc_df.iloc[x]['ID_en']\n",
    "                new_df.loc[n] = [zh_id, en_id]\n",
    "                n+=1\n",
    "                \n",
    "        zh_file = \"bucc_data/zh-en.sample.zh\"\n",
    "        en_file = \"bucc_data/zh-en.sample.en\"\n",
    "        \n",
    "        zh_df = read_df(zh_file, names=['ID_zh','Sentence_zh'], header=None, have_string=1)\n",
    "        en_df = read_df(en_file, names=['ID_en','Sentence_en'], header=None, have_string=1)\n",
    "        \n",
    "        new_df = new_df.merge(zh_df, 'inner', 'ID_zh')\n",
    "        new_df = new_df.merge(en_df, 'inner', 'ID_en')\n",
    "        save_df(new_df, data_file)\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T05:06:49.068111Z",
     "start_time": "2020-07-01T05:06:49.050120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file exists, reading...\n",
      "File exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_zh</th>\n",
       "      <th>ID_en</th>\n",
       "      <th>Sentence_zh</th>\n",
       "      <th>Sentence_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zh-000000057</td>\n",
       "      <td>en-000008530</td>\n",
       "      <td>在突尼斯的1000万人口中，该国最大报纸的发行量是大约5万份。</td>\n",
       "      <td>In Tunisia, the largest newspaper has a circul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zh-000000137</td>\n",
       "      <td>en-000003060</td>\n",
       "      <td>一些大城市已经开始了示威活动，要求遏制政府官员中的腐败行为。</td>\n",
       "      <td>Demonstrations begin in major cities, calling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zh-000000181</td>\n",
       "      <td>en-000006518</td>\n",
       "      <td>事实上，这就是Urkrise——让20世纪变得面目狰狞的事件。</td>\n",
       "      <td>Indeed, this was the Urkrise – the event that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zh-000000183</td>\n",
       "      <td>en-000007440</td>\n",
       "      <td>卡特里娜飓风的近期效果是把有关伊拉克的新闻报导赶下了电视屏幕和报纸头条。</td>\n",
       "      <td>The short-term effect of Katrina was to drive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zh-000000197</td>\n",
       "      <td>en-000006775</td>\n",
       "      <td>1979年之后，对于增长极限和原子能的恐惧消退了。</td>\n",
       "      <td>After 1979, fears about limits to growth and n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>zh-000008560</td>\n",
       "      <td>en-000005652</td>\n",
       "      <td>从更广义的角度讲，非洲国家需要规范自己的政治和经济秩序。</td>\n",
       "      <td>More broadly, African countries need to put th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>zh-000008566</td>\n",
       "      <td>en-000011992</td>\n",
       "      <td>发展地区弹道导弹防御等联合项目也提高了同盟的可信度。</td>\n",
       "      <td>Credibility is also enhanced by joint projects...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>zh-000008575</td>\n",
       "      <td>en-000003572</td>\n",
       "      <td>类似地，世界卫生组织也大力呼吁加大卫生发展援助力度。</td>\n",
       "      <td>Likewise, the World Health Organization issued...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>zh-000008581</td>\n",
       "      <td>en-000012939</td>\n",
       "      <td>在中国的外汇储备中，有大约8000亿美元投资于欧元资产。</td>\n",
       "      <td>About $800 billion of China’s foreign-exchange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>zh-000008614</td>\n",
       "      <td>en-000002701</td>\n",
       "      <td>新奥尔良市的大部分位于海平面以下，必须由堤坝将大水御于城门之外。</td>\n",
       "      <td>New Orleans is a city mostly below sea level, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_zh         ID_en                           Sentence_zh  \\\n",
       "0    zh-000000057  en-000008530       在突尼斯的1000万人口中，该国最大报纸的发行量是大约5万份。   \n",
       "1    zh-000000137  en-000003060        一些大城市已经开始了示威活动，要求遏制政府官员中的腐败行为。   \n",
       "2    zh-000000181  en-000006518       事实上，这就是Urkrise——让20世纪变得面目狰狞的事件。   \n",
       "3    zh-000000183  en-000007440  卡特里娜飓风的近期效果是把有关伊拉克的新闻报导赶下了电视屏幕和报纸头条。   \n",
       "4    zh-000000197  en-000006775             1979年之后，对于增长极限和原子能的恐惧消退了。   \n",
       "..            ...           ...                                   ...   \n",
       "252  zh-000008560  en-000005652          从更广义的角度讲，非洲国家需要规范自己的政治和经济秩序。   \n",
       "253  zh-000008566  en-000011992            发展地区弹道导弹防御等联合项目也提高了同盟的可信度。   \n",
       "254  zh-000008575  en-000003572            类似地，世界卫生组织也大力呼吁加大卫生发展援助力度。   \n",
       "255  zh-000008581  en-000012939          在中国的外汇储备中，有大约8000亿美元投资于欧元资产。   \n",
       "256  zh-000008614  en-000002701      新奥尔良市的大部分位于海平面以下，必须由堤坝将大水御于城门之外。   \n",
       "\n",
       "                                           Sentence_en  \n",
       "0    In Tunisia, the largest newspaper has a circul...  \n",
       "1    Demonstrations begin in major cities, calling ...  \n",
       "2    Indeed, this was the Urkrise – the event that ...  \n",
       "3    The short-term effect of Katrina was to drive ...  \n",
       "4    After 1979, fears about limits to growth and n...  \n",
       "..                                                 ...  \n",
       "252  More broadly, African countries need to put th...  \n",
       "253  Credibility is also enhanced by joint projects...  \n",
       "254  Likewise, the World Health Organization issued...  \n",
       "255  About $800 billion of China’s foreign-exchange...  \n",
       "256  New Orleans is a city mostly below sea level, ...  \n",
       "\n",
       "[257 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = get_sample_data()\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T05:07:03.055448Z",
     "start_time": "2020-07-01T05:07:02.076260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file to be overwritten.\n",
      "File exists, reading...\n",
      "File exists, reading...\n",
      "File exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_zh</th>\n",
       "      <th>ID_en</th>\n",
       "      <th>Sentence_zh</th>\n",
       "      <th>Sentence_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zh-000007549</td>\n",
       "      <td>en-000012077</td>\n",
       "      <td>莫拉莱斯随即以绝对优势在2005年的总统选举中获胜。</td>\n",
       "      <td>As the efficacy of military power is reduced, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zh-000008073</td>\n",
       "      <td>en-000012077</td>\n",
       "      <td>选举不会是完全自由的，但政府也不能完全操纵它。</td>\n",
       "      <td>As the efficacy of military power is reduced, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zh-000002494</td>\n",
       "      <td>en-000012077</td>\n",
       "      <td>这些补助基于竞争标准发放，资金量取决于是否实现可测量的目标。</td>\n",
       "      <td>As the efficacy of military power is reduced, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zh-000007764</td>\n",
       "      <td>en-000002453</td>\n",
       "      <td>奥巴桑乔和执政的人民党于2003年5月在充满争议的情况下当选。</td>\n",
       "      <td>Its unemployment rate, at just below 5%, is ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zh-000007764</td>\n",
       "      <td>en-000001135</td>\n",
       "      <td>奥巴桑乔和执政的人民党于2003年5月在充满争议的情况下当选。</td>\n",
       "      <td>With the liberalization of global financial ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>zh-000008441</td>\n",
       "      <td>en-000000418</td>\n",
       "      <td>福利开支花费巨大，削减这一开支将是痛苦的。</td>\n",
       "      <td>Government plays a central role in financing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>zh-000001580</td>\n",
       "      <td>en-000011892</td>\n",
       "      <td>实际上，2008年来自化石燃料的二氧化碳排放已经比1990年增长了近40%。</td>\n",
       "      <td>But, most importantly, the invention of coins ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>zh-000005549</td>\n",
       "      <td>en-000011663</td>\n",
       "      <td>卫生援助在拯救生命、改善生活方面是有用的，而且很有用。</td>\n",
       "      <td>Conservatives held a majority of the seats in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>zh-000004000</td>\n",
       "      <td>en-000004248</td>\n",
       "      <td>毕竟法国是欧元区排名第二、世界排名第五的经济大国。</td>\n",
       "      <td>There are no policies to reduce risks in shado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>zh-000008180</td>\n",
       "      <td>en-000013583</td>\n",
       "      <td>孩子们被鼓励学习数学和科学，美国的专业技术则帮助美国完成了这项艰巨的任务。</td>\n",
       "      <td>In the second half of the twentieth century, T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_zh         ID_en                             Sentence_zh  \\\n",
       "0    zh-000007549  en-000012077              莫拉莱斯随即以绝对优势在2005年的总统选举中获胜。   \n",
       "1    zh-000008073  en-000012077                 选举不会是完全自由的，但政府也不能完全操纵它。   \n",
       "2    zh-000002494  en-000012077          这些补助基于竞争标准发放，资金量取决于是否实现可测量的目标。   \n",
       "3    zh-000007764  en-000002453         奥巴桑乔和执政的人民党于2003年5月在充满争议的情况下当选。   \n",
       "4    zh-000007764  en-000001135         奥巴桑乔和执政的人民党于2003年5月在充满争议的情况下当选。   \n",
       "..            ...           ...                                     ...   \n",
       "252  zh-000008441  en-000000418                   福利开支花费巨大，削减这一开支将是痛苦的。   \n",
       "253  zh-000001580  en-000011892  实际上，2008年来自化石燃料的二氧化碳排放已经比1990年增长了近40%。   \n",
       "254  zh-000005549  en-000011663             卫生援助在拯救生命、改善生活方面是有用的，而且很有用。   \n",
       "255  zh-000004000  en-000004248               毕竟法国是欧元区排名第二、世界排名第五的经济大国。   \n",
       "256  zh-000008180  en-000013583   孩子们被鼓励学习数学和科学，美国的专业技术则帮助美国完成了这项艰巨的任务。   \n",
       "\n",
       "                                           Sentence_en  \n",
       "0    As the efficacy of military power is reduced, ...  \n",
       "1    As the efficacy of military power is reduced, ...  \n",
       "2    As the efficacy of military power is reduced, ...  \n",
       "3    Its unemployment rate, at just below 5%, is ha...  \n",
       "4    With the liberalization of global financial ma...  \n",
       "..                                                 ...  \n",
       "252  Government plays a central role in financing t...  \n",
       "253  But, most importantly, the invention of coins ...  \n",
       "254  Conservatives held a majority of the seats in ...  \n",
       "255  There are no policies to reduce risks in shado...  \n",
       "256  In the second half of the twentieth century, T...  \n",
       "\n",
       "[257 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_non_pair_df = get_sample_non_pair_data(1)\n",
    "sample_non_pair_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T05:23:39.780434Z",
     "start_time": "2020-07-01T05:13:02.110705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists, reading...\n",
      "File does not exist.\n",
      "File does not exist.\n",
      "File does not exist.\n",
      "File does not exist.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>char_cost</th>\n",
       "      <th>word_cost</th>\n",
       "      <th>special_cost</th>\n",
       "      <th>pos</th>\n",
       "      <th>laser_proc</th>\n",
       "      <th>laser_noproc</th>\n",
       "      <th>bert_cls_proc</th>\n",
       "      <th>bert_cls_noproc</th>\n",
       "      <th>bert_mean_proc</th>\n",
       "      <th>bert_mean_noproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>737.580423</td>\n",
       "      <td>15.043894</td>\n",
       "      <td>277.395265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.756168</td>\n",
       "      <td>0.839682</td>\n",
       "      <td>0.942113</td>\n",
       "      <td>0.934795</td>\n",
       "      <td>0.912724</td>\n",
       "      <td>0.741520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>622.485195</td>\n",
       "      <td>7.819304</td>\n",
       "      <td>210.027831</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.713394</td>\n",
       "      <td>0.859108</td>\n",
       "      <td>0.885409</td>\n",
       "      <td>0.890294</td>\n",
       "      <td>0.798097</td>\n",
       "      <td>0.691382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>502.889048</td>\n",
       "      <td>16.493954</td>\n",
       "      <td>134.634470</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.700916</td>\n",
       "      <td>0.788735</td>\n",
       "      <td>0.895154</td>\n",
       "      <td>0.911382</td>\n",
       "      <td>0.797245</td>\n",
       "      <td>0.683166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>791.115981</td>\n",
       "      <td>15.043894</td>\n",
       "      <td>267.592490</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.789793</td>\n",
       "      <td>0.819363</td>\n",
       "      <td>0.847412</td>\n",
       "      <td>0.915910</td>\n",
       "      <td>0.754864</td>\n",
       "      <td>0.600001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>380.692784</td>\n",
       "      <td>8.678403</td>\n",
       "      <td>95.249682</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.750441</td>\n",
       "      <td>0.875089</td>\n",
       "      <td>0.937944</td>\n",
       "      <td>0.920843</td>\n",
       "      <td>0.671142</td>\n",
       "      <td>0.661791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>615.189105</td>\n",
       "      <td>7.819304</td>\n",
       "      <td>218.530493</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.667896</td>\n",
       "      <td>0.854644</td>\n",
       "      <td>0.887325</td>\n",
       "      <td>0.927912</td>\n",
       "      <td>0.840848</td>\n",
       "      <td>0.712080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>920.148205</td>\n",
       "      <td>26.120477</td>\n",
       "      <td>435.112015</td>\n",
       "      <td>5.744563</td>\n",
       "      <td>0.761274</td>\n",
       "      <td>0.825573</td>\n",
       "      <td>0.883596</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.787054</td>\n",
       "      <td>0.649296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1</td>\n",
       "      <td>874.507913</td>\n",
       "      <td>46.801859</td>\n",
       "      <td>419.746350</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.712739</td>\n",
       "      <td>0.874674</td>\n",
       "      <td>0.695167</td>\n",
       "      <td>0.937445</td>\n",
       "      <td>0.429903</td>\n",
       "      <td>0.705683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "      <td>698.330681</td>\n",
       "      <td>8.077092</td>\n",
       "      <td>276.597159</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0.794179</td>\n",
       "      <td>0.881399</td>\n",
       "      <td>0.942517</td>\n",
       "      <td>0.943011</td>\n",
       "      <td>0.895734</td>\n",
       "      <td>0.678615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1</td>\n",
       "      <td>613.944781</td>\n",
       "      <td>42.197643</td>\n",
       "      <td>194.915898</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.726837</td>\n",
       "      <td>0.831128</td>\n",
       "      <td>0.657336</td>\n",
       "      <td>0.932062</td>\n",
       "      <td>0.579726</td>\n",
       "      <td>0.658440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pair   char_cost  word_cost  special_cost       pos  laser_proc  \\\n",
       "0       1  737.580423  15.043894    277.395265  1.000000    0.756168   \n",
       "1       1  622.485195   7.819304    210.027831  1.414214    0.713394   \n",
       "2       1  502.889048  16.493954    134.634470  3.605551    0.700916   \n",
       "3       1  791.115981  15.043894    267.592490  1.414214    0.789793   \n",
       "4       1  380.692784   8.678403     95.249682  1.414214    0.750441   \n",
       "..    ...         ...        ...           ...       ...         ...   \n",
       "252     1  615.189105   7.819304    218.530493  2.828427    0.667896   \n",
       "253     1  920.148205  26.120477    435.112015  5.744563    0.761274   \n",
       "254     1  874.507913  46.801859    419.746350  3.000000    0.712739   \n",
       "255     1  698.330681   8.077092    276.597159  2.449490    0.794179   \n",
       "256     1  613.944781  42.197643    194.915898  2.828427    0.726837   \n",
       "\n",
       "     laser_noproc  bert_cls_proc  bert_cls_noproc  bert_mean_proc  \\\n",
       "0        0.839682       0.942113         0.934795        0.912724   \n",
       "1        0.859108       0.885409         0.890294        0.798097   \n",
       "2        0.788735       0.895154         0.911382        0.797245   \n",
       "3        0.819363       0.847412         0.915910        0.754864   \n",
       "4        0.875089       0.937944         0.920843        0.671142   \n",
       "..            ...            ...              ...             ...   \n",
       "252      0.854644       0.887325         0.927912        0.840848   \n",
       "253      0.825573       0.883596         0.898876        0.787054   \n",
       "254      0.874674       0.695167         0.937445        0.429903   \n",
       "255      0.881399       0.942517         0.943011        0.895734   \n",
       "256      0.831128       0.657336         0.932062        0.579726   \n",
       "\n",
       "     bert_mean_noproc  \n",
       "0            0.741520  \n",
       "1            0.691382  \n",
       "2            0.683166  \n",
       "3            0.600001  \n",
       "4            0.661791  \n",
       "..                ...  \n",
       "252          0.712080  \n",
       "253          0.649296  \n",
       "254          0.705683  \n",
       "255          0.678615  \n",
       "256          0.658440  \n",
       "\n",
       "[257 rows x 11 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_output = ensemble(sample_df, \"bucc_data/sample/zh-en.output\", 257, 1)\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T05:32:45.283413Z",
     "start_time": "2020-07-01T05:25:02.623096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist.\n",
      "File does not exist.\n",
      "File does not exist.\n",
      "File does not exist.\n",
      "File does not exist.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>char_cost</th>\n",
       "      <th>word_cost</th>\n",
       "      <th>special_cost</th>\n",
       "      <th>pos</th>\n",
       "      <th>laser_proc</th>\n",
       "      <th>laser_noproc</th>\n",
       "      <th>bert_cls_proc</th>\n",
       "      <th>bert_cls_noproc</th>\n",
       "      <th>bert_mean_proc</th>\n",
       "      <th>bert_mean_noproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>641.468736</td>\n",
       "      <td>26.120477</td>\n",
       "      <td>242.183320</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>0.504368</td>\n",
       "      <td>0.477733</td>\n",
       "      <td>0.848468</td>\n",
       "      <td>0.858453</td>\n",
       "      <td>0.685114</td>\n",
       "      <td>0.439511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>716.068798</td>\n",
       "      <td>16.493954</td>\n",
       "      <td>327.528873</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0.517501</td>\n",
       "      <td>0.503216</td>\n",
       "      <td>0.799139</td>\n",
       "      <td>0.906307</td>\n",
       "      <td>0.677112</td>\n",
       "      <td>0.573194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>557.703778</td>\n",
       "      <td>7.819304</td>\n",
       "      <td>172.517183</td>\n",
       "      <td>4.582576</td>\n",
       "      <td>0.603498</td>\n",
       "      <td>0.597677</td>\n",
       "      <td>0.786354</td>\n",
       "      <td>0.894400</td>\n",
       "      <td>0.671513</td>\n",
       "      <td>0.499250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>336.901020</td>\n",
       "      <td>15.966182</td>\n",
       "      <td>40.080511</td>\n",
       "      <td>3.872983</td>\n",
       "      <td>0.494124</td>\n",
       "      <td>0.455999</td>\n",
       "      <td>0.861551</td>\n",
       "      <td>0.875606</td>\n",
       "      <td>0.742763</td>\n",
       "      <td>0.416285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>949.390537</td>\n",
       "      <td>31.252034</td>\n",
       "      <td>414.360425</td>\n",
       "      <td>4.582576</td>\n",
       "      <td>0.606292</td>\n",
       "      <td>0.556441</td>\n",
       "      <td>0.912340</td>\n",
       "      <td>0.861666</td>\n",
       "      <td>0.711010</td>\n",
       "      <td>0.480268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>1019.091467</td>\n",
       "      <td>57.068192</td>\n",
       "      <td>590.445529</td>\n",
       "      <td>4.690416</td>\n",
       "      <td>0.507537</td>\n",
       "      <td>0.541698</td>\n",
       "      <td>0.766315</td>\n",
       "      <td>0.892111</td>\n",
       "      <td>0.626709</td>\n",
       "      <td>0.483626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0</td>\n",
       "      <td>407.374407</td>\n",
       "      <td>24.422795</td>\n",
       "      <td>60.085454</td>\n",
       "      <td>5.385165</td>\n",
       "      <td>0.434843</td>\n",
       "      <td>0.556170</td>\n",
       "      <td>0.820043</td>\n",
       "      <td>0.859236</td>\n",
       "      <td>0.821027</td>\n",
       "      <td>0.444615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>500.790517</td>\n",
       "      <td>8.077092</td>\n",
       "      <td>162.293225</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0.440960</td>\n",
       "      <td>0.433448</td>\n",
       "      <td>0.804777</td>\n",
       "      <td>0.872671</td>\n",
       "      <td>0.636243</td>\n",
       "      <td>0.470573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0</td>\n",
       "      <td>720.648389</td>\n",
       "      <td>59.338722</td>\n",
       "      <td>312.988416</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>0.551633</td>\n",
       "      <td>0.507879</td>\n",
       "      <td>0.804550</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>0.732837</td>\n",
       "      <td>0.470202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0</td>\n",
       "      <td>568.621615</td>\n",
       "      <td>39.758455</td>\n",
       "      <td>139.867814</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>0.531555</td>\n",
       "      <td>0.517760</td>\n",
       "      <td>0.809622</td>\n",
       "      <td>0.907496</td>\n",
       "      <td>0.625781</td>\n",
       "      <td>0.519295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pair    char_cost  word_cost  special_cost       pos  laser_proc  \\\n",
       "0       0   641.468736  26.120477    242.183320  1.732051    0.504368   \n",
       "1       0   716.068798  16.493954    327.528873  2.449490    0.517501   \n",
       "2       0   557.703778   7.819304    172.517183  4.582576    0.603498   \n",
       "3       0   336.901020  15.966182     40.080511  3.872983    0.494124   \n",
       "4       0   949.390537  31.252034    414.360425  4.582576    0.606292   \n",
       "..    ...          ...        ...           ...       ...         ...   \n",
       "252     0  1019.091467  57.068192    590.445529  4.690416    0.507537   \n",
       "253     0   407.374407  24.422795     60.085454  5.385165    0.434843   \n",
       "254     0   500.790517   8.077092    162.293225  3.316625    0.440960   \n",
       "255     0   720.648389  59.338722    312.988416  3.162278    0.551633   \n",
       "256     0   568.621615  39.758455    139.867814  4.123106    0.531555   \n",
       "\n",
       "     laser_noproc  bert_cls_proc  bert_cls_noproc  bert_mean_proc  \\\n",
       "0        0.477733       0.848468         0.858453        0.685114   \n",
       "1        0.503216       0.799139         0.906307        0.677112   \n",
       "2        0.597677       0.786354         0.894400        0.671513   \n",
       "3        0.455999       0.861551         0.875606        0.742763   \n",
       "4        0.556441       0.912340         0.861666        0.711010   \n",
       "..            ...            ...              ...             ...   \n",
       "252      0.541698       0.766315         0.892111        0.626709   \n",
       "253      0.556170       0.820043         0.859236        0.821027   \n",
       "254      0.433448       0.804777         0.872671        0.636243   \n",
       "255      0.507879       0.804550         0.884800        0.732837   \n",
       "256      0.517760       0.809622         0.907496        0.625781   \n",
       "\n",
       "     bert_mean_noproc  \n",
       "0            0.439511  \n",
       "1            0.573194  \n",
       "2            0.499250  \n",
       "3            0.416285  \n",
       "4            0.480268  \n",
       "..                ...  \n",
       "252          0.483626  \n",
       "253          0.444615  \n",
       "254          0.470573  \n",
       "255          0.470202  \n",
       "256          0.519295  \n",
       "\n",
       "[257 rows x 11 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_non_pair_output = ensemble(sample_non_pair_df, \"bucc_data/sample/non_pairs/zh-en.output\", 257, 0)\n",
    "sample_non_pair_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T05:37:33.654414Z",
     "start_time": "2020-07-01T05:37:33.548716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File overwritten.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>char_cost</th>\n",
       "      <th>word_cost</th>\n",
       "      <th>special_cost</th>\n",
       "      <th>pos</th>\n",
       "      <th>laser_proc</th>\n",
       "      <th>laser_noproc</th>\n",
       "      <th>bert_cls_proc</th>\n",
       "      <th>bert_cls_noproc</th>\n",
       "      <th>bert_mean_proc</th>\n",
       "      <th>bert_mean_noproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>737.580423</td>\n",
       "      <td>15.043894</td>\n",
       "      <td>277.395265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.756168</td>\n",
       "      <td>0.839682</td>\n",
       "      <td>0.942113</td>\n",
       "      <td>0.934795</td>\n",
       "      <td>0.912724</td>\n",
       "      <td>0.741520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>622.485195</td>\n",
       "      <td>7.819304</td>\n",
       "      <td>210.027831</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.713394</td>\n",
       "      <td>0.859108</td>\n",
       "      <td>0.885409</td>\n",
       "      <td>0.890294</td>\n",
       "      <td>0.798097</td>\n",
       "      <td>0.691382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>502.889048</td>\n",
       "      <td>16.493954</td>\n",
       "      <td>134.634470</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.700916</td>\n",
       "      <td>0.788735</td>\n",
       "      <td>0.895154</td>\n",
       "      <td>0.911382</td>\n",
       "      <td>0.797245</td>\n",
       "      <td>0.683166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>791.115981</td>\n",
       "      <td>15.043894</td>\n",
       "      <td>267.592490</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.789793</td>\n",
       "      <td>0.819363</td>\n",
       "      <td>0.847412</td>\n",
       "      <td>0.915910</td>\n",
       "      <td>0.754864</td>\n",
       "      <td>0.600001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>380.692784</td>\n",
       "      <td>8.678403</td>\n",
       "      <td>95.249682</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.750441</td>\n",
       "      <td>0.875089</td>\n",
       "      <td>0.937944</td>\n",
       "      <td>0.920843</td>\n",
       "      <td>0.671142</td>\n",
       "      <td>0.661791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>1019.091467</td>\n",
       "      <td>57.068192</td>\n",
       "      <td>590.445529</td>\n",
       "      <td>4.690416</td>\n",
       "      <td>0.507537</td>\n",
       "      <td>0.541698</td>\n",
       "      <td>0.766315</td>\n",
       "      <td>0.892111</td>\n",
       "      <td>0.626709</td>\n",
       "      <td>0.483626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0</td>\n",
       "      <td>407.374407</td>\n",
       "      <td>24.422795</td>\n",
       "      <td>60.085454</td>\n",
       "      <td>5.385165</td>\n",
       "      <td>0.434843</td>\n",
       "      <td>0.556170</td>\n",
       "      <td>0.820043</td>\n",
       "      <td>0.859236</td>\n",
       "      <td>0.821027</td>\n",
       "      <td>0.444615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>500.790517</td>\n",
       "      <td>8.077092</td>\n",
       "      <td>162.293225</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0.440960</td>\n",
       "      <td>0.433448</td>\n",
       "      <td>0.804777</td>\n",
       "      <td>0.872671</td>\n",
       "      <td>0.636243</td>\n",
       "      <td>0.470573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0</td>\n",
       "      <td>720.648389</td>\n",
       "      <td>59.338722</td>\n",
       "      <td>312.988416</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>0.551633</td>\n",
       "      <td>0.507879</td>\n",
       "      <td>0.804550</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>0.732837</td>\n",
       "      <td>0.470202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0</td>\n",
       "      <td>568.621615</td>\n",
       "      <td>39.758455</td>\n",
       "      <td>139.867814</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>0.531555</td>\n",
       "      <td>0.517760</td>\n",
       "      <td>0.809622</td>\n",
       "      <td>0.907496</td>\n",
       "      <td>0.625781</td>\n",
       "      <td>0.519295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pair    char_cost  word_cost  special_cost       pos  laser_proc  \\\n",
       "0       1   737.580423  15.043894    277.395265  1.000000    0.756168   \n",
       "1       1   622.485195   7.819304    210.027831  1.414214    0.713394   \n",
       "2       1   502.889048  16.493954    134.634470  3.605551    0.700916   \n",
       "3       1   791.115981  15.043894    267.592490  1.414214    0.789793   \n",
       "4       1   380.692784   8.678403     95.249682  1.414214    0.750441   \n",
       "..    ...          ...        ...           ...       ...         ...   \n",
       "252     0  1019.091467  57.068192    590.445529  4.690416    0.507537   \n",
       "253     0   407.374407  24.422795     60.085454  5.385165    0.434843   \n",
       "254     0   500.790517   8.077092    162.293225  3.316625    0.440960   \n",
       "255     0   720.648389  59.338722    312.988416  3.162278    0.551633   \n",
       "256     0   568.621615  39.758455    139.867814  4.123106    0.531555   \n",
       "\n",
       "     laser_noproc  bert_cls_proc  bert_cls_noproc  bert_mean_proc  \\\n",
       "0        0.839682       0.942113         0.934795        0.912724   \n",
       "1        0.859108       0.885409         0.890294        0.798097   \n",
       "2        0.788735       0.895154         0.911382        0.797245   \n",
       "3        0.819363       0.847412         0.915910        0.754864   \n",
       "4        0.875089       0.937944         0.920843        0.671142   \n",
       "..            ...            ...              ...             ...   \n",
       "252      0.541698       0.766315         0.892111        0.626709   \n",
       "253      0.556170       0.820043         0.859236        0.821027   \n",
       "254      0.433448       0.804777         0.872671        0.636243   \n",
       "255      0.507879       0.804550         0.884800        0.732837   \n",
       "256      0.517760       0.809622         0.907496        0.625781   \n",
       "\n",
       "     bert_mean_noproc  \n",
       "0            0.741520  \n",
       "1            0.691382  \n",
       "2            0.683166  \n",
       "3            0.600001  \n",
       "4            0.661791  \n",
       "..                ...  \n",
       "252          0.483626  \n",
       "253          0.444615  \n",
       "254          0.470573  \n",
       "255          0.470202  \n",
       "256          0.519295  \n",
       "\n",
       "[514 rows x 11 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_combined = apply_to_df([sample_output, sample_non_pair_output], \"bucc_data/zh-en.sample.combined\", \"concat\")\n",
    "sample_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Train on training data (1899 rows), Test on sample data (267 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T04:26:04.579209Z",
     "start_time": "2020-07-01T04:26:04.364407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values# check for NaN values\n",
    "\n",
    "bucc_combined[bucc_combined.isnull().any(axis=1)]\n",
    "np.where(np.isnan(bucc_combined))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indivdually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T09:32:15.420072Z",
     "start_time": "2020-07-01T09:32:15.288884Z"
    }
   },
   "outputs": [],
   "source": [
    "def RandomForest(a, b):\n",
    "    x_train = bucc_combined.iloc[:, a:b]\n",
    "    y_train = bucc_combined.iloc[:, 0]\n",
    "\n",
    "    x_test = sample_combined.iloc[:, a:b]\n",
    "    y_test = sample_combined.iloc[:, 0]\n",
    "    \n",
    "    for col_name in x_train.columns:\n",
    "        print(col_name)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "\n",
    "    scores = cross_val_score(clf, x_train, y_train, cv=5, scoring = \"f1\")*100\n",
    "\n",
    "    print(\"Cross-Validation F1 Score: {:.2f}% (+/- {:.2f})\".format(scores.mean(), scores.std() * 2))\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Sample Data F1 Score: {:.2f}%\".format(f1*100))\n",
    "    \n",
    "    \n",
    "    new_df = pd.concat([x_test,y_test == y_pred], axis=1)\n",
    "    new_df= new_df[~new_df['pair']]\n",
    "    \n",
    "    return new_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:36:14.778218Z",
     "start_time": "2020-07-01T06:36:14.747734Z"
    }
   },
   "source": [
    "- Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:48:50.446983Z",
     "start_time": "2020-07-01T06:48:48.111265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_cost\n",
      "word_cost\n",
      "special_cost\n",
      "Cross-Validation F1 Score: 56.38% (+/- 5.30)\n",
      "Sample Data F1 Score: 79.87%\n"
     ]
    }
   ],
   "source": [
    "RandomForest(1,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:50:29.440619Z",
     "start_time": "2020-07-01T06:50:27.121587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "Cross-Validation F1 Score: 59.74% (+/- 4.43)\n",
      "Sample Data F1 Score: 62.79%\n"
     ]
    }
   ],
   "source": [
    "RandomForest(4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:50:44.855057Z",
     "start_time": "2020-07-01T06:50:42.611810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laser_proc\n",
      "laser_noproc\n",
      "Cross-Validation F1 Score: 99.50% (+/- 0.35)\n",
      "Sample Data F1 Score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "RandomForest(5,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:49:54.009691Z",
     "start_time": "2020-07-01T06:49:47.029Z"
    }
   },
   "source": [
    "- BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T09:32:25.693076Z",
     "start_time": "2020-07-01T09:32:21.889722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_cls_proc\n",
      "bert_cls_noproc\n",
      "bert_mean_proc\n",
      "bert_mean_noproc\n",
      "Cross-Validation F1 Score: 92.33% (+/- 1.02)\n",
      "Sample Data F1 Score: 95.34%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_cls_proc</th>\n",
       "      <th>bert_cls_noproc</th>\n",
       "      <th>bert_mean_proc</th>\n",
       "      <th>bert_mean_noproc</th>\n",
       "      <th>pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.885304</td>\n",
       "      <td>0.909413</td>\n",
       "      <td>0.826566</td>\n",
       "      <td>0.515286</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.954386</td>\n",
       "      <td>0.910722</td>\n",
       "      <td>0.814996</td>\n",
       "      <td>0.579358</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.831211</td>\n",
       "      <td>0.930241</td>\n",
       "      <td>0.788583</td>\n",
       "      <td>0.604848</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.769579</td>\n",
       "      <td>0.937763</td>\n",
       "      <td>0.385171</td>\n",
       "      <td>0.595545</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.815299</td>\n",
       "      <td>0.894325</td>\n",
       "      <td>0.865360</td>\n",
       "      <td>0.614066</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.891827</td>\n",
       "      <td>0.926146</td>\n",
       "      <td>0.719151</td>\n",
       "      <td>0.577512</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.860346</td>\n",
       "      <td>0.935513</td>\n",
       "      <td>0.740887</td>\n",
       "      <td>0.601121</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.893284</td>\n",
       "      <td>0.941624</td>\n",
       "      <td>0.711507</td>\n",
       "      <td>0.603914</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.914611</td>\n",
       "      <td>0.928160</td>\n",
       "      <td>0.842773</td>\n",
       "      <td>0.580464</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.914134</td>\n",
       "      <td>0.894631</td>\n",
       "      <td>0.708763</td>\n",
       "      <td>0.590125</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.759186</td>\n",
       "      <td>0.939263</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.589264</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.798664</td>\n",
       "      <td>0.915822</td>\n",
       "      <td>0.689283</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.702891</td>\n",
       "      <td>0.895497</td>\n",
       "      <td>0.556089</td>\n",
       "      <td>0.566562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.693489</td>\n",
       "      <td>0.892787</td>\n",
       "      <td>0.559514</td>\n",
       "      <td>0.598785</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.784591</td>\n",
       "      <td>0.940877</td>\n",
       "      <td>0.643094</td>\n",
       "      <td>0.598378</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.783759</td>\n",
       "      <td>0.892420</td>\n",
       "      <td>0.643243</td>\n",
       "      <td>0.587709</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.798542</td>\n",
       "      <td>0.927403</td>\n",
       "      <td>0.687298</td>\n",
       "      <td>0.583625</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.913368</td>\n",
       "      <td>0.924457</td>\n",
       "      <td>0.815583</td>\n",
       "      <td>0.594896</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.890358</td>\n",
       "      <td>0.943170</td>\n",
       "      <td>0.683171</td>\n",
       "      <td>0.640325</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.829326</td>\n",
       "      <td>0.926028</td>\n",
       "      <td>0.664441</td>\n",
       "      <td>0.600710</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.894313</td>\n",
       "      <td>0.907406</td>\n",
       "      <td>0.817581</td>\n",
       "      <td>0.634930</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.907226</td>\n",
       "      <td>0.904736</td>\n",
       "      <td>0.844205</td>\n",
       "      <td>0.600702</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.842771</td>\n",
       "      <td>0.924308</td>\n",
       "      <td>0.718011</td>\n",
       "      <td>0.590415</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.848119</td>\n",
       "      <td>0.909125</td>\n",
       "      <td>0.762505</td>\n",
       "      <td>0.605598</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.706437</td>\n",
       "      <td>0.901934</td>\n",
       "      <td>0.509438</td>\n",
       "      <td>0.640166</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bert_cls_proc  bert_cls_noproc  bert_mean_proc  bert_mean_noproc   pair\n",
       "220       0.885304         0.909413        0.826566          0.515286  False\n",
       "5         0.954386         0.910722        0.814996          0.579358  False\n",
       "8         0.831211         0.930241        0.788583          0.604848  False\n",
       "18        0.769579         0.937763        0.385171          0.595545  False\n",
       "24        0.815299         0.894325        0.865360          0.614066  False\n",
       "30        0.891827         0.926146        0.719151          0.577512  False\n",
       "33        0.860346         0.935513        0.740887          0.601121  False\n",
       "34        0.893284         0.941624        0.711507          0.603914  False\n",
       "38        0.914611         0.928160        0.842773          0.580464  False\n",
       "74        0.914134         0.894631        0.708763          0.590125  False\n",
       "94        0.759186         0.939263        0.583200          0.589264  False\n",
       "103       0.798664         0.915822        0.689283          0.644737  False\n",
       "110       0.702891         0.895497        0.556089          0.566562  False\n",
       "111       0.693489         0.892787        0.559514          0.598785  False\n",
       "135       0.784591         0.940877        0.643094          0.598378  False\n",
       "185       0.783759         0.892420        0.643243          0.587709  False\n",
       "211       0.798542         0.927403        0.687298          0.583625  False\n",
       "214       0.913368         0.924457        0.815583          0.594896  False\n",
       "220       0.890358         0.943170        0.683171          0.640325  False\n",
       "221       0.829326         0.926028        0.664441          0.600710  False\n",
       "233       0.894313         0.907406        0.817581          0.634930  False\n",
       "241       0.907226         0.904736        0.844205          0.600702  False\n",
       "242       0.842771         0.924308        0.718011          0.590415  False\n",
       "244       0.848119         0.909125        0.762505          0.605598  False\n",
       "245       0.706437         0.901934        0.509438          0.640166  False"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest(7,11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble (only pairs training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T06:34:59.435400Z",
     "start_time": "2020-07-01T06:34:45.374756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Score: 100.00% (+/- 0.00)\n",
      "Sample Data F1 Score: 66.67%\n"
     ]
    }
   ],
   "source": [
    "x_train = bucc_output.iloc[:, 1:]\n",
    "y_train = bucc_output.iloc[:, 0]\n",
    "\n",
    "x_test = sample_combined.iloc[:, 1:]\n",
    "y_test = sample_combined.iloc[:, 0]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=5, scoring = \"f1\")*100\n",
    "\n",
    "print(\"Cross-Validation F1 Score: {:.2f}% (+/- {:.2f})\".format(scores.mean(), scores.std() * 2))\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Sample Data F1 Score: {:.2f}%\".format(f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble (combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T09:13:17.045863Z",
     "start_time": "2020-07-01T09:13:08.207296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Score: 99.47% (+/- 0.53)\n",
      "Sample Data F1 Score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "x_train = bucc_combined.iloc[:, 1:]\n",
    "y_train = bucc_combined.iloc[:, 0]\n",
    "\n",
    "x_test = sample_combined.iloc[:, 1:]\n",
    "y_test = sample_combined.iloc[:, 0]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=5, scoring = \"f1\")*100\n",
    "\n",
    "print(\"Cross-Validation F1 Score: {:.2f}% (+/- {:.2f})\".format(scores.mean(), scores.std() * 2))\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Sample Data F1 Score: {:.2f}%\".format(f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T09:19:59.526704Z",
     "start_time": "2020-07-01T09:19:57.434491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Score: 99.53% (+/- 0.78)\n",
      "Train-Test-Split F1 Score: 99.49%\n"
     ]
    }
   ],
   "source": [
    "x = bucc_combined.iloc[:, 1:]\n",
    "y = bucc_combined.iloc[:, 0]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=5, scoring = \"f1\")*100\n",
    "\n",
    "print(\"Cross-Validation F1 Score: {:.2f}% (+/- {:.2f})\".format(scores.mean(), scores.std() * 2))\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Train-Test-Split F1 Score: {:.2f}%\".format(f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T09:20:01.807356Z",
     "start_time": "2020-07-01T09:20:01.771541Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-8fa4b534fbfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2938\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3000\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3001\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3636\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3638\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Length of values does not match length of index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "x_test['pred']=[y_test == y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T09:20:17.076718Z",
     "start_time": "2020-07-01T09:20:17.069698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1070    True\n",
       " 354     True\n",
       " 881     True\n",
       " 196     True\n",
       " 1619    True\n",
       "         ... \n",
       " 419     True\n",
       " 322     True\n",
       " 978     True\n",
       " 1610    True\n",
       " 1418    True\n",
       " Name: pair, Length: 950, dtype: bool]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T09:30:47.860699Z",
     "start_time": "2020-07-01T09:30:46.673228Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1658, 12), indices imply (1470, 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-92a341b28e01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_pd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pred\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnew_pd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m--> 497\u001b[1;33m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m             )\n\u001b[0;32m    499\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   2025\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2027\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m                 \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m             raise AssertionError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1692\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mblock_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1694\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (1658, 12), indices imply (1470, 12)"
     ]
    }
   ],
   "source": [
    "new_pd = pd.concat([x_test,y_test, pd.Series(y_pred, name=\"pred\")], axis=1)\n",
    "new_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T09:27:39.620027Z",
     "start_time": "2020-07-01T09:27:39.495803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_cost</th>\n",
       "      <th>word_cost</th>\n",
       "      <th>special_cost</th>\n",
       "      <th>pos</th>\n",
       "      <th>laser_proc</th>\n",
       "      <th>laser_noproc</th>\n",
       "      <th>bert_cls_proc</th>\n",
       "      <th>bert_cls_noproc</th>\n",
       "      <th>bert_mean_proc</th>\n",
       "      <th>bert_mean_noproc</th>\n",
       "      <th>pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>693.721982</td>\n",
       "      <td>14.637722</td>\n",
       "      <td>231.888405</td>\n",
       "      <td>5.744563</td>\n",
       "      <td>0.698821</td>\n",
       "      <td>0.646563</td>\n",
       "      <td>0.902548</td>\n",
       "      <td>0.881269</td>\n",
       "      <td>0.825414</td>\n",
       "      <td>0.620809</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>934.377036</td>\n",
       "      <td>75.583699</td>\n",
       "      <td>425.617604</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>0.615988</td>\n",
       "      <td>0.604749</td>\n",
       "      <td>0.858124</td>\n",
       "      <td>0.940161</td>\n",
       "      <td>0.691959</td>\n",
       "      <td>0.546335</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>653.195083</td>\n",
       "      <td>8.678403</td>\n",
       "      <td>261.926892</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.563388</td>\n",
       "      <td>0.573315</td>\n",
       "      <td>0.846855</td>\n",
       "      <td>0.916289</td>\n",
       "      <td>0.688008</td>\n",
       "      <td>0.579986</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>774.726146</td>\n",
       "      <td>57.068192</td>\n",
       "      <td>329.301192</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>0.660858</td>\n",
       "      <td>0.787891</td>\n",
       "      <td>0.928913</td>\n",
       "      <td>0.621074</td>\n",
       "      <td>0.654007</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1063.187621</td>\n",
       "      <td>43.587028</td>\n",
       "      <td>541.817874</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>0.647291</td>\n",
       "      <td>0.689850</td>\n",
       "      <td>0.979321</td>\n",
       "      <td>0.922198</td>\n",
       "      <td>0.964613</td>\n",
       "      <td>0.612956</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        char_cost  word_cost  special_cost       pos  laser_proc  \\\n",
       "1113   693.721982  14.637722    231.888405  5.744563    0.698821   \n",
       "1427   934.377036  75.583699    425.617604  3.464102    0.615988   \n",
       "712    653.195083   8.678403    261.926892  3.000000    0.563388   \n",
       "1410   774.726146  57.068192    329.301192  2.645751    0.628975   \n",
       "105   1063.187621  43.587028    541.817874  4.123106    0.647291   \n",
       "\n",
       "      laser_noproc  bert_cls_proc  bert_cls_noproc  bert_mean_proc  \\\n",
       "1113      0.646563       0.902548         0.881269        0.825414   \n",
       "1427      0.604749       0.858124         0.940161        0.691959   \n",
       "712       0.573315       0.846855         0.916289        0.688008   \n",
       "1410      0.660858       0.787891         0.928913        0.621074   \n",
       "105       0.689850       0.979321         0.922198        0.964613   \n",
       "\n",
       "      bert_mean_noproc   pair  \n",
       "1113          0.620809  False  \n",
       "1427          0.546335  False  \n",
       "712           0.579986  False  \n",
       "1410          0.654007  False  \n",
       "105           0.612956  False  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([x_test,y_test == y_pred], axis=1)\n",
    "new_pd[~new_pd['pair']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
