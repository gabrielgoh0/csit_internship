{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:29:35.019738Z",
     "start_time": "2020-06-05T10:29:23.523426Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Word Embeddings ##\n",
    "# LASER Embeddings pre-trained model\n",
    "\n",
    "import bucc_proc as bp\n",
    "import importlib\n",
    "importlib.reload(bp)\n",
    "from laserembeddings import Laser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:31:12.722381Z",
     "start_time": "2020-06-05T10:31:12.698445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of              ID_zh         ID_en                             Sentence_zh  \\\n",
       "0     zh-000000033  en-000005983               1989年以前，全球经济包含大约8亿到10亿人口。   \n",
       "1     zh-000000231  en-000047360        今日全球面临的威胁是超民族的，因此也必须采取超民族的方式来应对。   \n",
       "2     zh-000000272  en-000027140                   欧盟移民政策的硬伤还有一个不太显著的方面。   \n",
       "3     zh-000000438  en-000065621           只有让民粹主义服务于自由主义改革，政府才能取得长久的利益。   \n",
       "4     zh-000000639  en-000005169       但社会民主派必须理解为何示威的发展会独立于现有的有组织中左翼政治。   \n",
       "...            ...           ...                                     ...   \n",
       "1848  zh-000094590  en-000013258         事件发生后当局在尚未进行调查的情况下就匆匆掩埋了出事列车残骸。   \n",
       "1849  zh-000094593  en-000061419             北方拥有丰富的自然资源，就连电力也是从北方输送到南方。   \n",
       "1850  zh-000094607  en-000039373                如果利率为3%，那么年税收额必须增加15亿美元。   \n",
       "1851  zh-000094611  en-000003807           五年前，叙利亚北部边陲城镇享受着土耳其高速经济增长的红利。   \n",
       "1852  zh-000094633  en-000083972  在过去的一个世纪中，我们的世界发生了翻天覆地的变化——技术是其中的重要原因。   \n",
       "\n",
       "                                            Sentence_en  \n",
       "0     Until 1989, the global market encompassed betw...  \n",
       "1     The threats facing the world today are suprana...  \n",
       "2     There is another, less obvious, reason why the...  \n",
       "3     Only if populism is put at the service of libe...  \n",
       "4     But social democrats must understand why the p...  \n",
       "...                                                 ...  \n",
       "1848  The wrecked body of the ruined train was burie...  \n",
       "1849  Natural resources were abundant in the North, ...  \n",
       "1850  If it is 3%, the required increase in annual t...  \n",
       "1851  Five years ago, Syria’s northern border towns ...  \n",
       "1852  Our world has changed vastly over the past cen...  \n",
       "\n",
       "[1853 rows x 4 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = bp.get_merge()\n",
    "en_proc = bp.en_proc\n",
    "zh_proc = bp.zh_proc\n",
    "cosine_similarity = bp.cosine_similarity\n",
    "new_df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:31:22.749407Z",
     "start_time": "2020-06-05T10:31:22.743420Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vector(sentence,lang=\"en\",proc=True):\n",
    "    if proc==True:\n",
    "        if lang == \"en\":\n",
    "            s = ' '.join(en_proc(sentence))\n",
    "        elif lang == \"zh\":\n",
    "            s = ' '.join(zh_proc(sentence))\n",
    "        else:\n",
    "            print('No proccessing method for this language.')\n",
    "    else:\n",
    "        s = sentence\n",
    "    return laser.embed_sentences(s, lang=[lang])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:31:28.436782Z",
     "start_time": "2020-06-05T10:31:24.129456Z"
    }
   },
   "outputs": [],
   "source": [
    "laser = Laser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T06:48:29.033790Z",
     "start_time": "2020-06-05T06:44:05.307162Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(n, x=0, proc=True):\n",
    "    string = ''\n",
    "    \n",
    "    tp=0 #true positives\n",
    "    fn=0 #false negatives\n",
    "    \n",
    "    for i in range(x, n):\n",
    "        en_vect = get_vector(new_df.iloc[i]['Sentence_en'], proc=proc)\n",
    "        zh_vect = get_vector(new_df.iloc[i]['Sentence_zh'], lang=\"zh\", proc=proc)\n",
    "        this_value = cosine_similarity(en_vect, zh_vect)\n",
    "        \n",
    "        if i == x:\n",
    "            most = this_value\n",
    "            least = this_value\n",
    "            most_i = x\n",
    "            least_i = x\n",
    "            \n",
    "        elif most <= this_value:\n",
    "            most = this_value\n",
    "            most_i = i\n",
    "            \n",
    "        elif least >= this_value:\n",
    "            least = this_value\n",
    "            least_i = i\n",
    "        \n",
    "        if this_value>0.7:\n",
    "            j = 'YES'\n",
    "            tp+=1\n",
    "        else:\n",
    "            j = 'NO'\n",
    "            fn+=1\n",
    "        \n",
    "        string = string + str(i) +  \"\\t{:.2f}\".format(round(this_value,2)) + '\\t' + j + '\\n'\n",
    "    \n",
    "    \n",
    "    string = 'Line\\tSimilarity\\tPair\\n' + string\n",
    "    string = 'Most:' + str(most_i) + \"\\t{:.2f}\".format(most) + '\\n' + string\n",
    "    string = 'Least:' + str(least_i) + \"\\t{:.2f}\".format(least) + '\\n' + string\n",
    "    string = 'Size:' + str(n-x) + '\\tTP:' + str(tp) + '\\tFN:'+ str(fn) + '\\tAccuracy:' + str(round(tp/(n-x)*100,1))+'%\\n' + string\n",
    "    return string\n",
    "            \n",
    "def str_to_txt(filename, string):\n",
    "    with open(filename,'w', encoding='utf-8') as file:\n",
    "        file.write(string)\n",
    "                \n",
    "#str_to_txt('laser_output.txt',test(1853))\n",
    "#str_to_txt('laser_output_np.txt',test(1853, proc=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T06:55:54.462311Z",
     "start_time": "2020-06-05T06:48:29.033790Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "\n",
    "def negatest(t,n=0, proc=True):\n",
    "    string = ''\n",
    "    \n",
    "    tn=0 #true negatives\n",
    "    fp=0 #false positives\n",
    "    \n",
    "    start_n = n\n",
    "    \n",
    "    while t > n:\n",
    "        x = randrange(1853)\n",
    "        y = randrange(1853)\n",
    "        if x != y:\n",
    "            en_vect = get_vector(new_df.iloc[x]['Sentence_en'], proc=proc)\n",
    "            zh_vect = get_vector(new_df.iloc[y]['Sentence_zh'], lang=\"zh\", proc=proc)\n",
    "            this_value = cosine_similarity(en_vect, zh_vect)\n",
    "            \n",
    "            x = str(x)\n",
    "            y = str(y)\n",
    "            \n",
    "            if n == start_n:\n",
    "                most = this_value\n",
    "                least = this_value\n",
    "                most_i = (x,y)\n",
    "                least_i = (x,y)\n",
    "            \n",
    "            elif most <= this_value:\n",
    "                most = this_value\n",
    "                most_i = (x,y)\n",
    "            \n",
    "            elif least >= this_value:\n",
    "                least = this_value\n",
    "                least_i = (x,y)\n",
    "        \n",
    "            \n",
    "            if this_value>0.7:\n",
    "                j = 'YES'\n",
    "                fp+=1\n",
    "            else:\n",
    "                j = 'NO'\n",
    "                tn+=1\n",
    "            \n",
    "            string = string + '\\t' + x + '\\t' + y +  \"\\t{:.2f}\".format(round(this_value,2)) + '\\t' + j + '\\n'\n",
    "            n+=1\n",
    "    \n",
    "    \n",
    "    string = 'Line_en\\tLine_zh\\tSimilarity\\tPair\\n' + string\n",
    "    string = 'Most:' + '\\t'.join(most_i) + \"\\t{:.2f}\".format(most) + '\\n' + string\n",
    "    string = 'Least:' + '\\t'.join(least_i) + \"\\t{:.2f}\".format(least) + '\\n' + string\n",
    "    string = 'Size:' + str(t-start_n) + '\\tTN:' + str(tn) + '\\tFP:'+ str(fp) + '\\tAccuracy:' + str(round(tn/(t-start_n)*100,1))+'%\\n' + string\n",
    "    return string\n",
    "            \n",
    "        \n",
    "#str_to_txt('laser_output_negative.txt',negatest(1853))\n",
    "#str_to_txt('laser_output_negative_np.txt',negatest(1853, proc=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T09:24:31.863089Z",
     "start_time": "2020-06-01T09:24:31.858101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millions of people around the world will live, or die, depending on what these governments decide in December. \t 各国政府在11月的决定将影响数百万人的生死。\n"
     ]
    }
   ],
   "source": [
    "# Setting requirement to 0.7 similarity to exclude false positives\n",
    "# Line 9 is a problem, similarity close to non-pair sentences\n",
    "print(new_df.iloc[9]['Sentence_en'],'\\t',new_df.iloc[9]['Sentence_zh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:31:53.969536Z",
     "start_time": "2020-06-05T10:31:43.600395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: 0 \tSim: 0.9 \tPair: YES\n",
      "Line: 1 \tSim: 0.85 \tPair: YES\n",
      "Line: 2 \tSim: 0.74 \tPair: YES\n",
      "Line: 3 \tSim: 0.87 \tPair: YES\n",
      "Line: 4 \tSim: 0.88 \tPair: YES\n",
      "Line: 5 \tSim: 0.87 \tPair: YES\n",
      "Line: 6 \tSim: 0.86 \tPair: YES\n",
      "Line: 7 \tSim: 0.87 \tPair: YES\n",
      "Line: 8 \tSim: 0.82 \tPair: YES\n",
      "Line: 9 \tSim: 0.67 \tPair: NO\n",
      "Line: 10 \tSim: 0.93 \tPair: YES\n",
      "Line: 11 \tSim: 0.83 \tPair: YES\n",
      "Line: 12 \tSim: 0.81 \tPair: YES\n",
      "Line: 13 \tSim: 0.89 \tPair: YES\n",
      "Line: 14 \tSim: 0.86 \tPair: YES\n",
      "Line: 15 \tSim: 0.88 \tPair: YES\n",
      "Line: 16 \tSim: 0.86 \tPair: YES\n",
      "Line: 17 \tSim: 0.82 \tPair: YES\n",
      "Line: 18 \tSim: 0.89 \tPair: YES\n",
      "Line: 19 \tSim: 0.9 \tPair: YES\n",
      "Line: 20 \tSim: 0.89 \tPair: YES\n",
      "Line: 21 \tSim: 0.84 \tPair: YES\n",
      "Line: 22 \tSim: 0.86 \tPair: YES\n",
      "Line: 23 \tSim: 0.93 \tPair: YES\n",
      "Line: 24 \tSim: 0.9 \tPair: YES\n",
      "Line: 25 \tSim: 0.88 \tPair: YES\n",
      "Line: 26 \tSim: 0.88 \tPair: YES\n",
      "Line: 27 \tSim: 0.83 \tPair: YES\n",
      "Line: 28 \tSim: 0.92 \tPair: YES\n",
      "Line: 29 \tSim: 0.91 \tPair: YES\n",
      "Line: 30 \tSim: 0.84 \tPair: YES\n",
      "Line: 31 \tSim: 0.92 \tPair: YES\n",
      "Line: 32 \tSim: 0.86 \tPair: YES\n",
      "Line: 33 \tSim: 0.86 \tPair: YES\n",
      "Line: 34 \tSim: 0.9 \tPair: YES\n",
      "Line: 35 \tSim: 0.91 \tPair: YES\n",
      "Line: 36 \tSim: 0.94 \tPair: YES\n",
      "Line: 37 \tSim: 0.75 \tPair: YES\n",
      "Line: 38 \tSim: 0.8 \tPair: YES\n",
      "Line: 39 \tSim: 0.89 \tPair: YES\n",
      "Line: 40 \tSim: 0.93 \tPair: YES\n",
      "Line: 41 \tSim: 0.92 \tPair: YES\n",
      "Line: 42 \tSim: 0.78 \tPair: YES\n",
      "Line: 43 \tSim: 0.9 \tPair: YES\n",
      "Line: 44 \tSim: 0.88 \tPair: YES\n",
      "Line: 45 \tSim: 0.89 \tPair: YES\n",
      "Line: 46 \tSim: 0.88 \tPair: YES\n",
      "Line: 47 \tSim: 0.9 \tPair: YES\n",
      "Line: 48 \tSim: 0.86 \tPair: YES\n",
      "Line: 49 \tSim: 0.79 \tPair: YES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36, 0.9389751, 'Success Rate:98.0%')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing without proccessing text\n",
    "\n",
    "def test_no_proc(n, x=0):\n",
    "    k=0\n",
    "    j=''\n",
    "    for i in range(x, n):\n",
    "        this_value = cosine_similarity( get_vector(new_df.iloc[i]['Sentence_en'], proc=False), get_vector(new_df.iloc[i]['Sentence_zh'],lang=\"zh\",proc=False) )\n",
    "        if i == x:\n",
    "            most = this_value\n",
    "            s_index = 0\n",
    "        elif most <= this_value:\n",
    "            most = this_value\n",
    "            s_index = i\n",
    "        \n",
    "        if this_value>0.7:\n",
    "            j='YES'\n",
    "            k+=1\n",
    "        else:\n",
    "            j='NO'\n",
    "        \n",
    "        print('Line:',i,'\\tSim:',round(this_value,2), '\\tPair:', j)\n",
    "        \n",
    "    return s_index,most, 'Success Rate:'+str(round(k/(n-x)*100,1))+'%'\n",
    "            \n",
    "\n",
    "    \n",
    "test_no_proc(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T09:36:54.186949Z",
     "start_time": "2020-06-01T09:36:46.534831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line EN: 463 \tLine ZH: 724 \tSim: 0.54 \tPair: NO\n",
      "Line EN: 749 \tLine ZH: 1125 \tSim: 0.52 \tPair: NO\n",
      "Line EN: 996 \tLine ZH: 1843 \tSim: 0.51 \tPair: NO\n",
      "Line EN: 503 \tLine ZH: 495 \tSim: 0.5 \tPair: NO\n",
      "Line EN: 1527 \tLine ZH: 963 \tSim: 0.59 \tPair: NO\n",
      "Line EN: 311 \tLine ZH: 186 \tSim: 0.5 \tPair: NO\n",
      "Line EN: 519 \tLine ZH: 997 \tSim: 0.49 \tPair: NO\n",
      "Line EN: 361 \tLine ZH: 1120 \tSim: 0.54 \tPair: NO\n",
      "Line EN: 273 \tLine ZH: 1662 \tSim: 0.53 \tPair: NO\n",
      "Line EN: 624 \tLine ZH: 1826 \tSim: 0.54 \tPair: NO\n",
      "Line EN: 916 \tLine ZH: 1138 \tSim: 0.5 \tPair: NO\n",
      "Line EN: 1612 \tLine ZH: 1274 \tSim: 0.52 \tPair: NO\n",
      "Line EN: 712 \tLine ZH: 1277 \tSim: 0.5 \tPair: NO\n",
      "Line EN: 529 \tLine ZH: 18 \tSim: 0.52 \tPair: NO\n",
      "Line EN: 643 \tLine ZH: 604 \tSim: 0.52 \tPair: NO\n",
      "Line EN: 98 \tLine ZH: 1669 \tSim: 0.45 \tPair: NO\n",
      "Line EN: 727 \tLine ZH: 773 \tSim: 0.49 \tPair: NO\n",
      "Line EN: 434 \tLine ZH: 648 \tSim: 0.52 \tPair: NO\n",
      "Line EN: 423 \tLine ZH: 1614 \tSim: 0.52 \tPair: NO\n",
      "Line EN: 455 \tLine ZH: 1688 \tSim: 0.55 \tPair: NO\n",
      "Line EN: 1385 \tLine ZH: 1040 \tSim: 0.5 \tPair: NO\n",
      "Line EN: 922 \tLine ZH: 1720 \tSim: 0.48 \tPair: NO\n",
      "Line EN: 1712 \tLine ZH: 1236 \tSim: 0.53 \tPair: NO\n",
      "Line EN: 1545 \tLine ZH: 1459 \tSim: 0.61 \tPair: NO\n",
      "Line EN: 1105 \tLine ZH: 1107 \tSim: 0.51 \tPair: NO\n",
      "Line EN: 738 \tLine ZH: 1221 \tSim: 0.57 \tPair: NO\n",
      "Line EN: 1519 \tLine ZH: 1394 \tSim: 0.56 \tPair: NO\n",
      "Line EN: 1158 \tLine ZH: 1404 \tSim: 0.55 \tPair: NO\n",
      "Line EN: 1009 \tLine ZH: 1642 \tSim: 0.55 \tPair: NO\n",
      "Line EN: 923 \tLine ZH: 272 \tSim: 0.57 \tPair: NO\n",
      "Line EN: 1583 \tLine ZH: 939 \tSim: 0.51 \tPair: NO\n",
      "Line EN: 288 \tLine ZH: 188 \tSim: 0.58 \tPair: NO\n",
      "Line EN: 155 \tLine ZH: 1672 \tSim: 0.55 \tPair: NO\n",
      "Line EN: 116 \tLine ZH: 1799 \tSim: 0.55 \tPair: NO\n",
      "Line EN: 412 \tLine ZH: 328 \tSim: 0.51 \tPair: NO\n",
      "Line EN: 114 \tLine ZH: 454 \tSim: 0.54 \tPair: NO\n",
      "Line EN: 428 \tLine ZH: 106 \tSim: 0.52 \tPair: NO\n",
      "Line EN: 441 \tLine ZH: 1614 \tSim: 0.52 \tPair: NO\n",
      "Line EN: 682 \tLine ZH: 754 \tSim: 0.46 \tPair: NO\n",
      "Line EN: 491 \tLine ZH: 1463 \tSim: 0.54 \tPair: NO\n",
      "Line EN: 981 \tLine ZH: 671 \tSim: 0.56 \tPair: NO\n",
      "Line EN: 276 \tLine ZH: 858 \tSim: 0.57 \tPair: NO\n",
      "Line EN: 326 \tLine ZH: 124 \tSim: 0.47 \tPair: NO\n",
      "Line EN: 926 \tLine ZH: 733 \tSim: 0.65 \tPair: NO\n",
      "Line EN: 655 \tLine ZH: 1577 \tSim: 0.51 \tPair: NO\n",
      "Line EN: 527 \tLine ZH: 1680 \tSim: 0.54 \tPair: NO\n",
      "Line EN: 1469 \tLine ZH: 702 \tSim: 0.5 \tPair: NO\n",
      "Line EN: 826 \tLine ZH: 380 \tSim: 0.47 \tPair: NO\n",
      "Line EN: 152 \tLine ZH: 599 \tSim: 0.52 \tPair: NO\n",
      "Line EN: 1560 \tLine ZH: 238 \tSim: 0.54 \tPair: NO\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "t = 50\n",
    "n = 0\n",
    "\n",
    "while t > n:\n",
    "    x = randrange(1853)\n",
    "    y = randrange(1853)\n",
    "    if x != y:\n",
    "        z = cosine_similarity( get_vector(new_df.iloc[x]['Sentence_en'], proc=False), get_vector(new_df.iloc[y]['Sentence_zh'],lang=\"zh\", proc=False) )\n",
    "        zz = 'YES' if z>0.7 else 'NO'\n",
    "    \n",
    "        print('Line EN:',x,'\\tLine ZH:',y,'\\tSim:',round(z,2), '\\tPair:', zz)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not processing text is better as stopwords are kept => more information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Positive (is a pair and classified correct)\n",
    "# False Positive (is actually not a pair but classified wrong)\n",
    "# True Negative (is not a pair and classified correct)\n",
    "# False Negative (is actually a pair but classified wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T09:37:49.327631Z",
     "start_time": "2020-06-05T09:37:49.273459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without processing into bag of words:\n",
      "Precision: 100.0 %\n",
      "Recall: 98.8 %\n",
      "F1 Score: 99.4 %\n",
      "\n",
      "With processing into bag of words:\n",
      "Precision: 100.0 %\n",
      "Recall: 70.1 %\n",
      "F1 Score: 82.4 %\n"
     ]
    }
   ],
   "source": [
    "# Set 0.7 sim as classifying line\n",
    "\n",
    "#np (no proc)\n",
    "\n",
    "tn = 1853\n",
    "fp = 0\n",
    "tp = 1831\n",
    "fn = 22\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*(precision*recall/(precision+recall))\n",
    "\n",
    "print('Without processing into bag of words:')\n",
    "print('Precision:', round(precision*100,1), '%')\n",
    "print('Recall:', round(recall*100,1), '%')\n",
    "print('F1 Score:', round(f1*100,1), '%')\n",
    "\n",
    "\n",
    "# with proc\n",
    "tn = 1853\n",
    "fp = 0\n",
    "tp = 1299\n",
    "fn = 554\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*(precision*recall/(precision+recall))\n",
    "\n",
    "print('\\nWith processing into bag of words:')\n",
    "print('Precision:', round(precision*100,1), '%')\n",
    "print('Recall:', round(recall*100,1), '%')\n",
    "print('F1 Score:', round(f1*100,1), '%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
