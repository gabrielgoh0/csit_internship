{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T07:42:28.358809Z",
     "start_time": "2020-06-18T07:42:26.509129Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Part-Of-Speech Tagging \n",
    "# http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.4921&rep=rep1&type=pdf\n",
    "\n",
    "# Using Stanford NLP Stanza and Jieba\n",
    "# https://github.com/stanfordnlp/stanza/\n",
    "# https://stanfordnlp.github.io/stanza/data_objects.html#word\n",
    "\n",
    "import bucc_proc as bp\n",
    "\n",
    "np = bp.np # Numpy\n",
    "pd = bp.pd # Pandas\n",
    "Path = bp.Path # Pathlib\n",
    "from random import randrange\n",
    "\n",
    "import importlib\n",
    "importlib.reload(bp)\n",
    "\n",
    "import jieba\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T03:20:51.504069Z",
     "start_time": "2020-06-18T03:18:47.136793Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 1.47MB/s]\n",
      "2020-06-18 11:18:48 INFO: Downloading default packages for language: en (English)...\n",
      "2020-06-18 11:18:52 INFO: File exists: C:\\Users\\gabri\\stanza_resources\\en\\default.zip.\n",
      "2020-06-18 11:19:33 INFO: Finished downloading models and saved to C:\\Users\\gabri\\stanza_resources.\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 1.03MB/s]\n",
      "2020-06-18 11:19:34 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2020-06-18 11:19:34 INFO: Downloading default packages for language: zh-hans (Simplified_Chinese)...\n",
      "2020-06-18 11:20:02 INFO: File exists: C:\\Users\\gabri\\stanza_resources\\zh-hans\\default.zip.\n",
      "2020-06-18 11:20:51 INFO: Finished downloading models and saved to C:\\Users\\gabri\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('en')\n",
    "stanza.download('zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T03:21:15.269502Z",
     "start_time": "2020-06-18T03:20:51.584894Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-18 11:20:51 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | ewt       |\n",
      "| pos       | ewt       |\n",
      "| lemma     | ewt       |\n",
      "| depparse  | ewt       |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-06-18 11:20:52 INFO: Use device: cpu\n",
      "2020-06-18 11:20:52 INFO: Loading: tokenize\n",
      "2020-06-18 11:20:53 INFO: Loading: pos\n",
      "2020-06-18 11:21:00 INFO: Loading: lemma\n",
      "2020-06-18 11:21:01 INFO: Loading: depparse\n",
      "2020-06-18 11:21:04 INFO: Loading: ner\n",
      "2020-06-18 11:21:15 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "en_postagger = stanza.Pipeline('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T03:21:48.269625Z",
     "start_time": "2020-06-18T03:21:15.271497Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-18 11:21:15 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2020-06-18 11:21:15 INFO: Loading these models for language: zh-hans (Simplified_Chinese):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | gsdsimp   |\n",
      "| pos       | gsdsimp   |\n",
      "| lemma     | gsdsimp   |\n",
      "| depparse  | gsdsimp   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-06-18 11:21:15 INFO: Use device: cpu\n",
      "2020-06-18 11:21:15 INFO: Loading: tokenize\n",
      "2020-06-18 11:21:16 INFO: Loading: pos\n",
      "2020-06-18 11:21:27 INFO: Loading: lemma\n",
      "2020-06-18 11:21:27 INFO: Loading: depparse\n",
      "2020-06-18 11:21:40 INFO: Loading: ner\n",
      "2020-06-18 11:21:48 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "zh_postagger = stanza.Pipeline('zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T05:27:15.025387Z",
     "start_time": "2020-06-18T05:25:45.594171Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-18 13:25:45 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2020-06-18 13:25:45 INFO: Loading these models for language: zh-hans (Simplified_Chinese):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | gsdsimp   |\n",
      "| pos       | gsdsimp   |\n",
      "| lemma     | gsdsimp   |\n",
      "| depparse  | gsdsimp   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-06-18 13:25:46 INFO: Use device: cpu\n",
      "2020-06-18 13:25:46 INFO: Loading: tokenize\n",
      "2020-06-18 13:25:46 INFO: Loading: pos\n",
      "2020-06-18 13:26:14 INFO: Loading: lemma\n",
      "2020-06-18 13:26:16 INFO: Loading: depparse\n",
      "2020-06-18 13:26:58 INFO: Loading: ner\n",
      "2020-06-18 13:27:14 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "zh_postagger_pretoken = stanza.Pipeline(lang='zh', tokenize_pretokenized=True)\n",
    "\n",
    "# words split by space, sentences by newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T03:21:53.928357Z",
     "start_time": "2020-06-18T03:21:48.854360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of              ID_zh         ID_en                             Sentence_zh  \\\n",
       "0     zh-000000033  en-000005983               1989年以前，全球经济包含大约8亿到10亿人口。   \n",
       "1     zh-000000231  en-000047360        今日全球面临的威胁是超民族的，因此也必须采取超民族的方式来应对。   \n",
       "2     zh-000000272  en-000027140                   欧盟移民政策的硬伤还有一个不太显著的方面。   \n",
       "3     zh-000000438  en-000065621           只有让民粹主义服务于自由主义改革，政府才能取得长久的利益。   \n",
       "4     zh-000000639  en-000005169       但社会民主派必须理解为何示威的发展会独立于现有的有组织中左翼政治。   \n",
       "...            ...           ...                                     ...   \n",
       "1848  zh-000094590  en-000013258         事件发生后当局在尚未进行调查的情况下就匆匆掩埋了出事列车残骸。   \n",
       "1849  zh-000094593  en-000061419             北方拥有丰富的自然资源，就连电力也是从北方输送到南方。   \n",
       "1850  zh-000094607  en-000039373                如果利率为3%，那么年税收额必须增加15亿美元。   \n",
       "1851  zh-000094611  en-000003807           五年前，叙利亚北部边陲城镇享受着土耳其高速经济增长的红利。   \n",
       "1852  zh-000094633  en-000083972  在过去的一个世纪中，我们的世界发生了翻天覆地的变化——技术是其中的重要原因。   \n",
       "\n",
       "                                            Sentence_en  \n",
       "0     Until 1989, the global market encompassed betw...  \n",
       "1     The threats facing the world today are suprana...  \n",
       "2     There is another, less obvious, reason why the...  \n",
       "3     Only if populism is put at the service of libe...  \n",
       "4     But social democrats must understand why the p...  \n",
       "...                                                 ...  \n",
       "1848  The wrecked body of the ruined train was burie...  \n",
       "1849  Natural resources were abundant in the North, ...  \n",
       "1850  If it is 3%, the required increase in annual t...  \n",
       "1851  Five years ago, Syria’s northern border towns ...  \n",
       "1852  Our world has changed vastly over the past cen...  \n",
       "\n",
       "[1853 rows x 4 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = bp.get_merge()\n",
    "new_df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T07:06:30.434768Z",
     "start_time": "2020-06-18T07:06:25.017852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ADJ', 1), ('NOUN', 1), ('VERB', 2)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_pos_counts(sentence, attr = \"upos\", lang =\"en\", filtered=[]):\n",
    "    \n",
    "    tag_count_dict = {}\n",
    "    \n",
    "    if lang == \"en\":\n",
    "        pos_list = [getattr(word, attr) for s in en_postagger(sentence).sentences for word in s.words]\n",
    "        \n",
    "    elif lang == \"zh\":\n",
    "        pos_list = [getattr(word, attr) for s in zh_postagger(sentence).sentences for word in s.words]\n",
    "        \n",
    "    elif lang == \"zh_jieba\":\n",
    "        pos_list = [getattr(word, attr) for s in zh_postagger(' '.join(jieba.lcut(sentence))).sentences for word in s.words]\n",
    "        \n",
    "    for tag in pos_list:\n",
    "        if tag not in tag_count_dict:\n",
    "            tag_count_dict[tag]=1\n",
    "        else: \n",
    "            tag_count_dict[tag]+=1\n",
    "    \n",
    "    if filtered:\n",
    "        filtered_dict = {k: v for k, v in tag_count_dict.items() if k in filtered}\n",
    "        output_list = sorted(filtered_dict.items())\n",
    "    else:\n",
    "        output_list = sorted(tag_count_dict.items())\n",
    "    \n",
    "    \n",
    "    return output_list\n",
    "\n",
    "see_tags = ['NOUN','VERB','ADJ','NUM','PROPN']\n",
    "make_pos_counts('I’m sure that this world – I think I’ll have fully enjoyed it', filtered=see_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T06:08:36.360602Z",
     "start_time": "2020-06-18T05:46:52.119133Z"
    }
   },
   "outputs": [],
   "source": [
    "filters=[]\n",
    "\n",
    "pos_df = new_df\n",
    "pos_df['pos_en'] = [make_pos_counts(pos_df.iloc[i]['Sentence_en'], \"upos\", \"en\", filtered=filters) for i in range(1853)]\n",
    "pos_df['pos_zh'] = [make_pos_counts(pos_df.iloc[i]['Sentence_zh'], \"upos\", \"zh\", filtered=filters) for i in range(1853)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T06:33:13.591535Z",
     "start_time": "2020-06-18T06:33:09.331416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_zh</th>\n",
       "      <th>ID_en</th>\n",
       "      <th>Sentence_zh</th>\n",
       "      <th>Sentence_en</th>\n",
       "      <th>pos_en</th>\n",
       "      <th>pos_zh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zh-000000033</td>\n",
       "      <td>en-000005983</td>\n",
       "      <td>1989年以前，全球经济包含大约8亿到10亿人口。</td>\n",
       "      <td>Until 1989, the global market encompassed betw...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 2), (CCONJ, 1), (DET, 1), (NO...</td>\n",
       "      <td>[(ADP, 1), (ADV, 1), (NOUN, 4), (NUM, 3), (PAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zh-000000231</td>\n",
       "      <td>en-000047360</td>\n",
       "      <td>今日全球面临的威胁是超民族的，因此也必须采取超民族的方式来应对。</td>\n",
       "      <td>The threats facing the world today are suprana...</td>\n",
       "      <td>[(ADJ, 2), (ADV, 2), (AUX, 3), (DET, 2), (NOUN...</td>\n",
       "      <td>[(ADP, 1), (ADV, 2), (AUX, 2), (NOUN, 6), (PAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zh-000000272</td>\n",
       "      <td>en-000027140</td>\n",
       "      <td>欧盟移民政策的硬伤还有一个不太显著的方面。</td>\n",
       "      <td>There is another, less obvious, reason why the...</td>\n",
       "      <td>[(ADJ, 2), (ADP, 1), (ADV, 2), (AUX, 1), (DET,...</td>\n",
       "      <td>[(ADJ, 1), (ADV, 3), (NOUN, 5), (NUM, 1), (PAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zh-000000438</td>\n",
       "      <td>en-000065621</td>\n",
       "      <td>只有让民粹主义服务于自由主义改革，政府才能取得长久的利益。</td>\n",
       "      <td>Only if populism is put at the service of libe...</td>\n",
       "      <td>[(ADJ, 2), (ADP, 2), (ADV, 1), (AUX, 2), (DET,...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 1), (AUX, 1), (NOUN, 7), (PAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zh-000000639</td>\n",
       "      <td>en-000005169</td>\n",
       "      <td>但社会民主派必须理解为何示威的发展会独立于现有的有组织中左翼政治。</td>\n",
       "      <td>But social democrats must understand why the p...</td>\n",
       "      <td>[(ADJ, 2), (ADP, 1), (ADV, 3), (AUX, 1), (CCON...</td>\n",
       "      <td>[(ADP, 1), (ADV, 1), (AUX, 2), (NOUN, 6), (PAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>zh-000094590</td>\n",
       "      <td>en-000013258</td>\n",
       "      <td>事件发生后当局在尚未进行调查的情况下就匆匆掩埋了出事列车残骸。</td>\n",
       "      <td>The wrecked body of the ruined train was burie...</td>\n",
       "      <td>[(ADP, 2), (ADV, 2), (AUX, 1), (DET, 3), (NOUN...</td>\n",
       "      <td>[(ADP, 3), (ADV, 4), (NOUN, 6), (PART, 2), (PU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>zh-000094593</td>\n",
       "      <td>en-000061419</td>\n",
       "      <td>北方拥有丰富的自然资源，就连电力也是从北方输送到南方。</td>\n",
       "      <td>Natural resources were abundant in the North, ...</td>\n",
       "      <td>[(ADJ, 2), (ADP, 3), (ADV, 1), (AUX, 2), (CCON...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 1), (ADV, 2), (NOUN, 6), (PAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>zh-000094607</td>\n",
       "      <td>en-000039373</td>\n",
       "      <td>如果利率为3%，那么年税收额必须增加15亿美元。</td>\n",
       "      <td>If it is 3%, the required increase in annual t...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 2), (AUX, 1), (DET, 2), (NOUN...</td>\n",
       "      <td>[(ADP, 1), (ADV, 1), (AUX, 2), (NOUN, 4), (NUM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>zh-000094611</td>\n",
       "      <td>en-000003807</td>\n",
       "      <td>五年前，叙利亚北部边陲城镇享受着土耳其高速经济增长的红利。</td>\n",
       "      <td>Five years ago, Syria’s northern border towns ...</td>\n",
       "      <td>[(ADJ, 2), (ADP, 1), (ADV, 1), (AUX, 1), (DET,...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 1), (NOUN, 6), (NUM, 1), (PAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>zh-000094633</td>\n",
       "      <td>en-000083972</td>\n",
       "      <td>在过去的一个世纪中，我们的世界发生了翻天覆地的变化——技术是其中的重要原因。</td>\n",
       "      <td>Our world has changed vastly over the past cen...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 3), (ADV, 3), (AUX, 1), (CCON...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 2), (AUX, 1), (NOUN, 11), (NU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1853 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_zh         ID_en                             Sentence_zh  \\\n",
       "0     zh-000000033  en-000005983               1989年以前，全球经济包含大约8亿到10亿人口。   \n",
       "1     zh-000000231  en-000047360        今日全球面临的威胁是超民族的，因此也必须采取超民族的方式来应对。   \n",
       "2     zh-000000272  en-000027140                   欧盟移民政策的硬伤还有一个不太显著的方面。   \n",
       "3     zh-000000438  en-000065621           只有让民粹主义服务于自由主义改革，政府才能取得长久的利益。   \n",
       "4     zh-000000639  en-000005169       但社会民主派必须理解为何示威的发展会独立于现有的有组织中左翼政治。   \n",
       "...            ...           ...                                     ...   \n",
       "1848  zh-000094590  en-000013258         事件发生后当局在尚未进行调查的情况下就匆匆掩埋了出事列车残骸。   \n",
       "1849  zh-000094593  en-000061419             北方拥有丰富的自然资源，就连电力也是从北方输送到南方。   \n",
       "1850  zh-000094607  en-000039373                如果利率为3%，那么年税收额必须增加15亿美元。   \n",
       "1851  zh-000094611  en-000003807           五年前，叙利亚北部边陲城镇享受着土耳其高速经济增长的红利。   \n",
       "1852  zh-000094633  en-000083972  在过去的一个世纪中，我们的世界发生了翻天覆地的变化——技术是其中的重要原因。   \n",
       "\n",
       "                                            Sentence_en  \\\n",
       "0     Until 1989, the global market encompassed betw...   \n",
       "1     The threats facing the world today are suprana...   \n",
       "2     There is another, less obvious, reason why the...   \n",
       "3     Only if populism is put at the service of libe...   \n",
       "4     But social democrats must understand why the p...   \n",
       "...                                                 ...   \n",
       "1848  The wrecked body of the ruined train was burie...   \n",
       "1849  Natural resources were abundant in the North, ...   \n",
       "1850  If it is 3%, the required increase in annual t...   \n",
       "1851  Five years ago, Syria’s northern border towns ...   \n",
       "1852  Our world has changed vastly over the past cen...   \n",
       "\n",
       "                                                 pos_en  \\\n",
       "0     [(ADJ, 1), (ADP, 2), (CCONJ, 1), (DET, 1), (NO...   \n",
       "1     [(ADJ, 2), (ADV, 2), (AUX, 3), (DET, 2), (NOUN...   \n",
       "2     [(ADJ, 2), (ADP, 1), (ADV, 2), (AUX, 1), (DET,...   \n",
       "3     [(ADJ, 2), (ADP, 2), (ADV, 1), (AUX, 2), (DET,...   \n",
       "4     [(ADJ, 2), (ADP, 1), (ADV, 3), (AUX, 1), (CCON...   \n",
       "...                                                 ...   \n",
       "1848  [(ADP, 2), (ADV, 2), (AUX, 1), (DET, 3), (NOUN...   \n",
       "1849  [(ADJ, 2), (ADP, 3), (ADV, 1), (AUX, 2), (CCON...   \n",
       "1850  [(ADJ, 1), (ADP, 2), (AUX, 1), (DET, 2), (NOUN...   \n",
       "1851  [(ADJ, 2), (ADP, 1), (ADV, 1), (AUX, 1), (DET,...   \n",
       "1852  [(ADJ, 1), (ADP, 3), (ADV, 3), (AUX, 1), (CCON...   \n",
       "\n",
       "                                                 pos_zh  \n",
       "0     [(ADP, 1), (ADV, 1), (NOUN, 4), (NUM, 3), (PAR...  \n",
       "1     [(ADP, 1), (ADV, 2), (AUX, 2), (NOUN, 6), (PAR...  \n",
       "2     [(ADJ, 1), (ADV, 3), (NOUN, 5), (NUM, 1), (PAR...  \n",
       "3     [(ADJ, 1), (ADP, 1), (AUX, 1), (NOUN, 7), (PAR...  \n",
       "4     [(ADP, 1), (ADV, 1), (AUX, 2), (NOUN, 6), (PAR...  \n",
       "...                                                 ...  \n",
       "1848  [(ADP, 3), (ADV, 4), (NOUN, 6), (PART, 2), (PU...  \n",
       "1849  [(ADJ, 1), (ADP, 1), (ADV, 2), (NOUN, 6), (PAR...  \n",
       "1850  [(ADP, 1), (ADV, 1), (AUX, 2), (NOUN, 4), (NUM...  \n",
       "1851  [(ADJ, 1), (ADP, 1), (NOUN, 6), (NUM, 1), (PAR...  \n",
       "1852  [(ADJ, 1), (ADP, 2), (AUX, 1), (NOUN, 11), (NU...  \n",
       "\n",
       "[1853 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T05:38:53.184921Z",
     "start_time": "2020-06-18T05:38:50.677082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: Until\tupos: ADP\txpos: IN\tfeats: _\n",
      "word: 1989\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: ,\tupos: PUNCT\txpos: ,\tfeats: _\n",
      "word: the\tupos: DET\txpos: DT\tfeats: Definite=Def|PronType=Art\n",
      "word: global\tupos: ADJ\txpos: JJ\tfeats: Degree=Pos\n",
      "word: market\tupos: NOUN\txpos: NN\tfeats: Number=Sing\n",
      "word: encompassed\tupos: VERB\txpos: VBD\tfeats: Mood=Ind|Tense=Past|VerbForm=Fin\n",
      "word: between\tupos: ADP\txpos: IN\tfeats: _\n",
      "word: 800\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: million\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: and\tupos: CCONJ\txpos: CC\tfeats: _\n",
      "word: one\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: billion\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: people\tupos: NOUN\txpos: NNS\tfeats: Number=Plur\n",
      "word: .\tupos: PUNCT\txpos: .\tfeats: _\n",
      "[('ADJ', 1), ('NOUN', 2), ('NUM', 5), ('VERB', 1)]\n",
      "\n",
      "word: 1989\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: 年\tupos: NOUN\txpos: NNB\tfeats: _\n",
      "word: 以前\tupos: ADP\txpos: IN\tfeats: _\n",
      "word: ，\tupos: PUNCT\txpos: ,\tfeats: _\n",
      "word: 全球\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 经济\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 包含\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 大约\tupos: ADV\txpos: RB\tfeats: _\n",
      "word: 8亿到\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: 10亿\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: 人\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 口\tupos: PART\txpos: SFN\tfeats: _\n",
      "word: 。\tupos: PUNCT\txpos: .\tfeats: _\n",
      "[('NOUN', 4), ('NUM', 3), ('VERB', 1)]\n",
      "\n",
      "word: 1989\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: 年\tupos: NOUN\txpos: NNB\tfeats: _\n",
      "word: 以前\tupos: ADP\txpos: IN\tfeats: _\n",
      "word: ，\tupos: PUNCT\txpos: ,\tfeats: _\n",
      "word: 全球\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 经济\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 包含\tupos: VERB\txpos: VV\tfeats: _\n",
      "word: 大约\tupos: ADV\txpos: RB\tfeats: _\n",
      "word: 8\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: 亿到\tupos: CCONJ\txpos: CC\tfeats: _\n",
      "word: 10\tupos: NUM\txpos: CD\tfeats: NumType=Card\n",
      "word: 亿\tupos: NOUN\txpos: NNB\tfeats: _\n",
      "word: 人口\tupos: NOUN\txpos: NN\tfeats: _\n",
      "word: 。\tupos: PUNCT\txpos: .\tfeats: _\n",
      "[('NOUN', 4), ('NUM', 3), ('VERB', 1)]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "filters = ['NOUN', 'VERB', 'ADJ', 'NUM']\n",
    "\n",
    "doc= en_postagger(pos_df.iloc[i]['Sentence_en'])\n",
    "print(*[f'word: {word.text}\\tupos: {word.upos}\\txpos: {word.xpos}\\tfeats: {word.feats if word.feats else \"_\"}' for sent in doc.sentences for word in sent.words], sep='\\n')\n",
    "print(make_pos_counts(pos_df.iloc[i]['Sentence_en'], \"upos\", \"en\", filtered=filters))\n",
    "\n",
    "print()\n",
    "\n",
    "doc= zh_postagger(pos_df.iloc[i]['Sentence_zh'])\n",
    "print(*[f'word: {word.text}\\tupos: {word.upos}\\txpos: {word.xpos}\\tfeats: {word.feats if word.feats else \"_\"}' for sent in doc.sentences for word in sent.words], sep='\\n')\n",
    "print(make_pos_counts(pos_df.iloc[i]['Sentence_zh'], \"upos\", \"zh\", filtered=filters))\n",
    "\n",
    "print()\n",
    "\n",
    "doc= zh_postagger_pretoken(' '.join(jieba.lcut(pos_df.iloc[i]['Sentence_zh'])))\n",
    "print(*[f'word: {word.text}\\tupos: {word.upos}\\txpos: {word.xpos}\\tfeats: {word.feats if word.feats else \"_\"}' for sent in doc.sentences for word in sent.words], sep='\\n')\n",
    "print(make_pos_counts(pos_df.iloc[i]['Sentence_zh'], \"upos\", \"zh_jieba\", filtered=filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:12:49.243468Z",
     "start_time": "2020-06-18T08:12:49.148754Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pos_vect(pos_list, filters=['NOUN', 'VERB', 'ADJ', 'NUM']):\n",
    "    \n",
    "    filtered_dict = {}\n",
    "    ordered_list = []\n",
    "    \n",
    "    for t, n in pos_list:\n",
    "        if t in filters:\n",
    "            filtered_dict[t] = n\n",
    "            \n",
    "    for f in filters:\n",
    "        if f not in filtered_dict:\n",
    "            filtered_dict[f] = 0\n",
    "            \n",
    "    ordered_list = [v for k, v in sorted(filtered_dict.items())]\n",
    "            \n",
    "    vector = np.asarray(ordered_list)\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T07:52:51.132395Z",
     "start_time": "2020-06-18T07:52:51.127407Z"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(v1,v2):\n",
    "    '''cosine_similarity(transformed_docs[2], transformed_docs[2])'''\n",
    "    ## Idk why need to np.squeeze (1,148) into (148,) shape to dot product [error: shapes not aligned]\n",
    "    ## toarray() [error: dimension mismatch] v1.toarray()v2.toarray()\n",
    "    v1 = np.squeeze(v1)\n",
    "    v2 = np.squeeze(v2)\n",
    "    return np.dot(v1,v2) / ( np.sqrt(np.dot(v1,v1)) * np.sqrt(np.dot(v2,v2)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T07:38:52.422298Z",
     "start_time": "2020-06-18T07:38:51.726678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "filters = ['NOUN', 'VERB', 'ADJ', 'NUM']\n",
    "\n",
    "\n",
    "pos_df['similarity'] = [cosine_similarity( make_pos_vect(pos_df.iloc[i]['pos_en'], filters), make_pos_vect(pos_df.iloc[i]['pos_zh'], filters) ) for i in range(1853)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T07:54:36.928824Z",
     "start_time": "2020-06-18T07:54:36.853655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_zh</th>\n",
       "      <th>ID_en</th>\n",
       "      <th>Sentence_zh</th>\n",
       "      <th>Sentence_en</th>\n",
       "      <th>pos_en</th>\n",
       "      <th>pos_zh</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zh-000000033</td>\n",
       "      <td>en-000005983</td>\n",
       "      <td>1989年以前，全球经济包含大约8亿到10亿人口。</td>\n",
       "      <td>Until 1989, the global market encompassed betw...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 2), (CCONJ, 1), (DET, 1), (NO...</td>\n",
       "      <td>[(ADP, 1), (ADV, 1), (NOUN, 4), (NUM, 3), (PAR...</td>\n",
       "      <td>0.845364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zh-000000231</td>\n",
       "      <td>en-000047360</td>\n",
       "      <td>今日全球面临的威胁是超民族的，因此也必须采取超民族的方式来应对。</td>\n",
       "      <td>The threats facing the world today are suprana...</td>\n",
       "      <td>[(ADJ, 2), (ADV, 2), (AUX, 3), (DET, 2), (NOUN...</td>\n",
       "      <td>[(ADP, 1), (ADV, 2), (AUX, 2), (NOUN, 6), (PAR...</td>\n",
       "      <td>0.867722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zh-000000272</td>\n",
       "      <td>en-000027140</td>\n",
       "      <td>欧盟移民政策的硬伤还有一个不太显著的方面。</td>\n",
       "      <td>There is another, less obvious, reason why the...</td>\n",
       "      <td>[(ADJ, 2), (ADP, 1), (ADV, 2), (AUX, 1), (DET,...</td>\n",
       "      <td>[(ADJ, 1), (ADV, 3), (NOUN, 5), (NUM, 1), (PAR...</td>\n",
       "      <td>0.909137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zh-000000438</td>\n",
       "      <td>en-000065621</td>\n",
       "      <td>只有让民粹主义服务于自由主义改革，政府才能取得长久的利益。</td>\n",
       "      <td>Only if populism is put at the service of libe...</td>\n",
       "      <td>[(ADJ, 2), (ADP, 2), (ADV, 1), (AUX, 2), (DET,...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 1), (AUX, 1), (NOUN, 7), (PAR...</td>\n",
       "      <td>0.964237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zh-000000639</td>\n",
       "      <td>en-000005169</td>\n",
       "      <td>但社会民主派必须理解为何示威的发展会独立于现有的有组织中左翼政治。</td>\n",
       "      <td>But social democrats must understand why the p...</td>\n",
       "      <td>[(ADJ, 2), (ADP, 1), (ADV, 3), (AUX, 1), (CCON...</td>\n",
       "      <td>[(ADP, 1), (ADV, 1), (AUX, 2), (NOUN, 6), (PAR...</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>zh-000094590</td>\n",
       "      <td>en-000013258</td>\n",
       "      <td>事件发生后当局在尚未进行调查的情况下就匆匆掩埋了出事列车残骸。</td>\n",
       "      <td>The wrecked body of the ruined train was burie...</td>\n",
       "      <td>[(ADP, 2), (ADV, 2), (AUX, 1), (DET, 3), (NOUN...</td>\n",
       "      <td>[(ADP, 3), (ADV, 4), (NOUN, 6), (PART, 2), (PU...</td>\n",
       "      <td>0.995893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>zh-000094593</td>\n",
       "      <td>en-000061419</td>\n",
       "      <td>北方拥有丰富的自然资源，就连电力也是从北方输送到南方。</td>\n",
       "      <td>Natural resources were abundant in the North, ...</td>\n",
       "      <td>[(ADJ, 2), (ADP, 3), (ADV, 1), (AUX, 2), (CCON...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 1), (ADV, 2), (NOUN, 6), (PAR...</td>\n",
       "      <td>0.824163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>zh-000094607</td>\n",
       "      <td>en-000039373</td>\n",
       "      <td>如果利率为3%，那么年税收额必须增加15亿美元。</td>\n",
       "      <td>If it is 3%, the required increase in annual t...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 2), (AUX, 1), (DET, 2), (NOUN...</td>\n",
       "      <td>[(ADP, 1), (ADV, 1), (AUX, 2), (NOUN, 4), (NUM...</td>\n",
       "      <td>0.956183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>zh-000094611</td>\n",
       "      <td>en-000003807</td>\n",
       "      <td>五年前，叙利亚北部边陲城镇享受着土耳其高速经济增长的红利。</td>\n",
       "      <td>Five years ago, Syria’s northern border towns ...</td>\n",
       "      <td>[(ADJ, 2), (ADP, 1), (ADV, 1), (AUX, 1), (DET,...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 1), (NOUN, 6), (NUM, 1), (PAR...</td>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>zh-000094633</td>\n",
       "      <td>en-000083972</td>\n",
       "      <td>在过去的一个世纪中，我们的世界发生了翻天覆地的变化——技术是其中的重要原因。</td>\n",
       "      <td>Our world has changed vastly over the past cen...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 3), (ADV, 3), (AUX, 1), (CCON...</td>\n",
       "      <td>[(ADJ, 1), (ADP, 2), (AUX, 1), (NOUN, 11), (NU...</td>\n",
       "      <td>0.947678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1853 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_zh         ID_en                             Sentence_zh  \\\n",
       "0     zh-000000033  en-000005983               1989年以前，全球经济包含大约8亿到10亿人口。   \n",
       "1     zh-000000231  en-000047360        今日全球面临的威胁是超民族的，因此也必须采取超民族的方式来应对。   \n",
       "2     zh-000000272  en-000027140                   欧盟移民政策的硬伤还有一个不太显著的方面。   \n",
       "3     zh-000000438  en-000065621           只有让民粹主义服务于自由主义改革，政府才能取得长久的利益。   \n",
       "4     zh-000000639  en-000005169       但社会民主派必须理解为何示威的发展会独立于现有的有组织中左翼政治。   \n",
       "...            ...           ...                                     ...   \n",
       "1848  zh-000094590  en-000013258         事件发生后当局在尚未进行调查的情况下就匆匆掩埋了出事列车残骸。   \n",
       "1849  zh-000094593  en-000061419             北方拥有丰富的自然资源，就连电力也是从北方输送到南方。   \n",
       "1850  zh-000094607  en-000039373                如果利率为3%，那么年税收额必须增加15亿美元。   \n",
       "1851  zh-000094611  en-000003807           五年前，叙利亚北部边陲城镇享受着土耳其高速经济增长的红利。   \n",
       "1852  zh-000094633  en-000083972  在过去的一个世纪中，我们的世界发生了翻天覆地的变化——技术是其中的重要原因。   \n",
       "\n",
       "                                            Sentence_en  \\\n",
       "0     Until 1989, the global market encompassed betw...   \n",
       "1     The threats facing the world today are suprana...   \n",
       "2     There is another, less obvious, reason why the...   \n",
       "3     Only if populism is put at the service of libe...   \n",
       "4     But social democrats must understand why the p...   \n",
       "...                                                 ...   \n",
       "1848  The wrecked body of the ruined train was burie...   \n",
       "1849  Natural resources were abundant in the North, ...   \n",
       "1850  If it is 3%, the required increase in annual t...   \n",
       "1851  Five years ago, Syria’s northern border towns ...   \n",
       "1852  Our world has changed vastly over the past cen...   \n",
       "\n",
       "                                                 pos_en  \\\n",
       "0     [(ADJ, 1), (ADP, 2), (CCONJ, 1), (DET, 1), (NO...   \n",
       "1     [(ADJ, 2), (ADV, 2), (AUX, 3), (DET, 2), (NOUN...   \n",
       "2     [(ADJ, 2), (ADP, 1), (ADV, 2), (AUX, 1), (DET,...   \n",
       "3     [(ADJ, 2), (ADP, 2), (ADV, 1), (AUX, 2), (DET,...   \n",
       "4     [(ADJ, 2), (ADP, 1), (ADV, 3), (AUX, 1), (CCON...   \n",
       "...                                                 ...   \n",
       "1848  [(ADP, 2), (ADV, 2), (AUX, 1), (DET, 3), (NOUN...   \n",
       "1849  [(ADJ, 2), (ADP, 3), (ADV, 1), (AUX, 2), (CCON...   \n",
       "1850  [(ADJ, 1), (ADP, 2), (AUX, 1), (DET, 2), (NOUN...   \n",
       "1851  [(ADJ, 2), (ADP, 1), (ADV, 1), (AUX, 1), (DET,...   \n",
       "1852  [(ADJ, 1), (ADP, 3), (ADV, 3), (AUX, 1), (CCON...   \n",
       "\n",
       "                                                 pos_zh  similarity  \n",
       "0     [(ADP, 1), (ADV, 1), (NOUN, 4), (NUM, 3), (PAR...    0.845364  \n",
       "1     [(ADP, 1), (ADV, 2), (AUX, 2), (NOUN, 6), (PAR...    0.867722  \n",
       "2     [(ADJ, 1), (ADV, 3), (NOUN, 5), (NUM, 1), (PAR...    0.909137  \n",
       "3     [(ADJ, 1), (ADP, 1), (AUX, 1), (NOUN, 7), (PAR...    0.964237  \n",
       "4     [(ADP, 1), (ADV, 1), (AUX, 2), (NOUN, 6), (PAR...    0.942809  \n",
       "...                                                 ...         ...  \n",
       "1848  [(ADP, 3), (ADV, 4), (NOUN, 6), (PART, 2), (PU...    0.995893  \n",
       "1849  [(ADJ, 1), (ADP, 1), (ADV, 2), (NOUN, 6), (PAR...    0.824163  \n",
       "1850  [(ADP, 1), (ADV, 1), (AUX, 2), (NOUN, 4), (NUM...    0.956183  \n",
       "1851  [(ADJ, 1), (ADP, 1), (NOUN, 6), (NUM, 1), (PAR...    0.976190  \n",
       "1852  [(ADJ, 1), (ADP, 2), (AUX, 1), (NOUN, 11), (NU...    0.947678  \n",
       "\n",
       "[1853 rows x 7 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:50:49.643466Z",
     "start_time": "2020-06-18T08:50:49.607563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line EN: 1055 \tLine ZH: 1768 \tSim: 0.91 \tPair: YES\n",
      "Line EN: 1515 \tLine ZH: 1804 \tSim: 0.83 \tPair: NO\n",
      "Line EN: 53 \tLine ZH: 836 \tSim: 0.99 \tPair: YES\n",
      "Line EN: 1154 \tLine ZH: 1695 \tSim: 0.78 \tPair: NO\n",
      "Line EN: 1444 \tLine ZH: 435 \tSim: 0.49 \tPair: NO\n",
      "Line EN: 646 \tLine ZH: 1453 \tSim: 0.91 \tPair: YES\n",
      "Line EN: 248 \tLine ZH: 1389 \tSim: 0.83 \tPair: NO\n",
      "Line EN: 1257 \tLine ZH: 388 \tSim: 1.0 \tPair: YES\n",
      "Line EN: 788 \tLine ZH: 402 \tSim: 0.86 \tPair: NO\n",
      "Line EN: 351 \tLine ZH: 325 \tSim: 0.79 \tPair: NO\n",
      "Line EN: 574 \tLine ZH: 1842 \tSim: 1.0 \tPair: YES\n",
      "Line EN: 1748 \tLine ZH: 855 \tSim: 0.82 \tPair: NO\n",
      "Line EN: 1407 \tLine ZH: 84 \tSim: 0.87 \tPair: NO\n",
      "Line EN: 703 \tLine ZH: 388 \tSim: 0.82 \tPair: NO\n",
      "Line EN: 1130 \tLine ZH: 1031 \tSim: 0.57 \tPair: NO\n",
      "Line EN: 1484 \tLine ZH: 1341 \tSim: 0.81 \tPair: NO\n",
      "Line EN: 534 \tLine ZH: 1542 \tSim: 0.82 \tPair: NO\n",
      "Line EN: 1711 \tLine ZH: 434 \tSim: 0.97 \tPair: YES\n",
      "Line EN: 917 \tLine ZH: 1428 \tSim: 0.97 \tPair: YES\n",
      "Line EN: 1249 \tLine ZH: 1568 \tSim: 0.88 \tPair: NO\n"
     ]
    }
   ],
   "source": [
    "t = 20\n",
    "n = 0\n",
    "\n",
    "while t > n:\n",
    "    x = randrange(1853)\n",
    "    y = randrange(1853)\n",
    "    if x != y:\n",
    "        z = cosine_similarity(make_pos_vect(pos_df.iloc[x]['pos_en'], filters),make_pos_vect(pos_df.iloc[y]['pos_zh'], filters))\n",
    "        zz = 'YES' if z>0.9 else 'NO'\n",
    "    \n",
    "        print('Line EN:',x,'\\tLine ZH:',y,'\\tSim:',round(z,2), '\\tPair:', zz)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:27:34.593805Z",
     "start_time": "2020-06-18T08:27:34.428835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line_en</th>\n",
       "      <th>Line_zh</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.845364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.867722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.909137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.964237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>1848</td>\n",
       "      <td>1848</td>\n",
       "      <td>0.995893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>1849</td>\n",
       "      <td>1849</td>\n",
       "      <td>0.824163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>1850</td>\n",
       "      <td>1850</td>\n",
       "      <td>0.956183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>1851</td>\n",
       "      <td>1851</td>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>1852</td>\n",
       "      <td>1852</td>\n",
       "      <td>0.947678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1853 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Line_en  Line_zh  similarity\n",
       "0           0        0    0.845364\n",
       "1           1        1    0.867722\n",
       "2           2        2    0.909137\n",
       "3           3        3    0.964237\n",
       "4           4        4    0.942809\n",
       "...       ...      ...         ...\n",
       "1848     1848     1848    0.995893\n",
       "1849     1849     1849    0.824163\n",
       "1850     1850     1850    0.956183\n",
       "1851     1851     1851    0.976190\n",
       "1852     1852     1852    0.947678\n",
       "\n",
       "[1853 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df = pd.DataFrame()\n",
    "c_df['Line_en'] = pos_df.index\n",
    "c_df['Line_zh'] = pos_df.index\n",
    "c_df['similarity'] = pos_df['similarity']\n",
    "c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:26:22.180220Z",
     "start_time": "2020-06-18T08:26:22.080788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INC File exists, reading...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line_en</th>\n",
       "      <th>Line_zh</th>\n",
       "      <th>length_en</th>\n",
       "      <th>length_zh</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>647</td>\n",
       "      <td>430</td>\n",
       "      <td>126</td>\n",
       "      <td>52</td>\n",
       "      <td>0.800499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1835</td>\n",
       "      <td>1362</td>\n",
       "      <td>56</td>\n",
       "      <td>69</td>\n",
       "      <td>0.737865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>0.421160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1373</td>\n",
       "      <td>701</td>\n",
       "      <td>89</td>\n",
       "      <td>43</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197</td>\n",
       "      <td>987</td>\n",
       "      <td>114</td>\n",
       "      <td>60</td>\n",
       "      <td>0.862924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>1308</td>\n",
       "      <td>962</td>\n",
       "      <td>93</td>\n",
       "      <td>64</td>\n",
       "      <td>0.736248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>801</td>\n",
       "      <td>602</td>\n",
       "      <td>108</td>\n",
       "      <td>34</td>\n",
       "      <td>0.908893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>1778</td>\n",
       "      <td>1359</td>\n",
       "      <td>91</td>\n",
       "      <td>58</td>\n",
       "      <td>0.980379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>1782</td>\n",
       "      <td>1097</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>0.888532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>175</td>\n",
       "      <td>321</td>\n",
       "      <td>108</td>\n",
       "      <td>66</td>\n",
       "      <td>0.933139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1853 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Line_en  Line_zh  length_en  length_zh  similarity\n",
       "0         647      430        126         52    0.800499\n",
       "1        1835     1362         56         69    0.737865\n",
       "2         365       15         80         64    0.421160\n",
       "3        1373      701         89         43    0.966667\n",
       "4         197      987        114         60    0.862924\n",
       "...       ...      ...        ...        ...         ...\n",
       "1848     1308      962         93         64    0.736248\n",
       "1849      801      602        108         34    0.908893\n",
       "1850     1778     1359         91         58    0.980379\n",
       "1851     1782     1097         78         72    0.888532\n",
       "1852      175      321        108         66    0.933139\n",
       "\n",
       "[1853 rows x 5 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_file = Path(\"zh-en.training.incorrect\")\n",
    "if inc_file.is_file():\n",
    "    print('INC File exists, reading...')\n",
    "    inc_df = pd.read_csv(inc_file, header=0, sep='\\t')\n",
    "\n",
    "else:\n",
    "    print('No inc file Error')\n",
    "    \n",
    "\n",
    "if 'similarity' not in inc_df.columns:\n",
    "    cs_list = []\n",
    "\n",
    "    for i in range(1853):\n",
    "        x = int(inc_df.iloc[i]['Line_en'])\n",
    "        y = int(inc_df.iloc[i]['Line_zh'])\n",
    "        cs_list.append(cosine_similarity(make_pos_vect(pos_df.iloc[x]['pos_en']), make_pos_vect(pos_df.iloc[y]['pos_zh'])))\n",
    "\n",
    "    inc_df['similarity'] = cs_list\n",
    "\n",
    "    inc_df.to_csv(inc_file, index=False, sep='\\t')\n",
    "\n",
    "inc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:44:56.894883Z",
     "start_time": "2020-06-18T08:44:54.881881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criteria</th>\n",
       "      <th>Precision(%)</th>\n",
       "      <th>Recall(%)</th>\n",
       "      <th>F1_Score(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.80</td>\n",
       "      <td>53.571429</td>\n",
       "      <td>80.949811</td>\n",
       "      <td>64.474533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.81</td>\n",
       "      <td>54.125046</td>\n",
       "      <td>78.953049</td>\n",
       "      <td>64.223003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.82</td>\n",
       "      <td>54.645849</td>\n",
       "      <td>77.441986</td>\n",
       "      <td>64.076803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.83</td>\n",
       "      <td>54.901961</td>\n",
       "      <td>75.553157</td>\n",
       "      <td>63.593005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.84</td>\n",
       "      <td>55.228758</td>\n",
       "      <td>72.962763</td>\n",
       "      <td>62.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.85</td>\n",
       "      <td>55.659178</td>\n",
       "      <td>70.858068</td>\n",
       "      <td>62.345679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.86</td>\n",
       "      <td>56.121537</td>\n",
       "      <td>67.781975</td>\n",
       "      <td>61.403080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.87</td>\n",
       "      <td>56.975106</td>\n",
       "      <td>65.461414</td>\n",
       "      <td>60.924159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.88</td>\n",
       "      <td>57.568238</td>\n",
       "      <td>62.601187</td>\n",
       "      <td>59.979317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.89</td>\n",
       "      <td>58.206607</td>\n",
       "      <td>59.902860</td>\n",
       "      <td>59.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.90</td>\n",
       "      <td>58.251869</td>\n",
       "      <td>54.668106</td>\n",
       "      <td>56.403118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.91</td>\n",
       "      <td>58.801729</td>\n",
       "      <td>51.376147</td>\n",
       "      <td>54.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.92</td>\n",
       "      <td>59.877384</td>\n",
       "      <td>47.436589</td>\n",
       "      <td>52.935863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.93</td>\n",
       "      <td>60.655738</td>\n",
       "      <td>41.932002</td>\n",
       "      <td>49.585195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.94</td>\n",
       "      <td>61.450044</td>\n",
       "      <td>37.506746</td>\n",
       "      <td>46.581769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.95</td>\n",
       "      <td>62.365591</td>\n",
       "      <td>31.300594</td>\n",
       "      <td>41.681639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.96</td>\n",
       "      <td>63.695937</td>\n",
       "      <td>26.227739</td>\n",
       "      <td>37.155963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.97</td>\n",
       "      <td>64.746946</td>\n",
       "      <td>20.021587</td>\n",
       "      <td>30.585326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.98</td>\n",
       "      <td>67.115903</td>\n",
       "      <td>13.437669</td>\n",
       "      <td>22.392086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.99</td>\n",
       "      <td>69.767442</td>\n",
       "      <td>6.475985</td>\n",
       "      <td>11.851852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Criteria  Precision(%)  Recall(%)  F1_Score(%)\n",
       "0       0.80     53.571429  80.949811    64.474533\n",
       "1       0.81     54.125046  78.953049    64.223003\n",
       "2       0.82     54.645849  77.441986    64.076803\n",
       "3       0.83     54.901961  75.553157    63.593005\n",
       "4       0.84     55.228758  72.962763    62.869100\n",
       "5       0.85     55.659178  70.858068    62.345679\n",
       "6       0.86     56.121537  67.781975    61.403080\n",
       "7       0.87     56.975106  65.461414    60.924159\n",
       "8       0.88     57.568238  62.601187    59.979317\n",
       "9       0.89     58.206607  59.902860    59.042553\n",
       "10      0.90     58.251869  54.668106    56.403118\n",
       "11      0.91     58.801729  51.376147    54.838710\n",
       "12      0.92     59.877384  47.436589    52.935863\n",
       "13      0.93     60.655738  41.932002    49.585195\n",
       "14      0.94     61.450044  37.506746    46.581769\n",
       "15      0.95     62.365591  31.300594    41.681639\n",
       "16      0.96     63.695937  26.227739    37.155963\n",
       "17      0.97     64.746946  20.021587    30.585326\n",
       "18      0.98     67.115903  13.437669    22.392086\n",
       "19      0.99     69.767442   6.475985    11.851852"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _f_score(x, cut_point):\n",
    "    p,n = (0,0)\n",
    "    \n",
    "    if x['similarity'] > cut_point:\n",
    "        p += 1\n",
    "    else:\n",
    "        n +=1\n",
    "    return p, n\n",
    "\n",
    "def f_score(cut_point):\n",
    "    \n",
    "    tp = c_df.apply(lambda x: _f_score(x, cut_point), axis=1).value_counts().get((1,0))\n",
    "    fn = c_df.apply(lambda x: _f_score(x, cut_point), axis=1).value_counts().get((0,1))\n",
    "    fp = inc_df.apply(lambda x: _f_score(x, cut_point), axis=1).value_counts().get((1,0))\n",
    "    tn = inc_df.apply(lambda x: _f_score(x, cut_point), axis=1).value_counts().get((0,1))\n",
    "    \n",
    "    tp = tp if tp else 0\n",
    "    fn = fn if fn else 0\n",
    "    fp = fp if fp else 0\n",
    "    tn = tn if tn else 0\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 2*(precision*recall/(precision+recall))\n",
    "    \n",
    "    return precision*100, recall*100, f1*100\n",
    "\n",
    "\n",
    "start_c = 0.8\n",
    "step_c = 0.01\n",
    "num_c = 20\n",
    "\n",
    "f_df = pd.DataFrame(columns=['Criteria','Precision(%)','Recall(%)','F1_Score(%)'])\n",
    "\n",
    "n=0 \n",
    "while n<num_c:\n",
    "    criteria = start_c\n",
    "    \n",
    "    p,r,f = f_score(criteria)\n",
    "    \n",
    "    f_df.loc[len(f_df)] = [criteria, p, r, f]\n",
    "    \n",
    "    start_c += step_c\n",
    "    n+=1\n",
    "    \n",
    "f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:47:14.824401Z",
     "start_time": "2020-06-18T08:47:12.683445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criteria</th>\n",
       "      <th>Precision(%)</th>\n",
       "      <th>Recall(%)</th>\n",
       "      <th>F1_Score(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>50.675489</td>\n",
       "      <td>99.190502</td>\n",
       "      <td>67.080292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.51</td>\n",
       "      <td>50.690989</td>\n",
       "      <td>98.974636</td>\n",
       "      <td>67.044416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.52</td>\n",
       "      <td>50.705785</td>\n",
       "      <td>98.866703</td>\n",
       "      <td>67.032565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53</td>\n",
       "      <td>50.805108</td>\n",
       "      <td>98.758770</td>\n",
       "      <td>67.094409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.54</td>\n",
       "      <td>50.890869</td>\n",
       "      <td>98.650836</td>\n",
       "      <td>67.144169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.55</td>\n",
       "      <td>50.933928</td>\n",
       "      <td>98.596870</td>\n",
       "      <td>67.169118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.56</td>\n",
       "      <td>51.048951</td>\n",
       "      <td>98.488937</td>\n",
       "      <td>67.243920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.57</td>\n",
       "      <td>51.096121</td>\n",
       "      <td>98.111171</td>\n",
       "      <td>67.196452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.58</td>\n",
       "      <td>51.169343</td>\n",
       "      <td>98.003238</td>\n",
       "      <td>67.234358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.59</td>\n",
       "      <td>51.229856</td>\n",
       "      <td>97.787372</td>\n",
       "      <td>67.235622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.60</td>\n",
       "      <td>51.221591</td>\n",
       "      <td>97.301673</td>\n",
       "      <td>67.113345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.61</td>\n",
       "      <td>51.311288</td>\n",
       "      <td>97.139773</td>\n",
       "      <td>67.151651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.62</td>\n",
       "      <td>51.490826</td>\n",
       "      <td>96.923907</td>\n",
       "      <td>67.253323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.63</td>\n",
       "      <td>51.656583</td>\n",
       "      <td>96.762008</td>\n",
       "      <td>67.355372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.64</td>\n",
       "      <td>51.827146</td>\n",
       "      <td>96.438208</td>\n",
       "      <td>67.421241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.65</td>\n",
       "      <td>51.850772</td>\n",
       "      <td>96.006476</td>\n",
       "      <td>67.335352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.66</td>\n",
       "      <td>51.948432</td>\n",
       "      <td>95.682677</td>\n",
       "      <td>67.337638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.67</td>\n",
       "      <td>51.943463</td>\n",
       "      <td>95.196978</td>\n",
       "      <td>67.212802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.68</td>\n",
       "      <td>51.985774</td>\n",
       "      <td>94.657312</td>\n",
       "      <td>67.113067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.69</td>\n",
       "      <td>52.011923</td>\n",
       "      <td>94.171614</td>\n",
       "      <td>67.012289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Criteria  Precision(%)  Recall(%)  F1_Score(%)\n",
       "0       0.50     50.675489  99.190502    67.080292\n",
       "1       0.51     50.690989  98.974636    67.044416\n",
       "2       0.52     50.705785  98.866703    67.032565\n",
       "3       0.53     50.805108  98.758770    67.094409\n",
       "4       0.54     50.890869  98.650836    67.144169\n",
       "5       0.55     50.933928  98.596870    67.169118\n",
       "6       0.56     51.048951  98.488937    67.243920\n",
       "7       0.57     51.096121  98.111171    67.196452\n",
       "8       0.58     51.169343  98.003238    67.234358\n",
       "9       0.59     51.229856  97.787372    67.235622\n",
       "10      0.60     51.221591  97.301673    67.113345\n",
       "11      0.61     51.311288  97.139773    67.151651\n",
       "12      0.62     51.490826  96.923907    67.253323\n",
       "13      0.63     51.656583  96.762008    67.355372\n",
       "14      0.64     51.827146  96.438208    67.421241\n",
       "15      0.65     51.850772  96.006476    67.335352\n",
       "16      0.66     51.948432  95.682677    67.337638\n",
       "17      0.67     51.943463  95.196978    67.212802\n",
       "18      0.68     51.985774  94.657312    67.113067\n",
       "19      0.69     52.011923  94.171614    67.012289"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_c = 0.5\n",
    "step_c = 0.01\n",
    "num_c = 20\n",
    "\n",
    "f_df = pd.DataFrame(columns=['Criteria','Precision(%)','Recall(%)','F1_Score(%)'])\n",
    "\n",
    "n=0 \n",
    "while n<num_c:\n",
    "    criteria = start_c\n",
    "    \n",
    "    p,r,f = f_score(criteria)\n",
    "    \n",
    "    f_df.loc[len(f_df)] = [criteria, p, r, f]\n",
    "    \n",
    "    start_c += step_c\n",
    "    n+=1\n",
    "    \n",
    "f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best F1 would be 67.42% but precision only at 51%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
